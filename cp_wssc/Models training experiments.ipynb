{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the helpr class file 'All_helper_classes.ipynb' and instantiate the three helper classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T14:06:20.764162Z",
     "start_time": "2019-10-14T14:06:13.633609Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Necessary libraries imported.\n",
      "Initialised generic_parsing_helpers class and methods\n",
      "Initialised AIVM_helper class and methods\n",
      "Initialised model_helpers class and methods\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "You will find instantiate_model_helpers_for_project at the very TOP of All_helper_classes.ipynb, If you do not want to change the default config, used across all files you can instantiate your own model_helpers() instead."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "SEQUENCE_LENGTH 32"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "MAX_NB_WORDS 10000"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "EMBEDDING_DIM 100"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "VALIDATION_SPLIT 0.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "TFIDF_MAX_FEATURES 10000"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "NUM_EPOCHS 20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run \"All_helper_classes.ipynb\" sort=False\n",
    "\n",
    "#from \"Models training helpers.ipynb\" we will import 3 helper classes and the associated helper methods.\n",
    "parsing_helpers = generic_parsing_helpers()\n",
    "aivm_helper = AIVM_helper()\n",
    "model_helpers = default_model_helpers_for_project()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T14:06:21.290584Z",
     "start_time": "2019-10-14T14:06:21.281724Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "//To remove scroll from any output area and automatically extend the jupyter cell\n",
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "//To remove scroll from any output area and automatically extend the jupyter cell\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get project paths from helper classes\n",
    "access using paths.THE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T14:06:21.930451Z",
     "start_time": "2019-10-14T14:06:21.712078Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "*****GIT PROJECT*******"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "paths.GIT_OWNER: aideenf"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "paths.GIT_REPO: AIVC"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "paths.GIT_OWNER_REPO: aideenf/AIVC"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "*****PROJECT PATHS*******"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "paths.BASE_DIR_LOCAL: ./Data/Iterative-models-building"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "paths.GLOVE_DIR_LOCAL : Data/Iterative-models-building/Training data/"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "paths.GATHERED_DATA_CONV_DIR_LOCAL : Data/Iterative-models-building/Gathered_data/Conventions/"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "paths.GATHERED_DATA_CONV_DIR_GIT : cp_wssc/Data/Iterative-models-building/Gathered_data/Conventions/"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "paths.GITHUB_GATHERED_URL_PATH : https://raw.githubusercontent.com/aideenf/AIVC/master/cp_wssc/Data/Iterative-models-building/Gathered_data/Conventions/"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "paths.MODELS_DIR_LOCAL : ./Data/Iterative-models-building/Models/"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "paths.STOP_WORDS_DIR_FILE_LOCAL : Data/Iterative-models-building/Training data/resources/stopwords.txt"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "paths.STOP_WORDS_URL_GIT : https://raw.githubusercontent.com/aideenf/AIVC/master/cp_wssc/Data/Iterative-models-building/Training data/resources/stopwords.txt"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "paths.TRAINING_DATA_DIR_FILE_LOCAL : Data/Iterative-models-building/Training data/Conventions/training_aggregated_conventions.tsv"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "paths.TRAINING_DATA_DIR_FILE_GIT : https://raw.githubusercontent.com/aideenf/AIVC/master/cp_wssc/Data/Iterative-models-building/Training%20data/Conventions/training_aggregated_conventions.tsv"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "paths.TRAINING_DATA_DIR_LOCAL : Data/Iterative-models-building/Training data/Conventions/"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "paths.TRAINING_DATA_DIR_GIT : cp_wssc/Data/Iterative-models-building/Training data/Conventions/"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "paths.AUDITED_DATA_DIR_LOCAL : ./Data/Iterative-models-building/Classification results/Conventions/Audited/"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "paths.AUDITED_DATA_DIR_GIT : cp_wssc/Data/Iterative-models-building/Classification results/Conventions/Audited/"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "paths.GITHUB_AUDIT_URL_PATH : https://raw.githubusercontent.com/aideenf/AIVC/master/cp_wssc/Data/Iterative-models-building/Classification%20results/Conventions/Audited/"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "paths.GITHUB_AGGREGATED_AUDIT_URL_FILE : https://raw.githubusercontent.com/aideenf/AIVC/master/cp_wssc/Data/Iterative-models-building/Classification%20results/Conventions/Audited/audited_ALL.tsv"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "paths.CONV_MODEL_PCKL_URL : not_defined"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "paths.CHARACT_MODEL_PCKL_URL : not_defined"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "paths.CLASSIFIED_DATA_DIR_LOCAL : ./Data/Iterative-models-building/Classification results/Conventions/"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "paths.CLASSIFIED_DATA_DIR_GIT : cp_wssc/Data/Iterative-models-building/Classification results/Conventions/"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gc.collect()\n",
    "paths = project_paths()\n",
    "#Get the latest version of the aggregated already audited data (output from the audit tool) directly from GIT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Training_Data, Gathered_Data and Audited_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T14:06:57.862860Z",
     "start_time": "2019-10-14T14:06:30.981419Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised generic_parsing_helpers class and methods\n",
      "Initialised AIVM_helper class and methods\n"
     ]
    }
   ],
   "source": [
    "USE_GIT_HUB = True  #Use github directly to read the training data and gathered data\n",
    "\n",
    "\n",
    "# Read aggregated training data from TRAINING_DATA_DIR_FILE_LOCAL or TRAINING_DATA_DIR_FILE_GIT \n",
    "# and stores the content in a dataframe variable named 'training_df'. \n",
    "# Files in GATHERED_DATA_FOLDER are combined with the content of 'training_df' \n",
    "# to create the vocabulary of the Tokenizer, as by design, ```\"tokenizer.tokenize()\"``` \n",
    "# will remove any words not seen on the ```\"tokenizer.fit()\"``` stage.\n",
    "                                                      \n",
    "\n",
    "# Read the already static training data file \"paths.TRAINING_DATA_DIR_FILE\" with column_to_clean = 'text' and return \n",
    "# a pandas Data Frame of training data\n",
    "training_df = model_helpers.get_training_data(\n",
    "                            USE_GIT_HUB,\n",
    "                            paths.TRAINING_DATA_DIR_FILE_GIT,\n",
    "                            paths.TRAINING_DATA_DIR_FILE_LOCAL, \n",
    "                            paths.GIT_OWNER,\n",
    "                            paths.GIT_REPO)\n",
    "\n",
    "\n",
    "# Read the gathered_data files \"paths.TRAINING_DATA_DIR_FILE\" with column_to_clean = 'text' and return \n",
    "# a pandas Data Frame\n",
    "gathered_conventions_files, gathered_conventions_df = model_helpers.get_aggregated_gathered_data (\n",
    "                            USE_GIT_HUB,\n",
    "                            paths.GATHERED_DATA_CONV_DIR_GIT,\n",
    "                            paths.GATHERED_DATA_CONV_DIR_LOCAL,\n",
    "                            paths.GITHUB_GATHERED_URL_PATH, \n",
    "                            paths.GIT_OWNER,\n",
    "                            paths.GIT_REPO)\n",
    "\n",
    "\n",
    "#Get the latest version of the aggregated already audited data (output from the audit tool) directly from GIT\n",
    "audited_data_df = model_helpers.retrieve_aggregate_audited_data_from_git (paths.GITHUB_AGGREGATED_AUDIT_URL_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T14:28:21.656336Z",
     "start_time": "2019-10-14T14:28:21.604935Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Training Data'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>provenance</th>\n",
       "      <th>convention</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>an exotic payload crafted:</td>\n",
       "      <td>Manually_gathered</td>\n",
       "      <td>Domestic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>this package provides routines to construct gr...</td>\n",
       "      <td>Manually_gathered</td>\n",
       "      <td>Domestic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>** clearly see how your habits improved over</td>\n",
       "      <td>Manually_gathered</td>\n",
       "      <td>Domestic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>** create an individual reminder for each habi...</td>\n",
       "      <td>Manually_gathered</td>\n",
       "      <td>Domestic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>unit of work and continuity.</td>\n",
       "      <td>Manually_gathered</td>\n",
       "      <td>Domestic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text  \\\n",
       "0      1                        an exotic payload crafted:    \n",
       "1      1  this package provides routines to construct gr...   \n",
       "2      1      ** clearly see how your habits improved over    \n",
       "3      1  ** create an individual reminder for each habi...   \n",
       "4      1                      unit of work and continuity.    \n",
       "\n",
       "          provenance convention  \n",
       "0  Manually_gathered   Domestic  \n",
       "1  Manually_gathered   Domestic  \n",
       "2  Manually_gathered   Domestic  \n",
       "3  Manually_gathered   Domestic  \n",
       "4  Manually_gathered   Domestic  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Audited Data'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>provenance</th>\n",
       "      <th>convention</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The system computes color, motion, and shape c...</td>\n",
       "      <td>Semantic Scholar</td>\n",
       "      <td>inspired</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>To behave in a socially compliant way, robots ...</td>\n",
       "      <td>Semantic Scholar</td>\n",
       "      <td>inspired</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Extraterrestrial drilling is an important samp...</td>\n",
       "      <td>Semantic Scholar</td>\n",
       "      <td>inspired</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I am Srivatsan Srinivasan (I know!</td>\n",
       "      <td>Semantic Scholar</td>\n",
       "      <td>inspired</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We demonstrate how the task priorities can be ...</td>\n",
       "      <td>Semantic Scholar</td>\n",
       "      <td>inspired</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text        provenance  \\\n",
       "0  The system computes color, motion, and shape c...  Semantic Scholar   \n",
       "1  To behave in a socially compliant way, robots ...  Semantic Scholar   \n",
       "2  Extraterrestrial drilling is an important samp...  Semantic Scholar   \n",
       "3                 I am Srivatsan Srinivasan (I know!  Semantic Scholar   \n",
       "4  We demonstrate how the task priorities can be ...  Semantic Scholar   \n",
       "\n",
       "  convention  label  \n",
       "0   inspired      0  \n",
       "1   inspired      0  \n",
       "2   inspired      1  \n",
       "3   inspired      0  \n",
       "4   inspired      0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Gathered Data'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>provenance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>react can also render on the server using node...</td>\n",
       "      <td>Github</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b open source society university path to a fre...</td>\n",
       "      <td>Github</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the curriculum is designed as follows - intro ...</td>\n",
       "      <td>Github</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>all or nearly all course material prior to pro...</td>\n",
       "      <td>Github</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>please check our frequently asked questions, a...</td>\n",
       "      <td>Github</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text provenance\n",
       "0  react can also render on the server using node...     Github\n",
       "1  b open source society university path to a fre...     Github\n",
       "2  the curriculum is designed as follows - intro ...     Github\n",
       "3  all or nearly all course material prior to pro...     Github\n",
       "4  please check our frequently asked questions, a...     Github"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Gathered Data from files'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['gathered_github_sentences.tsv',\n",
       " 'gathered_green_test.tsv',\n",
       " 'gathered_news_sentences.tsv',\n",
       " 'gathered_pdf_green_AIFORSUSTAINABLEINTELIGENTBUILDINGS.tsv',\n",
       " 'gathered_pdf_green_Harnessing_Artificial_Intelligence_for_the_Earth_report_2018.tsv',\n",
       " 'gathered_pdf_green_introduction_to_the_green_economy_approach.tsv',\n",
       " 'gathered_s2_17-19_ki_kw.tsv']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display (\"Training Data\", training_df.head())\n",
    "print (\"\")\n",
    "display (\"Audited Data\", audited_data_df.head())\n",
    "print (\"\")\n",
    "display (\"Gathered Data\", gathered_conventions_df.head())\n",
    "print (\"\")\n",
    "display (\"Gathered Data from files\", gathered_conventions_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joining the audited daya to the training data and balancing the number of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T17:50:42.409376Z",
     "start_time": "2019-10-14T17:50:41.988217Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CALLING METHOD TO BALANCE LABELS\n",
      "domestic\n",
      "label 0: 354\n",
      "label 1: 182\n",
      "Training data size:  6730\n",
      "Excess of label 0 by: 172\n",
      "Balancing df to remove:  172\n",
      "num of index to rem: 172\n",
      "Training data size after removal:  6558\n",
      "\n",
      "civic\n",
      "label 0: 327\n",
      "label 1: 233\n",
      "Training data size:  6558\n",
      "Excess of label 0 by: 94\n",
      "Balancing df to remove:  94\n",
      "num of index to rem: 94\n",
      "Training data size after removal:  6464\n",
      "\n",
      "project\n",
      "label 0: 605\n",
      "label 1: 315\n",
      "Training data size:  6464\n",
      "Excess of label 0 by: 290\n",
      "Balancing df to remove:  290\n",
      "num of index to rem: 290\n",
      "Training data size after removal:  6174\n",
      "\n",
      "inspired\n",
      "label 0: 280\n",
      "label 1: 173\n",
      "Training data size:  6174\n",
      "Excess of label 0 by: 107\n",
      "Balancing df to remove:  107\n",
      "num of index to rem: 107\n",
      "Training data size after removal:  6067\n",
      "\n",
      "green\n",
      "label 0: 207\n",
      "label 1: 787\n",
      "Training data size:  6067\n",
      "Excess of label 1 by:  580\n",
      "Balancing df to add:  580\n",
      "Training data size after addition:  6647\n",
      "\n",
      "market\n",
      "label 0: 675\n",
      "label 1: 289\n",
      "Training data size:  6647\n",
      "Excess of label 0 by: 386\n",
      "Balancing df to remove:  386\n",
      "num of index to rem: 386\n",
      "Training data size after removal:  6261\n",
      "\n",
      "industrial\n",
      "label 0: 1141\n",
      "label 1: 671\n",
      "Training data size:  6261\n",
      "Excess of label 0 by: 470\n",
      "Balancing df to remove:  470\n",
      "num of index to rem: 470\n",
      "Training data size after removal:  5791\n",
      "\n",
      "renown\n",
      "label 0: 337\n",
      "label 1: 154\n",
      "Training data size:  5791\n",
      "Excess of label 0 by: 183\n",
      "Balancing df to remove:  183\n",
      "num of index to rem: 183\n",
      "Training data size after removal:  5608\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'original crosstab'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>convention</th>\n",
       "      <th>civic</th>\n",
       "      <th>domestic</th>\n",
       "      <th>green</th>\n",
       "      <th>industrial</th>\n",
       "      <th>inspired</th>\n",
       "      <th>market</th>\n",
       "      <th>project</th>\n",
       "      <th>renown</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>327</td>\n",
       "      <td>354</td>\n",
       "      <td>207</td>\n",
       "      <td>1141</td>\n",
       "      <td>280</td>\n",
       "      <td>675</td>\n",
       "      <td>605</td>\n",
       "      <td>337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>233</td>\n",
       "      <td>182</td>\n",
       "      <td>787</td>\n",
       "      <td>671</td>\n",
       "      <td>173</td>\n",
       "      <td>289</td>\n",
       "      <td>315</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "convention  civic  domestic  green  industrial  inspired  market  project  \\\n",
       "label                                                                       \n",
       "0             327       354    207        1141       280     675      605   \n",
       "1             233       182    787         671       173     289      315   \n",
       "\n",
       "convention  renown  \n",
       "label               \n",
       "0              337  \n",
       "1              154  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'new crosstab'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>convention</th>\n",
       "      <th>civic</th>\n",
       "      <th>domestic</th>\n",
       "      <th>green</th>\n",
       "      <th>industrial</th>\n",
       "      <th>inspired</th>\n",
       "      <th>market</th>\n",
       "      <th>project</th>\n",
       "      <th>renown</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>233</td>\n",
       "      <td>182</td>\n",
       "      <td>787</td>\n",
       "      <td>671</td>\n",
       "      <td>173</td>\n",
       "      <td>289</td>\n",
       "      <td>315</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>233</td>\n",
       "      <td>182</td>\n",
       "      <td>787</td>\n",
       "      <td>671</td>\n",
       "      <td>173</td>\n",
       "      <td>289</td>\n",
       "      <td>315</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "convention  civic  domestic  green  industrial  inspired  market  project  \\\n",
       "label                                                                       \n",
       "0             233       182    787         671       173     289      315   \n",
       "1             233       182    787         671       173     289      315   \n",
       "\n",
       "convention  renown  \n",
       "label               \n",
       "0              154  \n",
       "1              154  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Create a consolidated new Training_data with the Audited and original training data merged\n",
    "new_training_data_df =  pd.concat([training_df, audited_data_df], sort=True) \n",
    "#conv_lower_case = new_training_data_df.convention.str.lower()\n",
    "new_training_data_df['convention'] = new_training_data_df['convention'].str.lower() \n",
    "\n",
    "\n",
    "def create_label_balance (new_training_data_df):\n",
    "    new_training_data_df = new_training_data_df\n",
    "    new_training_data_df = new_training_data_df.reset_index()\n",
    "    \n",
    "    #Must ensure that for each convention there is an even balance of 0 and 1 labels\n",
    "    counts = pd.crosstab(new_training_data_df['label'],new_training_data_df['convention'])\n",
    "    conv_list = new_training_data_df.convention.unique()\n",
    "    conv_label_0 = []\n",
    "    conv_label_1 = []\n",
    "    # we should have the same amount of label 0 as label 1.\n",
    "    # if we have too many 1,s we can fill with 0(not_convention)\n",
    "    for conv in conv_list:\n",
    "        print (conv)\n",
    "        print (\"label 0:\",counts[conv][0] )\n",
    "        print (\"label 1:\",counts[conv][1] )\n",
    "        conv_label_0.append(counts[conv][0])\n",
    "        conv_label_1.append(counts[conv][1])\n",
    "        excessOne = (counts[conv][1] - counts[conv][0])\n",
    "        excessZero = (counts[conv][0] - counts[conv][1])\n",
    "        if (excessZero > 0):\n",
    "            print (\"Training data size: \", new_training_data_df.shape[0])\n",
    "            print (\"Excess of label 0 by:\", excessZero)\n",
    "             #As there is excess of label 0 we can remove excessZero num of label 0's for this conventions.\n",
    "            balance = new_training_data_df[(new_training_data_df['convention'] == conv) & (new_training_data_df['label']== 0)].sample(n=excessZero)\n",
    "            #display(balance.head(5))\n",
    "            print (\"Balancing df to remove: \", balance.shape[0])\n",
    "            print (\"num of index to rem:\", len(balance.index))\n",
    "            new_training_data_df = new_training_data_df.drop(balance.index)\n",
    "            print (\"Training data size after removal: \", new_training_data_df.shape[0])\n",
    "         \n",
    "        if (excessOne > 0):\n",
    "            print (\"Training data size: \", new_training_data_df.shape[0])\n",
    "            print (\"Excess of label 1 by: \", excessOne )\n",
    "            #As there is excess of label 1 we can add additional label 0's from the other conventions.\n",
    "            balance = new_training_data_df[(new_training_data_df['convention'] != conv) & (new_training_data_df['label']== 1)].sample(n=excessOne)\n",
    "            #now we should convert thos to convention = {convention} and label = 0.\n",
    "            balance['convention'] = conv\n",
    "            balance['label'] = 0\n",
    "            #display(balance.head(5))\n",
    "            #then concatenate this to the new_training_data_df\n",
    "            print (\"Balancing df to add: \", balance.shape[0])\n",
    "            new_training_data_df =  pd.concat([new_training_data_df, balance], sort=True) \n",
    "            print (\"Training data size after addition: \", new_training_data_df.shape[0])\n",
    "        print(\"\")\n",
    "        \n",
    "\n",
    "    return new_training_data_df, counts\n",
    "\n",
    "print (\"CALLING METHOD TO BALANCE LABELS\")\n",
    "new_training_data_df, cross_tab_before = create_label_balance (new_training_data_df)\n",
    "display(\"original crosstab\", cross_tab_before)\n",
    "counts = pd.crosstab(new_training_data_df['label'],new_training_data_df['convention'])\n",
    "display(\"new crosstab\", counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T17:50:41.437439Z",
     "start_time": "2019-10-14T17:43:12.687Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Read the glove word-embedding to obtain the embeddings_index \n",
    "embeddings_index = parsing_helpers.read_glove_embeddings(paths.GLOVE_DIR_LOCAL, model_helpers.EMBEDDING_DIM)\n",
    "stopwords = parsing_helpers.get_stop_words(paths.STOP_WORDS_DIR_FILE_LOCAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the embeddings and the stop words for the model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T17:50:41.620783Z",
     "start_time": "2019-10-14T17:43:16.289Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "column_to_tokenize = 'text'\n",
    "gathered_and_training = pd.DataFrame(gathered_conventions_df[column_to_tokenize].append(training_df[column_to_tokenize]))##Adding training data sentences\n",
    "extended_tokenizer = parsing_helpers.create_tokenizer(gathered_and_training, column_to_tokenize, max_words=model_helpers.MAX_NB_WORDS)\n",
    "display (type (gathered_and_training))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-14T12:42:32.371Z"
    }
   },
   "outputs": [],
   "source": [
    "EXECUTE_EXAMPLE = True\n",
    "if EXECUTE_EXAMPLE: #### JUST TO AVOID EXECUTING THIS CELL EVERY TIME\n",
    "\n",
    "    NUM_SENTENCES_TO_SHOW=10\n",
    "    #################################################\n",
    "    ## Example of how to use the models helper files\n",
    "    #################################################\n",
    "    display (training_df.head(3))\n",
    "    ## This is done as example, test dataframe should be readed from a diferent file!\n",
    "    test_df = training_df\n",
    "\n",
    "    ## Tokenizer was already trained!\n",
    "    assert(extended_tokenizer is not None)\n",
    "\n",
    "\n",
    "    ## Train DL models\n",
    "\n",
    "    _DLModels, _DLTokenizers, _DLData_val_x, _DLData_val_y, _DLTrain_histories = model_helpers.train_DL_models(df_train,\n",
    "                    data_class_column=\"convention\", \n",
    "                    data_label_column=\"label\",\n",
    "                    tokenizer=extended_tokenizer,\n",
    "                    random_seed=0,\n",
    "                    use_validation=False) \n",
    "\n",
    "    ## Train ML models\n",
    "    _MLModels = model_helpers.train_ML_models(df_train) \n",
    "\n",
    "    ##Getting sentences from data\n",
    "    test_sentences = test_df['text'].values\n",
    "\n",
    "    ## Calculate probability scores for for text data combining DL predictions and ML predictions\n",
    "    mixture_preds = model_helpers.calculate_matches_mixture(test_sentences, _MLModels, _DLModels, _DLTokenizers)\n",
    "\n",
    "    ## Getting top sentences per convention\n",
    "    for conv in _MLModels.keys():\n",
    "        print(\"\\n\\n     {}    \\n\\n\".format(conv))\n",
    "        for s in test_sentences[mixture_preds[conv].argsort()[-NUM_SENTENCES_TO_SHOW:][::-1]]:\n",
    "            print(\"{}\\n\".format(test_sentences[s]))\n",
    "            \n",
    "            \n",
    "    ## Store DL models in a pickle file\n",
    "    model_helpers.store_DL_models_in_picke(\"test.pickle\", _DLModels, _DLTokenizers, _DLData_val_x, _DLData_val_y, _DLTrain_histories, paths.PICKLED_MODELS_DIR)\n",
    "    \n",
    "    ## Read DL models from a pickle file\n",
    "    _DLModels, _DLTokenizers, _DLData_val_x, _DLData_val_y, _DLTrain_histories = model_helpers.read_pickle(\"test.pickle\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-14T12:42:32.375Z"
    }
   },
   "outputs": [],
   "source": [
    "CONVENTION = \"Green\"\n",
    "df = training_df[training_df['convention'] == CONVENTION]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-14T12:42:32.381Z"
    }
   },
   "outputs": [],
   "source": [
    "## Checking performance setting validation data on the model training\n",
    "## Validation data is created inside the models trainign function\n",
    "conv_models = model_helpers.train_DL_models(df,\n",
    "            data_class_column=\"convention\", \n",
    "            data_label_column=\"label\",\n",
    "            df_val=None,\n",
    "            tokenizer=extended_tokenizer,\n",
    "            random_seed=0, \n",
    "            use_validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-14T12:42:32.388Z"
    }
   },
   "outputs": [],
   "source": [
    "## Checking performance setting validation data on the model training\n",
    "## Validation data is created outside the models trainign function\n",
    "## Training models\n",
    "texts = df['text'].values\n",
    "labels = df['label'].values\n",
    "\n",
    "indices = np.arange(len(texts))\n",
    "np.random.seed(0)\n",
    "np.random.shuffle(indices)\n",
    "texts = texts[indices]\n",
    "labels = labels[indices]\n",
    "nb_validation_samples = int(VALIDATION_SPLIT * len(texts))\n",
    "\n",
    "x_train = texts[:-nb_validation_samples]\n",
    "y_train = labels[:-nb_validation_samples]\n",
    "x_val = texts[-nb_validation_samples:]\n",
    "y_val = labels[-nb_validation_samples:]\n",
    "\n",
    "df_train = pd.DataFrame(columns=['text', 'label', 'convention'])\n",
    "df_train['text'] = x_train\n",
    "df_train['label'] = y_train\n",
    "df_train['convention'] = CONVENTION\n",
    "\n",
    "\n",
    "df_val = pd.DataFrame(columns=['text', 'label', 'convention'])\n",
    "df_val['text'] = x_val\n",
    "df_val['label'] = y_val\n",
    "df_val['convention'] = CONVENTION\n",
    "\n",
    "print(\"\\n\\n===========================\")\n",
    "print(\"WITH VALIDATION!\")\n",
    "print(\"===========================\\n\\n\")\n",
    "models2 = model_helpers.train_DL_models(df_train,\n",
    "                data_class_column=\"convention\", \n",
    "                data_label_column=\"label\",\n",
    "                df_val=df_val,\n",
    "                tokenizer=extended_tokenizer,\n",
    "                random_seed=0, use_validation=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-14T12:42:32.392Z"
    }
   },
   "outputs": [],
   "source": [
    "######################\n",
    "### Cross validation\n",
    "######################\n",
    "\n",
    "## 1. Split training, validation data outside the training function\n",
    "## 2. Train a model with training data\n",
    "## 3. Check performance (acc) of the model on training and validation\n",
    "## 4. Repeat num_tests times\n",
    "## Next cell plots results\n",
    "\n",
    "## Number of tests = 10\n",
    "num_tests = 10\n",
    "num_epochs = 20\n",
    "\n",
    "accs = []\n",
    "val_accs = []\n",
    "epochs = np.arange(0,num_epochs, 1)\n",
    "\n",
    "texts = df['text'].values\n",
    "labels = df['label'].values\n",
    "\n",
    "\n",
    "for n in range(num_tests):\n",
    "    print(\"\\n\\n=================================\")\n",
    "    print(\"               {}\".format(n))\n",
    "    print(\"=================================\")\n",
    "    indices = np.arange(len(texts))\n",
    "    np.random.shuffle(indices)\n",
    "    texts = texts[indices]\n",
    "    labels = labels[indices]\n",
    "    nb_validation_samples = int(VALIDATION_SPLIT * len(texts))\n",
    "\n",
    "    x_train = texts[:-nb_validation_samples]\n",
    "    y_train = labels[:-nb_validation_samples]\n",
    "    x_val = texts[-nb_validation_samples:]\n",
    "    y_val = labels[-nb_validation_samples:]\n",
    "\n",
    "    df_train = pd.DataFrame(columns=['text', 'label', 'convention'])\n",
    "    df_train['text'] = x_train\n",
    "    df_train['label'] = y_train\n",
    "    df_train['convention'] = CONVENTION\n",
    "\n",
    "\n",
    "    df_val = pd.DataFrame(columns=['text', 'label', 'convention'])\n",
    "    df_val['text'] = x_val\n",
    "    df_val['label'] = y_val\n",
    "    df_val['convention'] = CONVENTION\n",
    "\n",
    "\n",
    "    tmp_training = model_helpers.train_DL_models(df_train,\n",
    "                data_class_column=\"convention\", \n",
    "                data_label_column=\"label\",\n",
    "                df_val=df_val,\n",
    "                tokenizer=extended_tokenizer,\n",
    "                random_seed=0,\n",
    "                use_validation=True, \n",
    "                num_epochs = num_epochs)\n",
    "\n",
    "    accs.append(tmp_training[4][CONVENTION].history['acc'])\n",
    "    val_accs.append(tmp_training[4][CONVENTION].history['val_acc'])       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-14T12:42:32.397Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[10,10])\n",
    "fig.suptitle(\"Checking performance on multiple random data partitions\\n       ({} Convention)\".format(CONVENTION), fontsize=16)\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.subplots_adjust(wspace=0.4, hspace=0.4)\n",
    "\n",
    "\n",
    "for i in range(len(accs)):\n",
    "    plt.plot(epochs,accs[i], label=\"Test {}\".format(i))\n",
    "plt.title(\"Training accuracies per epoch\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"acc score\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "for i in range(len(val_accs)):\n",
    "    plt.plot(epochs,val_accs[i], label=\"Test {}\".format(i))\n",
    "plt.title(\"Validation accuracies per epoch\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"acc score\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-14T12:42:32.401Z"
    }
   },
   "outputs": [],
   "source": [
    "models2_tokenizer = models2[1][CONVENTION]\n",
    "val_seq = models2_tokenizer.texts_to_sequences(x_val)\n",
    "val_seq = pad_sequences(val_seq, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "preds2 = models2[0][CONVENTION].predict(val_seq)\n",
    "print(\"Real label for samples classified with value 0\")\n",
    "display(y_val[preds2[:,0]>preds2[:,1]])\n",
    "print(\"Real label for samples classified with value 1\")\n",
    "display(y_val[preds2[:,0]<preds2[:,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-14T12:42:32.409Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n\\n===========================\")    \n",
    "print(\"WITHOUT VALIDATION!\")\n",
    "print(\"===========================\\n\\n\")\n",
    "models3 = model_helpers.train_DL_models(df_train,\n",
    "                data_class_column=\"convention\", \n",
    "                data_label_column=\"label\",\n",
    "                df_val=None,\n",
    "                tokenizer = models2_tokenizer,\n",
    "                random_seed=0, use_validation=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-14T12:42:32.414Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "val_seq = models2_tokenizer.texts_to_sequences(x_val)\n",
    "val_seq = pad_sequences(val_seq, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "preds2 = models2[0][CONVENTION].predict(val_seq)\n",
    "print(\"Real label for samples classified with value 0\")\n",
    "display(y_val[preds2[:,0]>preds2[:,1]])\n",
    "print(\"Real label for samples classified with value 1\")\n",
    "display(y_val[preds2[:,0]<preds2[:,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-14T12:42:32.419Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "tok1 = parsing_helpers.create_tokenizer(training_df)\n",
    "word_index = tok1.word_index\n",
    "tok1_words = []\n",
    "for word, i in word_index.items():\n",
    "    tok1_words.append(word)\n",
    "\n",
    "for idx, _df in enumerate(gathered_dfs[:-1]):\n",
    "    tok2 = parsing_helpers.create_tokenizer(_df)\n",
    "    word_index2 = tok2.word_index\n",
    "\n",
    "    gathered_f = gathered_data_files[idx]\n",
    "\n",
    "    tok2_words = []\n",
    "    for word, i in word_index2.items():\n",
    "        tok2_words.append(word)\n",
    "\n",
    "    words_in_tok1 = [w for w in tok2_words if w in tok1_words]\n",
    "    tok1_words_in_tok2 = [w for w in tok1_words if w in tok2_words]\n",
    "    print(\"\\n > {}\".format(gathered_f))\n",
    "    print(\"Gathered source words in training data: {}\".format(len(words_in_tok1) / len(tok1_words)))\n",
    "    print(\"Training data words in gathered source: {}\".format(len(tok1_words_in_tok2) / len(tok2_words)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-14T12:42:32.426Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "NUM_SENTENCES_TO_SHOW=10\n",
    "\n",
    "df_test = pd.read_csv(os.path.join(paths.GATHERED_DATA_CONV_DIR_LOCAL, \"gathered_github_sentences.tsv\"), sep=\"\\t\")\n",
    "\n",
    "test_sentences = df_test['sentence'].values\n",
    "\n",
    "test_seq = extended_tokenizer.texts_to_sequences(test_sentences)\n",
    "test_seq = pad_sequences(val_seq, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "preds = conv_models[0][CONVENTION].predict(test_seq)[:,1]\n",
    "\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(\" >> Top sentences with higher confidence for Github:\")\n",
    "print(\"            ({} convention)\".format(CONVENTION))\n",
    "print(\"-----------------------------------------------------\\n\")\n",
    "for s in test_sentences[preds.argsort()[-NUM_SENTENCES_TO_SHOW:][::-1]]:\n",
    "    print(\"{}\\n\".format(s))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-14T12:42:32.430Z"
    }
   },
   "outputs": [],
   "source": [
    "### Ading more green examples\n",
    "green_audit_df = pd.read_csv(\"Data/Iterative-models-building/Classification results/Conventions/Audited/audited_ALL_2019-10-08-20:23:58.598102.tsv\", sep=\"\\t\")\n",
    "green_audit_df = green_audit_df[['text', 'provenance', 'convention', 'new']]\n",
    "green_audit_df = green_audit_df.rename(columns={\"new\": \"label\"})\n",
    "green_audit_df = green_audit_df[green_audit_df['convention']=='green']\n",
    "green_audit_df['convention'] = \"Green\"\n",
    "green_audit_df.head(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-14T12:42:32.434Z"
    }
   },
   "outputs": [],
   "source": [
    "green_df = pd.concat([df, green_audit_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-14T12:42:32.438Z"
    }
   },
   "outputs": [],
   "source": [
    "######################\n",
    "### Cross validation with new data\n",
    "######################\n",
    "\n",
    "## 1. Split training, validation data outside the training function\n",
    "## 2. Train a model with training data\n",
    "## 3. Check performance (acc) of the model on training and validation\n",
    "## 4. Repeat num_tests times\n",
    "## Next cell plots results\n",
    "\n",
    "## Number of tests = 10\n",
    "num_tests = 10\n",
    "num_epochs = 20\n",
    "\n",
    "accs2 = []\n",
    "val_accs2 = []\n",
    "epochs = np.arange(0,num_epochs, 1)\n",
    "\n",
    "texts = green_df['text'].values\n",
    "labels = green_df['label'].values\n",
    "np.random.seed(0)\n",
    "\n",
    "for n in range(num_tests):\n",
    "    print(\"\\n\\n=================================\")\n",
    "    print(\"               {}\".format(n))\n",
    "    print(\"=================================\")\n",
    "    indices = np.arange(len(texts))\n",
    "\n",
    "    np.random.shuffle(indices)\n",
    "    texts = texts[indices]\n",
    "    labels = labels[indices]\n",
    "    nb_validation_samples = int(VALIDATION_SPLIT * len(texts))\n",
    "\n",
    "    x_train = texts[:-nb_validation_samples]\n",
    "    y_train = labels[:-nb_validation_samples]\n",
    "    x_val = texts[-nb_validation_samples:]\n",
    "    y_val = labels[-nb_validation_samples:]\n",
    "\n",
    "    df_train = pd.DataFrame(columns=['text', 'label', 'convention'])\n",
    "    df_train['text'] = x_train\n",
    "    df_train['label'] = y_train\n",
    "    df_train['convention'] = CONVENTION\n",
    "\n",
    "\n",
    "    df_val = pd.DataFrame(columns=['text', 'label', 'convention'])\n",
    "    df_val['text'] = x_val\n",
    "    df_val['label'] = y_val\n",
    "    df_val['convention'] = CONVENTION\n",
    "\n",
    "\n",
    "    tmp_training = model_helpers.train_DL_models(df_train,\n",
    "                data_class_column=\"convention\", \n",
    "                data_label_column=\"label\",\n",
    "                df_val=df_val,\n",
    "                tokenizer=extended_tokenizer,\n",
    "                random_seed=0,\n",
    "                use_validation=True, \n",
    "                num_epochs = num_epochs)\n",
    "\n",
    "    accs2.append(tmp_training[4][CONVENTION].history['acc'])\n",
    "    val_accs2.append(tmp_training[4][CONVENTION].history['val_acc'])       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-14T12:42:32.442Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[10,10])\n",
    "fig.suptitle(\"Checking performance on multiple random data partitions\\n       ({} Convention)\".format(CONVENTION), fontsize=16)\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.subplots_adjust(wspace=0.4, hspace=0.4)\n",
    "\n",
    "\n",
    "for i in range(len(accs)):\n",
    "    plt.plot(epochs,accs2[i], label=\"Test {}\".format(i))\n",
    "plt.title(\"Training accuracies per epoch\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"acc score\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "for i in range(len(val_accs)):\n",
    "    plt.plot(epochs,val_accs2[i], label=\"Test {}\".format(i))\n",
    "plt.title(\"Validation accuracies per epoch\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"acc score\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-14T12:42:32.445Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Checking performance setting validation data on the model training\n",
    "## Validation data is created inside the models trainign function\n",
    "conv_models2 = model_helpers.train_DL_models(green_df,\n",
    "            data_class_column=\"convention\", \n",
    "            data_label_column=\"label\",\n",
    "            df_val=None,\n",
    "            tokenizer=extended_tokenizer,\n",
    "            random_seed=0, \n",
    "            use_validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-14T12:42:32.449Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "NUM_SENTENCES_TO_SHOW=20\n",
    "\n",
    "df_test = pd.read_csv(os.path.join(GATHERED_DATA_FOLDER, \"gathered_github_sentences.tsv\"), sep=\"\\t\")\n",
    "\n",
    "test_sentences = df_test['sentence'].values\n",
    "test_sentences = np.array([sent for sent in test_sentences if len(sent.split(\" \"))<40])\n",
    "\n",
    "test_seq = extended_tokenizer.texts_to_sequences(test_sentences)\n",
    "test_seq = pad_sequences(test_seq, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "preds = conv_models2[0][CONVENTION].predict(test_seq)[:,1]\n",
    "\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(\" >> DL model results\")\n",
    "print(\" >> Top sentences with higher confidence for Github:\")\n",
    "print(\"            ({} convention)\".format(CONVENTION))\n",
    "print(\"-----------------------------------------------------\\n\")\n",
    "for s in test_sentences[preds.argsort()[-NUM_SENTENCES_TO_SHOW:][::-1]]:\n",
    "    print(\"{}\\n\".format(s))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-14T12:42:32.455Z"
    }
   },
   "outputs": [],
   "source": [
    "_DLModels = conv_models2[0]\n",
    "_DLTokenizers = conv_models2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-14T12:42:32.460Z"
    }
   },
   "outputs": [],
   "source": [
    "_MLModels = model_helpers.train_ML_models(green_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-14T12:42:32.463Z"
    }
   },
   "outputs": [],
   "source": [
    "test_sentences = df_test['sentence'].values\n",
    "\n",
    "mixture_preds = model_helpers.calculate_matches_mixture(test_sentences, _MLModels, _DLModels, _DLTokenizers)\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(\" >> Mixture model results\")\n",
    "print(\" >> Top sentences with higher confidence for Github:\")\n",
    "print(\"            ({} convention)\".format(CONVENTION))\n",
    "print(\"-----------------------------------------------------\\n\")\n",
    "for s in test_sentences[mixture_preds[CONVENTION].argsort()[-NUM_SENTENCES_TO_SHOW:][::-1]]:\n",
    "    print(\"{}\\n\".format(s))\n",
    "    \n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
