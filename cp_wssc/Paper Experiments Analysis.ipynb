{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T19:11:07.935610Z",
     "start_time": "2020-01-13T19:11:06.707536Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Necessary libraries imported.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArMAAABLCAYAAABjuQ9GAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAAvpJREFUeJzt3b+rjnEcxvHPfRJhUhgMfg6ELPwnNn/AMVlsNpLJIMlikrIYDcqGDIpFyaRYHKeTEzl08qNui8XCOae+fc91n9dre+oers/wPL2Hu55hHMcCAIBEM70HAADAWolZAABiiVkAAGKJWQAAYolZAABiiVkAAGKJWQAAYolZAABiiVkAAGJt+t8DwzDMVtVsVdWWrdtO7tl/qPmoXt5/Wu49oam9u6Z739zSYu8JTR0Zd/ee0NTPuQ+9JzS1+cCO3hPaWlrovaCpb9uP9Z7QzOL8194Tmtp7eNr/cvr57XS/ewtff9aX77+GlTw7rObvbA8ePTFeuftgzcPWuwv3Xvae0NSNs697T2jm0uM7vSc09ezHud4Tmpq/eLn3hKb23D3de0JTM4+u957Q1POT0/3tvH31ae8JTd18Mu2YvX/mWu8JzZx/+K7eLC6vKGa9ZgAAQCwxCwBALDELAEAsMQsAQCwxCwBALDELAEAsMQsAQCwxCwBALDELAEAsMQsAQCwxCwBALDELAEAsMQsAQCwxCwBALDELAEAsMQsAQCwxCwBALDELAEAsMQsAQCwxCwBALDELAEAsMQsAQCwxCwBALDELAEAsMQsAQCwxCwBALDELAEAsMQsAQCwxCwBALDELAEAsMQsAQCwxCwBALDELAEAsMQsAQCwxCwBALDELAEAsMQsAQCwxCwBALDELAEAsMQsAQCwxCwBALDELAEAsMQsAQCwxCwBALDELAEAsMQsAQCwxCwBALDELAEAsMQsAQCwxCwBALDELAEAsMQsAQKxhHMd/PzAMs1U1++fj8ap61XpURzur6mPvEY1M+bYq96VzX64p31blvnTuy7VvHMddK3nwvzH718PD8GIcx1NrnrXOTfm+Kd9W5b507ss15duq3JfOfRuD1wwAAIglZgEAiLXamL3VZMX6MeX7pnxblfvSuS/XlG+rcl86920Aq3pnFgAA1hOvGQAAEEvMAgAQS8wCABBLzAIAEEvMAgAQ6zc7qY697nWb7gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised generic_parsing_helpers class and methods\n",
      "Initialised AIVM_helper class and methods\n",
      "Initialised model_helpers class and methods\n"
     ]
    }
   ],
   "source": [
    "%run \"All_helper_classes.ipynb\" sort=False\n",
    "\n",
    "#from \"Models training helpers.ipynb\" we will import 3 helper classes and the associated helper methods.\n",
    "parsing_helpers = generic_parsing_helpers()\n",
    "aivm_helper = AIVM_helper()\n",
    "model_helpers, info = default_model_helpers_for_project()\n",
    "#if you want to see the paths now can call with...\n",
    "# # display (HTML(info))\n",
    "\n",
    "paths = project_paths()\n",
    "\n",
    "# generate random integer values\n",
    "from random import seed\n",
    "from random import randint\n",
    "# seed random number generator\n",
    "seed(1)\n",
    "#same for paths and repo data, display using...\n",
    "# display (HTML(paths.get_paths_data()))\n",
    "# display (HTML(paths.get_repo_data()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T18:32:37.470037Z",
     "start_time": "2020-01-13T18:32:37.457358Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "//To remove scroll from any output area and automatically extend the jupyter cell\n",
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "//To remove scroll from any output area and automatically extend the jupyter cell\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First we will retrieve the most recently trained DL Models, Calibration Models and the Threshold.\n",
    "these have been stored in the \"Resource\" directory of Git as a pickle file.\n",
    "        * global_final_thresholds.pickle\n",
    "        * {conv}_models.pickle\n",
    "        * {conv}_calibration_model.pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T18:33:36.112673Z",
     "start_time": "2020-01-13T18:32:45.386116Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'civic': 0.5,\n",
       " 'domestic': 0.5,\n",
       " 'green': 0.5,\n",
       " 'industrial': 0.5,\n",
       " 'inspired': 0.5,\n",
       " 'market': 0.5,\n",
       " 'project': 0.5,\n",
       " 'renown': 0.5}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading  civic\n",
      "Reading  domestic\n",
      "Reading  green\n",
      "Reading  industrial\n",
      "Reading  inspired\n",
      "Reading  market\n",
      "Reading  project\n",
      "Reading  renown\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'civic': {'model': <keras.engine.training.Model at 0x13689c908>},\n",
       " 'domestic': {'model': <keras.engine.training.Model at 0x142bc2358>},\n",
       " 'green': {'model': <keras.engine.training.Model at 0x10e3b4080>},\n",
       " 'industrial': {'model': <keras.engine.training.Model at 0x14b92e2e8>},\n",
       " 'inspired': {'model': <keras.engine.training.Model at 0x14b92e470>},\n",
       " 'market': {'model': <keras.engine.training.Model at 0x142bc24e0>},\n",
       " 'project': {'model': <keras.engine.training.Model at 0x13c89f978>},\n",
       " 'renown': {'model': <keras.engine.training.Model at 0x13c89fa58>}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading  civic\n",
      "Reading  domestic\n",
      "Reading  green\n",
      "Reading  industrial\n",
      "Reading  inspired\n",
      "Reading  market\n",
      "Reading  project\n",
      "Reading  renown\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'civic': {'model': IsotonicRegression(increasing=True, out_of_bounds='clip', y_max=None,\n",
       "                     y_min=None)},\n",
       " 'domestic': {'model': IsotonicRegression(increasing=True, out_of_bounds='clip', y_max=None,\n",
       "                     y_min=None)},\n",
       " 'green': {'model': IsotonicRegression(increasing=True, out_of_bounds='clip', y_max=None,\n",
       "                     y_min=None)},\n",
       " 'industrial': {'model': IsotonicRegression(increasing=True, out_of_bounds='clip', y_max=None,\n",
       "                     y_min=None)},\n",
       " 'inspired': {'model': IsotonicRegression(increasing=True, out_of_bounds='clip', y_max=None,\n",
       "                     y_min=None)},\n",
       " 'market': {'model': IsotonicRegression(increasing=True, out_of_bounds='clip', y_max=None,\n",
       "                     y_min=None)},\n",
       " 'project': {'model': IsotonicRegression(increasing=True, out_of_bounds='clip', y_max=None,\n",
       "                     y_min=None)},\n",
       " 'renown': {'model': IsotonicRegression(increasing=True, out_of_bounds='clip', y_max=None,\n",
       "                     y_min=None)}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'tokenizer': <keras_preprocessing.text.Tokenizer at 0x143f9cfd0>}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Read the latest models/Tresholds etc from GIT \"Resource\" directory.\n",
    "USE_GIT_HUB = False\n",
    "GIT_USR = 'aideenf'\n",
    "GIT_PSWD = 'aid00rk5'\n",
    "\n",
    "AI_GITHUB = \"Data/ToBeAnalyzed/github_AI_repos_dump.csv\"\n",
    "REDDIT_AI = \"Data/ToBeAnalyzed/reddit_data_all.csv\"\n",
    "SS  = \"Data/ToBeAnalyzed/s2_sents_ki_ids_23k.tsv\"\n",
    "# NON_AI_GITHUB = \"Data/ToBeAnalyzed/github_non_AI_repos_dump.csv\"\n",
    "# SEM_SCHOLAR = \"\"\n",
    "\n",
    "\n",
    "AI_GITHUB_GIT = \"https://github.com/aideenf/AIVC/blob/master/cp_wssc/Data/ToBeAnalyzed/github_AI_repos_dump.csv?raw=true\"\n",
    "REDDIT_AI_GIT = \"https://github.com/aideenf/AIVC/blob/master/cp_wssc/Data/ToBeAnalyzed/reddit_data_all.csv?raw=true\"\n",
    "SS_GIT = \"https://github.com/aideenf/AIVC/blob/master/cp_wssc/Data/ToBeAnalyzed/s2_sents_ki_ids_23k.tsv?raw=true\"\n",
    "\n",
    "\n",
    "# NON_AI_GITHUB_GIT = \"https://github.com/aideenf/AIVC/blob/master/cp_wssc/Data/ToBeAnalyzed/github_AI_repos_dump.csv?raw=true\"\n",
    "# NON_AI_REDDIT_GIT = \"https://github.com/aideenf/AIVC/blob/master/cp_wssc/Data/ToBeAnalyzed/reddit_data_all.csv?raw=true\"\n",
    "# NON_AI_SS_GIT = \"https://github.com/aideenf/AIVC/blob/master/cp_wssc/Data/ToBeAnalyzed/s2_sents_ki_ids_23k.tsv?raw=true\"\n",
    "\n",
    "# NON_AI_GITHUB_GIT = \"Data/ToBeAnalyzed/github_non_AI_repos_dump.csv\"\n",
    "# SEM_SCHOLAR_GIT = \"\"\n",
    "\n",
    "\n",
    "_DLModelsIsotonicRegression = {}\n",
    "_DLModels = {}\n",
    "_thresholds = {}\n",
    "_tokenizer = \"\"\n",
    "\n",
    "_thresholds = model_helpers.read_thresholds_from_pickle(USE_GIT_HUB)\n",
    "display(_thresholds)\n",
    "\n",
    "\n",
    "\n",
    "_DLModels = model_helpers.read_models_from_pickle(USE_GIT_HUB, _thresholds )\n",
    "display(_DLModels)\n",
    "\n",
    "_DLModelsIsotonicRegression = model_helpers.read_calibration_models_from_pickle(USE_GIT_HUB, _thresholds)\n",
    "display(_DLModelsIsotonicRegression)\n",
    "\n",
    "_tokenizer = model_helpers.read_tokenizer_from_pickle(USE_GIT_HUB)\n",
    "display (_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T19:49:06.581770Z",
     "start_time": "2020-01-13T19:49:06.219539Z"
    }
   },
   "outputs": [],
   "source": [
    "# This method will use the trained classification and calibration models to predict and quantify \n",
    "# the presence of conventions in new data(the data to be analyzed)\n",
    " \n",
    "def predict_scores_and_classify(thresholds_in, to_predict_df, _tokenizer, _DLModels, _DLModelsIsotonicRegression, seq_len):\n",
    "    \n",
    "    predict = True\n",
    "     \n",
    "    extended_tokenizer = _tokenizer\n",
    " \n",
    "    \n",
    "    #Replacing R_BODY in the cases with reddit body defined.\n",
    "    sequences = extended_tokenizer.texts_to_sequences(to_predict_df.copy()['text'].str.replace('R_BODY', ''))\n",
    "    data = pad_sequences(sequences, maxlen= seq_len) \n",
    "    extended_tokenizer = 0\n",
    "    sequences = 0\n",
    "    gc.collect()\n",
    "    \n",
    "\n",
    "    \n",
    "    thresholds = {'civic': 0.5,\n",
    "                  'domestic': 0.5,\n",
    "                  'green': 0.5,\n",
    "                  'industrial': 0.5,\n",
    "                  'inspired': 0.5,\n",
    "                  'market': 0.5,\n",
    "                  'project': 0.5,\n",
    "                  'renown': 0.5}\n",
    "    # otherwise use default.\n",
    "    \n",
    "    if thresholds_in != None:\n",
    "        thresholds = thresholds_in\n",
    "       \n",
    "    column_list = []\n",
    "    column_list.append(\"repo_id\")\n",
    "    column_list.append(\"text\")\n",
    "    column_list.append(\"repo\")\n",
    "    \n",
    "    for conv in _DLModels.keys():\n",
    "        column_list.append(conv)\n",
    "        column_list.append(conv+\"_prob\")\n",
    "        column_list.append(conv+\"_y_pred\")\n",
    "        column_list.append(conv+\"_prob_1\")\n",
    "        \n",
    "    df = pd.DataFrame(columns=column_list)\n",
    "    all_df = pd.DataFrame(columns=column_list)\n",
    "    \n",
    "    ###################\n",
    "    #a sub function within the function, just used in this scope \n",
    "    def sub_funct_get_prob(prob, y):\n",
    "        res = []\n",
    "        for (probability, predicted) in zip(prob, y):\n",
    "            if predicted == 1:\n",
    "                res.append(probability)\n",
    "            if predicted == 0:\n",
    "                res.append(1 - probability)\n",
    "        return res\n",
    "    ####################\n",
    "\n",
    "    df = pd.DataFrame(columns=column_list)\n",
    "    \n",
    "    #get the the txt of the sentence to be Analyzed\n",
    "    df['text'] = to_predict_df[\"text\"]\n",
    "    df['repo_id'] = to_predict_df[\"repo_id\"]\n",
    "    df['repo'] = to_predict_df[\"repo\"]\n",
    "\n",
    "        \n",
    "\n",
    "    for model in _DLModels.keys():\n",
    "        my_model = _DLModels[model]           \n",
    "        #First through the model\n",
    "        y_predict = my_model['model'].predict(data)\n",
    "                \n",
    "        #get the score for value = 1 as the response is [x,y] we need only the y values\n",
    "        y_pos_predict_prob = model_helpers.get_positive_preds_probabilities(y_predict)\n",
    "                \n",
    "        #get the 1 or 0 value depending on the threshold\n",
    "        y_pred = model_helpers.get_positive_preds_with_threshold(y_pos_predict_prob, thresholds[model])\n",
    "                \n",
    "        #if the call has been made with an isotonic reg calibration model too then call its predict.\n",
    "        if _DLModelsIsotonicRegression != None:\n",
    "            other_ir = _DLModelsIsotonicRegression[model]\n",
    "            y_pos_predict_isotonic_prob = other_ir['model'].predict(y_pos_predict_prob)\n",
    "            y_pred = model_helpers.get_positive_preds_with_threshold(y_pos_predict_isotonic_prob, thresholds[model])\n",
    "            y_pos_predict_prob = y_pos_predict_isotonic_prob\n",
    "                \n",
    "        #The probability of the y_predict, whether it i 1 or 0\n",
    "        df[model+\"_prob\"] =  sub_funct_get_prob(y_pos_predict_prob, y_pred)\n",
    "        df[model+\"_y_pred\"] = y_pred\n",
    "        df[model+\"_prob_1\"] = y_pos_predict_prob         \n",
    "        \n",
    "   \n",
    "    y_pred_list = []\n",
    "    for x in df.columns.values:\n",
    "        if x.endswith(('_y_pred')):\n",
    "            y_pred_list.append(x)\n",
    "            \n",
    "    prob_list = []\n",
    "    conv_list = []\n",
    "    for x in df.columns.values:\n",
    "        if x.endswith(('_prob')):\n",
    "            prob_list.append(x)\n",
    "            conv_list.append(x.replace('_prob', ''))\n",
    "    \n",
    "    if predict == True:\n",
    "        #add the label cardinality as the sum of all the predicted = 1 for sentence for conventions\n",
    "        pred_sums = df[y_pred_list].sum(axis=1)\n",
    "        df['lbl_cnt'] = pred_sums\n",
    "        #add the overall score as the product of all the individual predicted convention scores\n",
    "        prob_product= all_df[prob_list].prod(axis=1)\n",
    "        df['set_conf'] = prob_product\n",
    "    \n",
    "    \n",
    "    #this will be > 1 if the same sentence was used as True for 2 or more conventions.\n",
    "    positive_sample = df[conv_list].sum(axis=1)\n",
    "    df['pos_sample'] = positive_sample\n",
    "     \n",
    "\n",
    "    #Drop any lines that are fully duplicated \n",
    "    df = df.drop_duplicates(keep = \"first\")\n",
    "    print (\"Num Dupes:\", len(df.index) - len(df['text'].unique()) )\n",
    "    \n",
    "    co_occur_list = []\n",
    "    rename = []\n",
    "    for x in df.columns.values:\n",
    "            if x.endswith(('_y_pred')):\n",
    "                co_occur_list.append(x)\n",
    "                rename.append(x.replace('_y_pred', ''))\n",
    "\n",
    "    co_occur_y_predict = df[co_occur_list].copy()\n",
    "    for old, x in zip(co_occur_list, range(len(co_occur_list))): \n",
    "        co_occur_y_predict = co_occur_y_predict.rename(columns={old: rename[x]})\n",
    "        \n",
    "    plt.figure(figsize=(10,5))\n",
    "#   plt.style.use('seaborn-colorblind')\n",
    "\n",
    "        \n",
    "    text = \"Predicted Co-occurance Matrix with Predicted and Actual Cardinality \"\n",
    "    display (HTML(\"<font color = green><h3><left>\" + text + \"</left></h3></font>\"))\n",
    "    ax1 = plt.subplot(1, 2, 1)\n",
    "    ax1 = model_helpers.co_occurance_matrix (co_occur_y_predict)\n",
    "\n",
    "    ax2 = plt.subplot(1, 2, 2)\n",
    "    ax2 = model_helpers.label_cardinality_bar(co_occur_y_predict, title = \"Predicted Cardinality\") \n",
    "    plt.tight_layout()\n",
    "    plt.show() \n",
    "    \n",
    "    return df.fillna(0), thresholds\n",
    "\n",
    "\n",
    "def clean_descriptions (text, keep_case, remove_tab_line):\n",
    "    \n",
    "    # remove any line starting with a tab and ending with a space or new line.\n",
    "    if remove_tab_line == True:\n",
    "        text = re.sub(r'\\\\t.*?\\\\n', ' ', text)\n",
    "        text = re.sub(r'\\\\t.*?\\\\s', ' ', text)\n",
    "        \n",
    "    \n",
    "    \n",
    "    try:\n",
    "        #remove snippets of code\n",
    "        text = re.sub(\"```.*?```\", \" \", text)\n",
    "    except: \n",
    "        print (\"WOOOOPS:\", text)\n",
    "    \n",
    "    #https://regex101.com/r/cO8lqs/2\n",
    "    text = re.sub(\"b'\", ' ', text)\n",
    "    \n",
    "    text = re.sub(\"i\\.e\\.\", 'i.e', text)\n",
    "    text = re.sub(\"e\\.g\\.\", 'e.g', text)\n",
    "    \n",
    "    # remove anything with this format \"[![text]....\"\n",
    "    text = re.sub(r'\\[\\!.*?\\)', ' ', text)\n",
    "    \n",
    "        \n",
    "    # remove anything with this format \"([.....)).\"\n",
    "    text = re.sub(r'\\(\\[.*?\\)\\)\\.', ' ', text)\n",
    "    \n",
    "    \n",
    "    # remove anything with this format \"([.....))\"\n",
    "    text = re.sub(r'\\(\\[.*?\\)\\)', ' ', text)\n",
    "    \n",
    "    \n",
    "    #remove HTML tags\n",
    "    text = re.sub(\"(<.*?>)\",\"\",text)\n",
    "    \n",
    "    #remove URL's\n",
    "    text = re.sub(r'\\(http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text, flags=re.MULTILINE)\n",
    "\n",
    "    #remove new lines as they are not correctly formatted\n",
    "    text = text.replace('\\\\n', \" \")\n",
    "    text = text.replace('\\n', \" \")\n",
    "\n",
    "\n",
    "\n",
    "    text = text.replace(\"\\\\'\", \"'\")\n",
    "    text = text.replace(\"\\'\", \"'\")\n",
    "    \n",
    "    # remove anything with this format \"[![text]\"\n",
    "    text = re.sub(r'\\[\\!.*?\\]', ' ', text)\n",
    "    \n",
    "    # remove headers and replace with full stop, in case a previous sentence doed not have it\n",
    "    text  = re.sub(r'#.*?\\n', '', text)\n",
    "    text  = re.sub(r'# .*?\\s', '', text)\n",
    "    text = text.replace(\"####\", \".\")\n",
    "    text = text.replace(\"###\", \".\")\n",
    "    text = text.replace(\"##\", \".\")\n",
    "    text = text.replace(\"#\", \".\")\n",
    "\n",
    "    #remove tables\n",
    "    text = re.sub(r\"[\\|].*?[\\|]\", \"||\", text)\n",
    "    \n",
    "    text = re.sub(r\"[^a-zA-Z0-9.,\\'-|]\\$\\£\\€\",' ', text)    \n",
    "    text = text.replace(\"[\", \"\")\n",
    "    text = text.replace(\"]\", \"\")\n",
    "    text = text.replace(\"--\", \"\")\n",
    "    text = text.replace(\" -\", \"\")\n",
    "    text = text.replace(\"- \", \"\")\n",
    "    text = re.sub(' +', ' ', text)\n",
    "   \n",
    "    new_list = []\n",
    "    text_list = text.split('||')\n",
    "    for line in text_list:\n",
    "        if len(line) > 25:\n",
    "            new_list.append(line +'\\n')\n",
    "    text = ''   \n",
    "    text = text.join(new_list)\n",
    "    text = text.replace(\"*\", \"\")\n",
    "    text = text.replace(\"\\\\n\", \".\")\n",
    "    text = text.replace(\"\\n\", \".\")\n",
    "\n",
    "    text = text.replace(\" .\", \".\")\n",
    "    text = text.replace(\"..\", \".\")\n",
    "    text = text.lstrip()\n",
    "    text = text.rstrip()\n",
    "    text = text.strip()\n",
    "    \n",
    "    text = re.sub(r\"[\\\\][x][0-9][0-9][0-9]\", \"\", text)\n",
    "    text = re.sub(r\"[\\\\][x][a-z][0-9]\", \"\", text)\n",
    "    text = re.sub(r\"[\\\\][x][a-z][a-z]\", \"\", text)\n",
    "    text = re.sub(r\"[\\\\][x][0-9][0-9]\", \"\", text)\n",
    "    text = re.sub(r\"[\\\\][x][a-z]\", \"\", text)\n",
    "    text = re.sub(r\"[\\\\][x][0-9]\", \"\", text)\n",
    "    text = re.sub(r\"[\\\\][x]\", \" \", text)\n",
    "    text_list = text.split('. ')\n",
    "    new_list = []\n",
    "    for line in text_list:\n",
    "        \n",
    "        line = line.strip()\n",
    "        if keep_case == False:\n",
    "            line = line.capitalize() + '.\\n'\n",
    "        else:\n",
    "            line = line + '.\\n'\n",
    "        new_list.append(line)\n",
    "    text = ''   \n",
    "    text = text.join(new_list)\n",
    "    \n",
    "    text = re.sub('\\.__', ' ', text)\n",
    "    text = re.sub('__\\.', ' ', text)\n",
    "    text = re.sub('__' ,'', text)\n",
    "    text = re.sub('>_' ,'', text)\n",
    "    text = re.sub('/' ,' ', text)\n",
    "    text = re.sub('{' ,'', text)\n",
    "    text = re.sub('Image::' ,'', text)\n",
    "    text = re.sub(r\"=\",\"\",text)\n",
    "    text = re.sub(r'\\r',\"\",text)\n",
    "    text = re.sub(r'\\\\r',\"\",text)\n",
    "    text = re.sub(r\"\\(\\)\",\"\",text)\n",
    "    text = text.replace(\" .\", \".\")\n",
    "    text = text.replace(\"..\", \".\")\n",
    "    text = text.replace(\">\", \"\")\n",
    "    text = text.replace(\":height:\", \"\")\n",
    "    text = text.replace(\".. image::\", \"\")\n",
    "    text = text.replace(\":target:\", \"\")\n",
    "    text = text.replace(\":alt:\", \"\")\n",
    "    text = text.replace(\"`_\", \"`\")\n",
    "    text = text.replace(\"^\", \"\")\n",
    "    text = text.replace(\"Code-block::\", \"\")\n",
    "    text = text.replace(\":start-offset\", \"\")\n",
    "    text = text.replace(\":end-offset\", \"\")\n",
    "    text = text.replace(\"\\\\\\\\\", \"\\\\\")\n",
    "    text = text.replace(\"\\t\", \" \")\n",
    "    text = text.replace(\"\\r\", \" \")\n",
    "    text = text.replace(\"image::\", \" \")\n",
    "\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def create_pd_from_repo(_texts, _id, _name, _keep_case, _remove_tab_line, _source ):\n",
    "    # for every repo in the _texts file, \n",
    "    # get the raw description\n",
    "    # process it\n",
    "    # convert to an array of sentences\n",
    "    # add each individual sentence to a pandas\n",
    "    # add the repo ID to the pandas.  in the end we will \n",
    "    # have a pandas DB with repo_id and text to be predicted.\n",
    "    # only add the text if it is more than 40 letters long\n",
    "    print (\"Num repos: \", len ( _texts))\n",
    "\n",
    "    print (\"Source: \", _source)\n",
    "    \n",
    "    #small function contained in scope of this function\n",
    "    def my_fun(variable):\n",
    "        if variable == 'R_BODY R_BODY.':\n",
    "            return False\n",
    "        \n",
    "        if (_source == \"github\") & (len(variable) < 50):\n",
    "            return False\n",
    "        \n",
    "        if len(variable) > 6:\n",
    "            return True\n",
    "        \n",
    "        else:\n",
    "            if 'R_BODY.' in variable:\n",
    "                 #print (variable)\n",
    "                return True\n",
    "            \n",
    "        return False\n",
    "     \n",
    "    df_all = pd.DataFrame()\n",
    "    for x in range(len(_texts)):\n",
    "        df = pd.DataFrame()\n",
    "        sent = _texts[x]\n",
    "        repo_id = _id[x]\n",
    "        repo_name = _name[x]\n",
    "        sen_arr = clean_descriptions(sent, _keep_case, _remove_tab_line).split(\"\\n\")\n",
    "        sen_arr  = list(filter(my_fun, sen_arr)) \n",
    "            \n",
    "        df['text'] = sen_arr\n",
    "        df['repo_id'] = repo_id\n",
    "        df['repo'] = repo_name\n",
    "        \n",
    "        #remove very short sentences and empty BODY\n",
    "        df_all = pd.concat([df_all, df])\n",
    "    print (\"Number of sentences to be analyzed\",df_all.shape[0] )\n",
    "    if (_source == \"github\"):\n",
    "        df_new = pd.DataFrame()\n",
    "        df_new ['sentence'] = df_all.text\n",
    "        df_new['provenance'] = \"github\"\n",
    "        display (df_new.head(3))\n",
    "        print  (\"Saving to Gathered data local folder:\", paths.GATHERED_DATA_CONV_DIR_LOCAL)\n",
    "        df_new.to_csv(paths.GATHERED_DATA_CONV_DIR_LOCAL + \"gathered_github_sentences_latest.tsv\",index=False, sep = \"\\t\")\n",
    "        df_new.to_csv(paths.GATHERED_DATA_CONV_DIR_LOCAL + \"gathered_github_sentences_latest.zip\",index=False, sep = \"\\t\", compression='gzip')\n",
    "        \n",
    "        \n",
    "    if (_source == \"reddit\"):\n",
    "        df_new = pd.DataFrame()\n",
    "        df_new ['sentence'] = df_all.text\n",
    "        df_new['provenance'] = \"github\"\n",
    "        df_new.to_csv(paths.GATHERED_DATA_CONV_DIR_LOCAL +\"gathered_reddit_sentences.tsv\",index=False, sep = \"\\t\")\n",
    "        df_new.to_csv(paths.GATHERED_DATA_CONV_DIR_LOCAL +\"gathered_reddit_sentences.zip\",index=False, sep = \"\\t\", compression='gzip')\n",
    "        \n",
    "    return df_all\n",
    "\n",
    "def analyze_git_repo(url, thresholds, tokenizer, DLModels, DLModelsIsotonicRegression, model_helpers):\n",
    "    AI_repos = pd.read_csv(url, sep=\";\")\n",
    "    \n",
    "    AI_texts = AI_repos['repo_raw_description'].values\n",
    "    AI_repo_id = AI_repos['repo_id'].values\n",
    "    AI_repo_name = AI_repos['repo_name'].values\n",
    "    AI_repos = 0\n",
    "    gc.collect()\n",
    "    res, _ = predict_scores_and_classify(thresholds, create_pd_from_repo(AI_texts, AI_repo_id, AI_repo_name, False, True, \"github\" ), tokenizer, DLModels, DLModelsIsotonicRegression, model_helpers.MAX_SEQUENCE_LENGTH)\n",
    "    AI_repos = 0\n",
    "    AI_texts = 0\n",
    "    AI_repo_id = 0\n",
    "\n",
    "    text = \"Probabilistic count v's Classification count\"\n",
    "    display (HTML(\"<font color = green><h4><left>\" + text + \"</left></h4></font>\"))\n",
    "    display (model_helpers.get_count(res, _DLModels, thresholds, num_prob_buckets = 8, actual=False ))\n",
    "    return res\n",
    "\n",
    "\n",
    "def tag_sentence_text (df, thresholds ):\n",
    "    # Append a sequence of tags to the end of each classified sentence\n",
    "    # e.g. Tensorflow is an end-to-end open source platform for machine learning.[0,0,0,1,0,0,0,0,] \n",
    "    # This will be used to show which tags match which sentence during analysis \n",
    "    # (after re-grouping sentences by RepoId or subredit id etc.\n",
    "    sum_list = []\n",
    "    prob_1_list = []\n",
    "    for conv in thresholds:\n",
    "        sum_list.append(conv+'_y_pred')\n",
    "        prob_1_list.append(conv+'_prob_1')\n",
    "\n",
    "            \n",
    "    df['text'] = df['text'] + '['\n",
    "    for conv_pred in sum_list :\n",
    "        df['text'] = df[\"text\"].map(str) +  df[conv_pred].map(str) +','\n",
    "    df['text'] = df['text'] + \"]\"\n",
    "    \n",
    "    df['text'] = df['text'] + '['\n",
    "    for prob in prob_1_list :\n",
    "        df['text'] = df[\"text\"].map(str) +  round (df[prob],2).map(str) +','\n",
    "    df['text'] = df['text'] + \"].\"\n",
    "    return df\n",
    "\n",
    "\n",
    "def re_group(df, convention_dict):\n",
    "    sum_list = []\n",
    "    for conv in convention_dict:\n",
    "        sum_list.append(conv+'_y_pred')\n",
    "    sum_list.append(\"text\")\n",
    "    grouped_df = df.groupby(['repo_id', 'repo'])\n",
    "    grouped_df = grouped_df[sum_list].sum(axis=0)\n",
    "\n",
    "    def applyFunc(s): \n",
    "        return len(s.split(' '))\n",
    "    def numSen(s): \n",
    "        return len(s.split('].'))\n",
    "\n",
    "    grouped_df['word_count'] = grouped_df['text'].apply(applyFunc)\n",
    "    grouped_df['sentence_count'] = grouped_df['text'].apply(numSen)\n",
    "\n",
    "\n",
    "    print (\"The number of repos is\", grouped_df.shape[0])\n",
    "    grouped_df = grouped_df.reset_index()\n",
    "    grouped_df['word_count'] = grouped_df['text'].apply(applyFunc)\n",
    "    return grouped_df\n",
    "\n",
    "\n",
    "\n",
    "def print_analysis(df, file_path, to_display, number, source):\n",
    "    \n",
    "    f1=open(file_path, 'w+')\n",
    "\n",
    "    i = 0\n",
    "    max_num = df.shape[0] -1\n",
    "\n",
    "    for x in range(number):\n",
    "        \n",
    "        ex_num = x + 1\n",
    "        html = \"\"\n",
    "        i = randint(0, max_num)\n",
    "        \n",
    "        if to_display == True:\n",
    "            print(\"****************************EXAMPLE \",ex_num, \"************************************\")\n",
    "            print(\"Number of words:\", df.iloc[i][11])\n",
    "            print(\"Number of sentences:\", df.iloc[i][12])\n",
    "            print(\"Total civic:\", df.iloc[i][2])\n",
    "            print(\"Total domestic:\", df.iloc[i][3])\n",
    "            print(\"Total green:\", df.iloc[i][4])\n",
    "            print(\"Total industrial:\", df.iloc[i][5])\n",
    "            print(\"Total inspired:\", df.iloc[i][6])\n",
    "            print(\"Total market:\", df.iloc[i][7])\n",
    "            print(\"Total project:\", df.iloc[i][8])\n",
    "            print(\"Total renown:\", df.iloc[i][9])\n",
    "            if source == \"github\":\n",
    "                print(\"URL:\", 'https://github.com/' + df.iloc[i][1] + '/blob/master/README.md')\n",
    "                print(\"URL:\", 'https://github.com/' + df.iloc[i][1] + '/blob/master/README.rst')\n",
    "                print (\"Reference:\" , df.iloc[i][0])\n",
    "            if source == \"reddit\":\n",
    "                print(\"URL:\",  df.iloc[i][1] )\n",
    "                print (\"Reference:\", df.iloc[i][0])\n",
    "            if source == \"ss\":\n",
    "                print(\"URL:\",  df.iloc[i][1] )\n",
    "                print (\"Reference:\", df.iloc[i][0])\n",
    "\n",
    "\n",
    "        f1.write(\"<br/>****************************EXAMPLE \" + str(i) + \"************************************\")\n",
    "        f1.write(\"<br/>Number of words:\"+ str( df.iloc[i][11]))\n",
    "        f1.write(\"<br/>Number of sentences:\"+ str( df.iloc[i][12]))\n",
    "        f1.write(\"<br/>Total civic:\"+ str(df.iloc[i][2]))\n",
    "        f1.write(\"<br/>Total domestic:\"+ str(df.iloc[i][3]))\n",
    "        f1.write(\"<br/>Total green:\"+ str(df.iloc[i][4]))\n",
    "        f1.write(\"<br/>Total industrial:\"+ str(df.iloc[i][5]))\n",
    "        f1.write(\"<br/>Total inspired:\"+ str(df.iloc[i][6]))\n",
    "        f1.write(\"<br/>Total market:\"+ str(df.iloc[i][7]))\n",
    "        f1.write(\"<br/>Total project:\"+ str(df.iloc[i][8]))\n",
    "        f1.write(\"<br/>Total renown:\"+ str(df.iloc[i][9]))\n",
    "        \n",
    "        if source == \"github\":\n",
    "            f1.write(\"<br/><a href='https://github.com/\" \n",
    "                     + df.iloc[i][1] \n",
    "                     + \"/blob/master/README.md'>https://github.com/\" \n",
    "                     + df.iloc[i][1] \n",
    "                     + \"/blob/master/README.md</a>\")\n",
    "    \n",
    "            f1.write(\"<br/><a href='https://github.com/\" \n",
    "                     + df.iloc[i][1] \n",
    "                     + \"/blob/master/README.rst'>https://github.com/\" \n",
    "                     + df.iloc[i][1] \n",
    "                     + \"/blob/master/README.rst</a>\")\n",
    "        \n",
    "        if source == \"reddit\":\n",
    "            f1.write(\"<br/><a href='\" \n",
    "                     + df.iloc[i][1] \n",
    "                     + \"'>\" \n",
    "                     + df.iloc[i][1] \n",
    "                     + \"</a>\")\n",
    "            \n",
    "        if source == \"ss\":\n",
    "            f1.write(\"<br/><a href='\" \n",
    "                     + df.iloc[i][1] \n",
    "                     + \"'>\" \n",
    "                     + df.iloc[i][1] \n",
    "                     + \"</a>\")\n",
    "        \n",
    "        f1.write(\"<br/>Reference:\"+ str(df.iloc[i][0]))\n",
    "        \n",
    "        sen_arr = df.iloc[i][10].split(\"].\")\n",
    "        \n",
    "        if to_display == True:\n",
    "            print(\"\")\n",
    "\n",
    "        title = ''\n",
    "        get_title = False\n",
    "        for sen in sen_arr:\n",
    "            try:\n",
    "               \n",
    "                parts = sen.split(\"[\")\n",
    "                tags = parts[1].split(\",\")\n",
    "                prob = parts[2].split(\",\")\n",
    "                del tags[-1]\n",
    "                del prob[-1]\n",
    "\n",
    "                tags = list(map(int, tags))\n",
    "                prob = list(map(float,  prob))\n",
    "\n",
    "                sum_list = []\n",
    "                count = 0\n",
    "                conventions = \"\"\n",
    "                for conv, x in zip(_thresholds, range(len(tags)) ):\n",
    "                    if conv == \"industrial\":\n",
    "                        color = 'red'\n",
    "                    if conv == \"civic\":\n",
    "                        color = 'blue'\n",
    "                    if conv == \"domestic\":\n",
    "                        color = 'purple'  \n",
    "                    if conv == \"market\":\n",
    "                        color = 'violet'  \n",
    "                    if conv == \"project\":\n",
    "                        color = 'orange' \n",
    "                    if conv == \"green\":\n",
    "                        color = 'green' \n",
    "                    if conv == \"renown\":\n",
    "                        color = 'gold' \n",
    "                    if conv == \"inspired\":\n",
    "                        color = 'pink' \n",
    "                    add_text = \"<font color=\" + color + \">\" + conv + ':' + str(prob[x]) + ', ' + \"</font>\"\n",
    "                    if tags[x] == 1:\n",
    "                        conventions =  conventions + add_text  + \" \"\n",
    "                        count = count + 1\n",
    "               \n",
    "                \n",
    "                text_a = ''\n",
    "                text_b = ''\n",
    "                \n",
    "                if get_title == True:\n",
    "\n",
    "                    if (count > 0):\n",
    "                        conventions = conventions[:-10]+\"</font>\"\n",
    "                        title = '<br/><b>Title:</b><br/>' + parts[0][:-1] + \"</b>\" + \"[\" + conventions + \"]\" + '<b>. </b><br/><br/>'\n",
    "                    else:\n",
    "                        title = '<br/><b>Title:</b><br/>' + parts[0] + '<br/><br/>'\n",
    "                    get_title = False   \n",
    "                \n",
    "                if 'R_BODY.' in parts[0]:\n",
    "         \n",
    "                    parts[0] = parts[0].replace('R_BODY.', '')\n",
    "                    text_b = '<br/><br/><b>Comments:</b><br/>'\n",
    "                    get_title = True #A hack because of the way i collected the data. the title is the first sentence in the comment field\n",
    "                     \n",
    "                if 'R_BODY' in parts[0]:\n",
    "                \n",
    "                    parts[0] = parts[0].replace('R_BODY', '')\n",
    "                    text_a = '<b>Body:</b> <br/>'\n",
    "            \n",
    "                if (count > 0):\n",
    "                    conventions = conventions[:-10]+\"</font>\"\n",
    "                    html = html + \" \" + text_a + \"<b>\" + parts[0][:-1] + \"</b>\" + \"[\" + conventions + \"]\" + '<b>. </b>' + text_b\n",
    "                    \n",
    "                else:\n",
    "                    html = html +  \" \" + text_a + parts[0] + text_b \n",
    "\n",
    "            except:\n",
    "                continue\n",
    "        if source == \"reddit\":\n",
    "            if title == '':\n",
    "                html_list = html.split('. ')\n",
    "                title =  '<br/><b>Title:</b><br/>'+html_list[0] +'<br/><br/><b>Comments:</b><br/>'\n",
    "                html_list.pop(0)\n",
    "                html = '. '.join(html_list)\n",
    "            else:\n",
    "                html_list = html.split('Comments:</b><br/>')\n",
    "                html_list_reduced = html_list[1].split('. ')\n",
    "                html_list_reduced.pop(0)\n",
    "                html_list[1] = '. '.join(html_list_reduced)\n",
    "                html = 'Comments:</b><br/>'.join(html_list)\n",
    "             \n",
    "                \n",
    "        \n",
    "        html = title + html\n",
    "        \n",
    "        \n",
    "        if to_display == True:        \n",
    "            display(HTML(html))\n",
    "            \n",
    "        f1.write(\"<br/>\")\n",
    "        f1.write(\"<br/>\")\n",
    "        f1.write( html)\n",
    "        f1.write(\"<br/>\")\n",
    "        f1.write(\"<br/>\")\n",
    "        \n",
    "        if to_display == True:\n",
    "            print(\"\")\n",
    "            print(\"\")\n",
    "            print(\"\")\n",
    "    print (\"File saved\")\n",
    "    f1.close()\n",
    "    \n",
    "def scatter_plot(grouped_df):\n",
    "    from pandas.plotting import scatter_matrix\n",
    "#     plt.style.use('ggplot')\n",
    "    sm = scatter_matrix(grouped_df.rename(columns={\n",
    "    \"civic_y_pred\": \"civic\",\n",
    "    \"domestic_y_pred\": \"domestic\",\n",
    "    \"green_y_pred\": \"green\",\n",
    "    \"industrial_y_pred\": \"industry\",\n",
    "    \"inspired_y_pred\": \"inspired\",\n",
    "    \"market_y_pred\": \"market\",\n",
    "    \"project_y_pred\": \"project\",\n",
    "    \"renown_y_pred\": \"renown\",\n",
    "    \"word_count\": \"words\",\n",
    "    }).drop(\"text\", axis = 1),figsize=[20,20], alpha=0.4, diagonal='kde')\n",
    "    #kernel density estimation(KDE)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "def analyze_subreddit(url, thresholds, tokenizer, DLModels, DLModelsIsotonicRegression, model_helpers, min_score):\n",
    "    reddit_df = pd.read_csv(url)\n",
    "    reddit_df.loc[reddit_df['body'] == \"[deleted]\", 'body'] = \" \"\n",
    "    reddit_df.loc[reddit_df['body'] == \"[removed]\", 'body'] = \" \"\n",
    "    reddit_df.loc[reddit_df['body'].isnull(), 'body'] = \" \"\n",
    "    reddit_df = reddit_df.loc[reddit_df['score'] > min_score] \n",
    "    reddit_df =  reddit_df.reset_index()\n",
    "    reddit_df['url'] = \"https://www.reddit.com/r/artificial/comments/\" + reddit_df['id']\n",
    "  \n",
    "    reddit_df['text'] = \"R_BODY \" + reddit_df['body'] + \"R_BODY. \" + reddit_df['comments']\n",
    "    reddit_df.dropna(inplace=True)\n",
    "\n",
    "    texts = reddit_df['text'].values\n",
    "    subreddit_id = reddit_df['id'].values\n",
    "    url = reddit_df['url'].values\n",
    "    \n",
    "    reddit_df = reddit_df.drop(\"created\", axis = 1).drop(\"score\", axis = 1).drop(\"title\", axis = 1).drop(\"comments\", axis = 1).drop(\"body\", axis = 1)\n",
    "    print (reddit_df.shape[0])\n",
    "    print (len(reddit_df.id.unique()))\n",
    "    \n",
    "    del reddit_df\n",
    "    gc.collect()\n",
    "    res, _ = predict_scores_and_classify(thresholds, create_pd_from_repo(texts, subreddit_id, url, True, False, \"reddit\"), tokenizer, DLModels, DLModelsIsotonicRegression, model_helpers.MAX_SEQUENCE_LENGTH)\n",
    "    del texts\n",
    "    del subreddit_id\n",
    "    del url\n",
    "    text = \"Probabilistic count v's Classification count\"\n",
    "    display (HTML(\"<font color = green><h4><left>\" + text + \"</left></h4></font>\"))\n",
    "    display (model_helpers.get_count(res, _DLModels, thresholds, num_prob_buckets = 8, actual=False ))\n",
    "    return res\n",
    "\n",
    "\n",
    "def analyze_ss(url, thresholds, tokenizer, DLModels, DLModelsIsotonicRegression, model_helpers):\n",
    "    ss_df = pd.read_csv(url, sep = '\\t', names=[\"repo_id\", \"text\"])\n",
    "    \n",
    "\n",
    "    ss_df.dropna(inplace=True)\n",
    "    ss_df.text.apply(lambda x: clean_descriptions(x,True,False))\n",
    "    ss_df['repo'] = \"http://api.semanticscholar.org/\"  + ss_df.repo_id\n",
    "    print (ss_df.shape[0])\n",
    "    gc.collect()\n",
    "    res, _ = predict_scores_and_classify(thresholds, ss_df, tokenizer, DLModels, DLModelsIsotonicRegression, model_helpers.MAX_SEQUENCE_LENGTH)\n",
    "    del ss_df\n",
    "    text = \"Probabilistic count v's Classification count\"\n",
    "    display (HTML(\"<font color = green><h4><left>\" + text + \"</left></h4></font>\"))\n",
    "    display (model_helpers.get_count(res, _DLModels, thresholds, num_prob_buckets = 8, actual=False ))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify GitHub AI repo or non-AI repo with latest models\n",
    "\n",
    "    _DLModelsIsotonicRegression \n",
    "    _DLModels\n",
    "    _thresholds\n",
    "    _tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T21:42:26.443672Z",
     "start_time": "2020-01-13T21:42:17.832704Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://github.com/aideenf/AIVC/blob/master/cp_wssc/Data/ToBeAnalyzed/github_AI_repos_dump.csv?raw=true\n"
     ]
    }
   ],
   "source": [
    "#Can use this to test the clean_descriptions function for github\n",
    "# AI_repos = pd.read_csv(AI_GITHUB_GIT, sep=\";\")\n",
    "# row = AI_repos.loc[AI_repos['repo_id'] == 3964514] \n",
    "# display (row)\n",
    "# display (row.iloc[0][9])\n",
    "# print (clean_descriptions (row.iloc[0][9], False, True))\n",
    "# print (clean_descriptions (row.iloc[0][9], False, False))\n",
    "#Save ai_repo_analysis_df to the classified folder to be used by the Audit tool\n",
    "\n",
    "print (AI_GITHUB_GIT)\n",
    "\n",
    "NON_AI_GITHUB_GIT = \"https://github.com/aideenf/AIVC/blob/master/cp_wssc/Data/ToBeAnalyzed/github_non_AI_repos_dump.csv?raw=true\"\n",
    "AI_repos = pd.read_csv(NON_AI_GITHUB_GIT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T21:23:20.746973Z",
     "start_time": "2020-01-13T21:23:19.548621Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 1 fields in line 59, saw 5\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-f3aeff3f189a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#with calibration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mai_repo_analysis_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalyze_git_repo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNON_AI_GITHUB_GIT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_thresholds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_tokenizer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tokenizer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_DLModels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_DLModelsIsotonicRegression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_helpers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#without calibration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# ai_repo_analysis_df = analyze_git_repo(AI_GITHUB_GIT, _thresholds, _tokenizer['tokenizer'], _DLModels, None, model_helpers)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0maivm_helper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_to_shelf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'non_ai_repo_analysis_df'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'non_ai_repo_analysis_df'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mai_repo_analysis_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-7cc9b0914664>\u001b[0m in \u001b[0;36manalyze_git_repo\u001b[0;34m(url, thresholds, tokenizer, DLModels, DLModelsIsotonicRegression, model_helpers)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0manalyze_git_repo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresholds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDLModels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDLModelsIsotonicRegression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_helpers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m     \u001b[0mAI_repos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\";\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0mAI_texts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAI_repos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'repo_raw_description'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/python3.6/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/python3.6/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/python3.6/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nrows'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/python3.6/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1993\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1994\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1995\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1996\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1997\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 59, saw 5\n"
     ]
    }
   ],
   "source": [
    "#with calibration\n",
    "ai_repo_analysis_df = analyze_git_repo(NON_AI_GITHUB_GIT, _thresholds, _tokenizer['tokenizer'], _DLModels, _DLModelsIsotonicRegression, model_helpers)\n",
    "#without calibration\n",
    "# ai_repo_analysis_df = analyze_git_repo(AI_GITHUB_GIT, _thresholds, _tokenizer['tokenizer'], _DLModels, None, model_helpers)\n",
    "aivm_helper.save_to_shelf('non_ai_repo_analysis_df', 'non_ai_repo_analysis_df', ai_repo_analysis_df, False, None, None)\n",
    "\n",
    "USE_GIT_HUB = True\n",
    "ai_repo_for_audit_tool = pd.DataFrame()\n",
    "ai_repo_for_audit_tool['text'] = ai_repo_analysis_df['text']\n",
    "ai_repo_for_audit_tool['ref'] = ai_repo_analysis_df['repo_id']\n",
    "ai_repo_for_audit_tool['repo'] = ai_repo_analysis_df['repo']\n",
    "ai_repo_for_audit_tool['data_provenance'] = 'github_ai'\n",
    "\n",
    "for conv in _thresholds:\n",
    "    ai_repo_for_audit_tool['convention_'+conv] = ai_repo_analysis_df[conv+'_prob_1']\n",
    "    \n",
    "ai_repo_for_audit_tool.to_csv(paths.CLASSIFIED_DATA_DIR_LOCAL  + 'git_ai_repo_for_audit_tool.tsv', sep = '\\t')\n",
    "\n",
    "display (ai_repo_for_audit_tool.head())\n",
    "if USE_GIT_HUB == True:\n",
    "    my_file_list = [paths.CLASSIFIED_DATA_DIR_LOCAL + 'git_ai_repo_for_audit_tool.tsv']\n",
    "    push_to_git_as = [paths.CLASSIFIED_DATA_DIR_GIT + 'git_ai_repo_for_audit_tool.tsv']\n",
    "    \n",
    "    commit, message = aivm_helper.save_to_github(GIT_USR, GIT_PSWD, paths.GIT_OWNER_REPO, my_file_list, push_to_git_as, \"auto save keywords\")\n",
    "\n",
    "    if (commit != \"error\"):\n",
    "        print (\"File to commit:\", my_file_list)\n",
    "        print (\"Push to git as:\", push_to_git_as)\n",
    "        print (\"Commit: \", commit)\n",
    "        display(HTML(\"<font color='green'><b>git_ai_repo_for_audit_tool saved to 'Classification results/Conventions/Audited/'</b></font>\"))\n",
    "        \n",
    "            \n",
    "    if (commit == \"error\"):\n",
    "        print (\"File to commit: \", my_file_list)\n",
    "        print (\"Push to git as: \", push_to_git_as)\n",
    "        display(HTML(\"<font color='red'><b>Warning!!</b></font>\"))\n",
    "        print(message)\n",
    "        \n",
    "del ai_repo_for_audit_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T21:09:25.636689Z",
     "start_time": "2020-01-13T21:09:25.624884Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[390.0, 3.0, 11.0, 35.0, 0.0, 27.0, 19.0, 22.0], [3.0, 182.0, 1.0, 11.0, 6.0, 2.0, 12.0, 4.0], [11.0, 1.0, 195.0, 20.0, 0.0, 63.0, 1.0, 14.0], [35.0, 11.0, 20.0, 77041.0, 264.0, 1788.0, 73.0, 18.0], [0.0, 6.0, 0.0, 264.0, 399.0, 0.0, 0.0, 0.0], [27.0, 2.0, 63.0, 1788.0, 0.0, 3678.0, 18.0, 19.0], [19.0, 12.0, 1.0, 73.0, 0.0, 18.0, 423.0, 2.0], [22.0, 4.0, 14.0, 18.0, 0.0, 19.0, 2.0, 236.0]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "listStr =  \"\"\"[[3.9000e+02 3.0000e+00 1.1000e+01 3.5000e+01 0.0000e+00 2.7000e+01\n",
    "  1.9000e+01 2.2000e+01]\n",
    " [3.0000e+00 1.8200e+02 1.0000e+00 1.1000e+01 6.0000e+00 2.0000e+00\n",
    "  1.2000e+01 4.0000e+00]\n",
    " [1.1000e+01 1.0000e+00 1.9500e+02 2.0000e+01 0.0000e+00 6.3000e+01\n",
    "  1.0000e+00 1.4000e+01]\n",
    " [3.5000e+01 1.1000e+01 2.0000e+01 7.7041e+04 2.6400e+02 1.7880e+03\n",
    "  7.3000e+01 1.8000e+01]\n",
    " [0.0000e+00 6.0000e+00 0.0000e+00 2.6400e+02 3.9900e+02 0.0000e+00\n",
    "  0.0000e+00 0.0000e+00]\n",
    " [2.7000e+01 2.0000e+00 6.3000e+01 1.7880e+03 0.0000e+00 3.6780e+03\n",
    "  1.8000e+01 1.9000e+01]\n",
    " [1.9000e+01 1.2000e+01 1.0000e+00 7.3000e+01 0.0000e+00 1.8000e+01\n",
    "  4.2300e+02 2.0000e+00]\n",
    " [2.2000e+01 4.0000e+00 1.4000e+01 1.8000e+01 0.0000e+00 1.9000e+01\n",
    "  2.0000e+00 2.3600e+02]]\"\"\"\n",
    "listStr = listStr.replace(\" \", \", \")\n",
    "listStr = listStr.replace(\",,\", \"\")\n",
    "listStr = listStr.replace(\", ,\", \",\")\n",
    "# listStr = listStr.replace(\"],\", \"]\")\n",
    "listStr = listStr.replace(\"\\n\", \"\")\n",
    "listStr = listStr.replace(\",\", \" \")\n",
    "listStr = listStr.replace(\"]  [\", \"],  [\")\n",
    "listStr = listStr.replace(\"[[\", \"[\")\n",
    "listStr = listStr.replace(\"]]\", \"]\")\n",
    "\n",
    "li = list(listStr.split(\", \")) \n",
    "print(\"\")\n",
    "lista=[]\n",
    "for row in li:\n",
    "    row = row.replace(\"]\", \"\")\n",
    "    row = row.replace(\"[\", \"\")\n",
    "    row_cont = list(row.split(\"  \"))\n",
    "    listb= []\n",
    "    for num in row_cont:\n",
    "        listb.append(float(num))\n",
    "    lista.append(listb)\n",
    "print (lista)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T21:15:15.889634Z",
     "start_time": "2020-01-13T21:15:13.584245Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "name": "Probability Count",
         "textposition": "auto",
         "type": "bar",
         "x": [
          "civic",
          "domestic",
          "green",
          "industrial",
          "inspired",
          "market",
          "project",
          "renown"
         ],
         "y": [
          7573,
          9148,
          8229,
          59323,
          11651,
          9902,
          11814,
          4778
         ]
        },
        {
         "name": "Actual count",
         "textposition": "auto",
         "type": "bar",
         "x": [
          "civic",
          "domestic",
          "green",
          "industrial",
          "inspired",
          "market",
          "project",
          "renown"
         ],
         "y": [
          "not applicable",
          "not applicable",
          "not applicable",
          "not applicable",
          "not applicable",
          "not applicable",
          "not applicable",
          "not applicable"
         ]
        },
        {
         "name": "Predicted by classifier",
         "textposition": "auto",
         "type": "bar",
         "x": [
          "civic",
          "domestic",
          "green",
          "industrial",
          "inspired",
          "market",
          "project",
          "renown"
         ],
         "y": [
          390,
          182,
          195,
          77041,
          399,
          3678,
          423,
          236
         ]
        }
       ],
       "layout": {
        "barmode": "group",
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Probabilistic count vs classifier predicted"
        },
        "xaxis": {
         "tickangle": -45
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"eb39c5c9-e235-44b7-8ebd-46fd7e618c78\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    \n",
       "                if (document.getElementById(\"eb39c5c9-e235-44b7-8ebd-46fd7e618c78\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        'eb39c5c9-e235-44b7-8ebd-46fd7e618c78',\n",
       "                        [{\"name\": \"Probability Count\", \"textposition\": \"auto\", \"type\": \"bar\", \"x\": [\"civic\", \"domestic\", \"green\", \"industrial\", \"inspired\", \"market\", \"project\", \"renown\"], \"y\": [7573, 9148, 8229, 59323, 11651, 9902, 11814, 4778]}, {\"name\": \"Actual count\", \"textposition\": \"auto\", \"type\": \"bar\", \"x\": [\"civic\", \"domestic\", \"green\", \"industrial\", \"inspired\", \"market\", \"project\", \"renown\"], \"y\": [\"not applicable\", \"not applicable\", \"not applicable\", \"not applicable\", \"not applicable\", \"not applicable\", \"not applicable\", \"not applicable\"]}, {\"name\": \"Predicted by classifier\", \"textposition\": \"auto\", \"type\": \"bar\", \"x\": [\"civic\", \"domestic\", \"green\", \"industrial\", \"inspired\", \"market\", \"project\", \"renown\"], \"y\": [390, 182, 195, 77041, 399, 3678, 423, 236]}],\n",
       "                        {\"barmode\": \"group\", \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Probabilistic count vs classifier predicted\"}, \"xaxis\": {\"tickangle\": -45}},\n",
       "                        {\"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('eb39c5c9-e235-44b7-8ebd-46fd7e618c78');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "colorscale": [
          [
           0,
           "#00083e"
          ],
          [
           0.5,
           "#ededee"
          ],
          [
           1,
           "#ffffff"
          ]
         ],
         "hoverinfo": "none",
         "opacity": 0.75,
         "showscale": false,
         "type": "heatmap",
         "z": [
          [
           0,
           0,
           0,
           0,
           0
          ],
          [
           0.5,
           0.5,
           0.5,
           0.5,
           0.5
          ],
          [
           1,
           1,
           1,
           1,
           1
          ],
          [
           0.5,
           0.5,
           0.5,
           0.5,
           0.5
          ],
          [
           1,
           1,
           1,
           1,
           1
          ],
          [
           0.5,
           0.5,
           0.5,
           0.5,
           0.5
          ],
          [
           1,
           1,
           1,
           1,
           1
          ],
          [
           0.5,
           0.5,
           0.5,
           0.5,
           0.5
          ],
          [
           1,
           1,
           1,
           1,
           1
          ]
         ]
        }
       ],
       "layout": {
        "annotations": [
         {
          "align": "left",
          "font": {
           "color": "#ffffff"
          },
          "showarrow": false,
          "text": "<b>Convention</b>",
          "x": -0.45,
          "xanchor": "left",
          "xref": "x",
          "y": 0,
          "yref": "y"
         },
         {
          "align": "left",
          "font": {
           "color": "#ffffff"
          },
          "showarrow": false,
          "text": "<b>Probability count</b>",
          "x": 0.55,
          "xanchor": "left",
          "xref": "x",
          "y": 0,
          "yref": "y"
         },
         {
          "align": "left",
          "font": {
           "color": "#ffffff"
          },
          "showarrow": false,
          "text": "<b>Classifier count</b>",
          "x": 1.55,
          "xanchor": "left",
          "xref": "x",
          "y": 0,
          "yref": "y"
         },
         {
          "align": "left",
          "font": {
           "color": "#ffffff"
          },
          "showarrow": false,
          "text": "<b>Threshold</b>",
          "x": 2.55,
          "xanchor": "left",
          "xref": "x",
          "y": 0,
          "yref": "y"
         },
         {
          "align": "left",
          "font": {
           "color": "#ffffff"
          },
          "showarrow": false,
          "text": "<b>True count</b>",
          "x": 3.55,
          "xanchor": "left",
          "xref": "x",
          "y": 0,
          "yref": "y"
         },
         {
          "align": "left",
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "civic",
          "x": -0.45,
          "xanchor": "left",
          "xref": "x",
          "y": 1,
          "yref": "y"
         },
         {
          "align": "left",
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "7573",
          "x": 0.55,
          "xanchor": "left",
          "xref": "x",
          "y": 1,
          "yref": "y"
         },
         {
          "align": "left",
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "390",
          "x": 1.55,
          "xanchor": "left",
          "xref": "x",
          "y": 1,
          "yref": "y"
         },
         {
          "align": "left",
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "0.5",
          "x": 2.55,
          "xanchor": "left",
          "xref": "x",
          "y": 1,
          "yref": "y"
         },
         {
          "align": "left",
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "not applicable",
          "x": 3.55,
          "xanchor": "left",
          "xref": "x",
          "y": 1,
          "yref": "y"
         },
         {
          "align": "left",
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "domestic",
          "x": -0.45,
          "xanchor": "left",
          "xref": "x",
          "y": 2,
          "yref": "y"
         },
         {
          "align": "left",
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "9148",
          "x": 0.55,
          "xanchor": "left",
          "xref": "x",
          "y": 2,
          "yref": "y"
         },
         {
          "align": "left",
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "182",
          "x": 1.55,
          "xanchor": "left",
          "xref": "x",
          "y": 2,
          "yref": "y"
         },
         {
          "align": "left",
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "0.5",
          "x": 2.55,
          "xanchor": "left",
          "xref": "x",
          "y": 2,
          "yref": "y"
         },
         {
          "align": "left",
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "not applicable",
          "x": 3.55,
          "xanchor": "left",
          "xref": "x",
          "y": 2,
          "yref": "y"
         },
         {
          "align": "left",
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "green",
          "x": -0.45,
          "xanchor": "left",
          "xref": "x",
          "y": 3,
          "yref": "y"
         },
         {
          "align": "left",
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "8229",
          "x": 0.55,
          "xanchor": "left",
          "xref": "x",
          "y": 3,
          "yref": "y"
         },
         {
          "align": "left",
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "195",
          "x": 1.55,
          "xanchor": "left",
          "xref": "x",
          "y": 3,
          "yref": "y"
         },
         {
          "align": "left",
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "0.5",
          "x": 2.55,
          "xanchor": "left",
          "xref": "x",
          "y": 3,
          "yref": "y"
         },
         {
          "align": "left",
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "not applicable",
          "x": 3.55,
          "xanchor": "left",
          "xref": "x",
          "y": 3,
          "yref": "y"
         },
         {
          "align": "left",
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "industrial",
          "x": -0.45,
          "xanchor": "left",
          "xref": "x",
          "y": 4,
          "yref": "y"
         },
         {
          "align": "left",
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "59323",
          "x": 0.55,
          "xanchor": "left",
          "xref": "x",
          "y": 4,
          "yref": "y"
         },
         {
          "align": "left",
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "77041",
          "x": 1.55,
          "xanchor": "left",
          "xref": "x",
          "y": 4,
          "yref": "y"
         },
         {
          "align": "left",
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "0.5",
          "x": 2.55,
          "xanchor": "left",
          "xref": "x",
          "y": 4,
          "yref": "y"
         },
         {
          "align": "left",
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "not applicable",
          "x": 3.55,
          "xanchor": "left",
          "xref": "x",
          "y": 4,
          "yref": "y"
         },
         {
          "align": "left",
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "inspired",
          "x": -0.45,
          "xanchor": "left",
          "xref": "x",
          "y": 5,
          "yref": "y"
         },
         {
          "align": "left",
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "11651",
          "x": 0.55,
          "xanchor": "left",
          "xref": "x",
          "y": 5,
          "yref": "y"
         },
         {
          "align": "left",
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "399",
          "x": 1.55,
          "xanchor": "left",
          "xref": "x",
          "y": 5,
          "yref": "y"
         },
         {
          "align": "left",
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "0.5",
          "x": 2.55,
          "xanchor": "left",
          "xref": "x",
          "y": 5,
          "yref": "y"
         },
         {
          "align": "left",
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "not applicable",
          "x": 3.55,
          "xanchor": "left",
          "xref": "x",
          "y": 5,
          "yref": "y"
         },
         {
          "align": "left",
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "market",
          "x": -0.45,
          "xanchor": "left",
          "xref": "x",
          "y": 6,
          "yref": "y"
         },
         {
          "align": "left",
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "9902",
          "x": 0.55,
          "xanchor": "left",
          "xref": "x",
          "y": 6,
          "yref": "y"
         },
         {
          "align": "left",
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "3678",
          "x": 1.55,
          "xanchor": "left",
          "xref": "x",
          "y": 6,
          "yref": "y"
         },
         {
          "align": "left",
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "0.5",
          "x": 2.55,
          "xanchor": "left",
          "xref": "x",
          "y": 6,
          "yref": "y"
         },
         {
          "align": "left",
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "not applicable",
          "x": 3.55,
          "xanchor": "left",
          "xref": "x",
          "y": 6,
          "yref": "y"
         },
         {
          "align": "left",
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "project",
          "x": -0.45,
          "xanchor": "left",
          "xref": "x",
          "y": 7,
          "yref": "y"
         },
         {
          "align": "left",
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "11814",
          "x": 0.55,
          "xanchor": "left",
          "xref": "x",
          "y": 7,
          "yref": "y"
         },
         {
          "align": "left",
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "423",
          "x": 1.55,
          "xanchor": "left",
          "xref": "x",
          "y": 7,
          "yref": "y"
         },
         {
          "align": "left",
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "0.5",
          "x": 2.55,
          "xanchor": "left",
          "xref": "x",
          "y": 7,
          "yref": "y"
         },
         {
          "align": "left",
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "not applicable",
          "x": 3.55,
          "xanchor": "left",
          "xref": "x",
          "y": 7,
          "yref": "y"
         },
         {
          "align": "left",
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "renown",
          "x": -0.45,
          "xanchor": "left",
          "xref": "x",
          "y": 8,
          "yref": "y"
         },
         {
          "align": "left",
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "4778",
          "x": 0.55,
          "xanchor": "left",
          "xref": "x",
          "y": 8,
          "yref": "y"
         },
         {
          "align": "left",
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "236",
          "x": 1.55,
          "xanchor": "left",
          "xref": "x",
          "y": 8,
          "yref": "y"
         },
         {
          "align": "left",
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "0.5",
          "x": 2.55,
          "xanchor": "left",
          "xref": "x",
          "y": 8,
          "yref": "y"
         },
         {
          "align": "left",
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "not applicable",
          "x": 3.55,
          "xanchor": "left",
          "xref": "x",
          "y": 8,
          "yref": "y"
         }
        ],
        "height": 320,
        "margin": {
         "b": 0,
         "l": 0,
         "r": 0,
         "t": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "dtick": 1,
         "gridwidth": 2,
         "showticklabels": false,
         "tick0": -0.5,
         "ticks": "",
         "zeroline": false
        },
        "yaxis": {
         "autorange": "reversed",
         "dtick": 1,
         "gridwidth": 2,
         "showticklabels": false,
         "tick0": 0.5,
         "ticks": "",
         "zeroline": false
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"9e50c40f-3340-40ad-ab5a-e69faff2d92a\" class=\"plotly-graph-div\" style=\"height:320px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    \n",
       "                if (document.getElementById(\"9e50c40f-3340-40ad-ab5a-e69faff2d92a\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        '9e50c40f-3340-40ad-ab5a-e69faff2d92a',\n",
       "                        [{\"colorscale\": [[0, \"#00083e\"], [0.5, \"#ededee\"], [1, \"#ffffff\"]], \"hoverinfo\": \"none\", \"opacity\": 0.75, \"showscale\": false, \"type\": \"heatmap\", \"z\": [[0, 0, 0, 0, 0], [0.5, 0.5, 0.5, 0.5, 0.5], [1, 1, 1, 1, 1], [0.5, 0.5, 0.5, 0.5, 0.5], [1, 1, 1, 1, 1], [0.5, 0.5, 0.5, 0.5, 0.5], [1, 1, 1, 1, 1], [0.5, 0.5, 0.5, 0.5, 0.5], [1, 1, 1, 1, 1]]}],\n",
       "                        {\"annotations\": [{\"align\": \"left\", \"font\": {\"color\": \"#ffffff\"}, \"showarrow\": false, \"text\": \"<b>Convention</b>\", \"x\": -0.45, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 0, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#ffffff\"}, \"showarrow\": false, \"text\": \"<b>Probability count</b>\", \"x\": 0.55, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 0, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#ffffff\"}, \"showarrow\": false, \"text\": \"<b>Classifier count</b>\", \"x\": 1.55, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 0, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#ffffff\"}, \"showarrow\": false, \"text\": \"<b>Threshold</b>\", \"x\": 2.55, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 0, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#ffffff\"}, \"showarrow\": false, \"text\": \"<b>True count</b>\", \"x\": 3.55, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 0, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#000000\"}, \"showarrow\": false, \"text\": \"civic\", \"x\": -0.45, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 1, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#000000\"}, \"showarrow\": false, \"text\": \"7573\", \"x\": 0.55, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 1, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#000000\"}, \"showarrow\": false, \"text\": \"390\", \"x\": 1.55, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 1, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#000000\"}, \"showarrow\": false, \"text\": \"0.5\", \"x\": 2.55, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 1, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#000000\"}, \"showarrow\": false, \"text\": \"not applicable\", \"x\": 3.55, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 1, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#000000\"}, \"showarrow\": false, \"text\": \"domestic\", \"x\": -0.45, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 2, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#000000\"}, \"showarrow\": false, \"text\": \"9148\", \"x\": 0.55, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 2, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#000000\"}, \"showarrow\": false, \"text\": \"182\", \"x\": 1.55, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 2, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#000000\"}, \"showarrow\": false, \"text\": \"0.5\", \"x\": 2.55, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 2, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#000000\"}, \"showarrow\": false, \"text\": \"not applicable\", \"x\": 3.55, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 2, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#000000\"}, \"showarrow\": false, \"text\": \"green\", \"x\": -0.45, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 3, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#000000\"}, \"showarrow\": false, \"text\": \"8229\", \"x\": 0.55, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 3, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#000000\"}, \"showarrow\": false, \"text\": \"195\", \"x\": 1.55, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 3, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#000000\"}, \"showarrow\": false, \"text\": \"0.5\", \"x\": 2.55, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 3, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#000000\"}, \"showarrow\": false, \"text\": \"not applicable\", \"x\": 3.55, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 3, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#000000\"}, \"showarrow\": false, \"text\": \"industrial\", \"x\": -0.45, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 4, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#000000\"}, \"showarrow\": false, \"text\": \"59323\", \"x\": 0.55, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 4, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#000000\"}, \"showarrow\": false, \"text\": \"77041\", \"x\": 1.55, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 4, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#000000\"}, \"showarrow\": false, \"text\": \"0.5\", \"x\": 2.55, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 4, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#000000\"}, \"showarrow\": false, \"text\": \"not applicable\", \"x\": 3.55, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 4, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#000000\"}, \"showarrow\": false, \"text\": \"inspired\", \"x\": -0.45, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 5, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#000000\"}, \"showarrow\": false, \"text\": \"11651\", \"x\": 0.55, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 5, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#000000\"}, \"showarrow\": false, \"text\": \"399\", \"x\": 1.55, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 5, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#000000\"}, \"showarrow\": false, \"text\": \"0.5\", \"x\": 2.55, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 5, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#000000\"}, \"showarrow\": false, \"text\": \"not applicable\", \"x\": 3.55, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 5, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#000000\"}, \"showarrow\": false, \"text\": \"market\", \"x\": -0.45, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 6, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#000000\"}, \"showarrow\": false, \"text\": \"9902\", \"x\": 0.55, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 6, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#000000\"}, \"showarrow\": false, \"text\": \"3678\", \"x\": 1.55, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 6, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#000000\"}, \"showarrow\": false, \"text\": \"0.5\", \"x\": 2.55, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 6, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#000000\"}, \"showarrow\": false, \"text\": \"not applicable\", \"x\": 3.55, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 6, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#000000\"}, \"showarrow\": false, \"text\": \"project\", \"x\": -0.45, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 7, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#000000\"}, \"showarrow\": false, \"text\": \"11814\", \"x\": 0.55, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 7, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#000000\"}, \"showarrow\": false, \"text\": \"423\", \"x\": 1.55, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 7, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#000000\"}, \"showarrow\": false, \"text\": \"0.5\", \"x\": 2.55, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 7, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#000000\"}, \"showarrow\": false, \"text\": \"not applicable\", \"x\": 3.55, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 7, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#000000\"}, \"showarrow\": false, \"text\": \"renown\", \"x\": -0.45, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 8, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#000000\"}, \"showarrow\": false, \"text\": \"4778\", \"x\": 0.55, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 8, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#000000\"}, \"showarrow\": false, \"text\": \"236\", \"x\": 1.55, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 8, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#000000\"}, \"showarrow\": false, \"text\": \"0.5\", \"x\": 2.55, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 8, \"yref\": \"y\"}, {\"align\": \"left\", \"font\": {\"color\": \"#000000\"}, \"showarrow\": false, \"text\": \"not applicable\", \"x\": 3.55, \"xanchor\": \"left\", \"xref\": \"x\", \"y\": 8, \"yref\": \"y\"}], \"height\": 320, \"margin\": {\"b\": 0, \"l\": 0, \"r\": 0, \"t\": 0}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"xaxis\": {\"dtick\": 1, \"gridwidth\": 2, \"showticklabels\": false, \"tick0\": -0.5, \"ticks\": \"\", \"zeroline\": false}, \"yaxis\": {\"autorange\": \"reversed\", \"dtick\": 1, \"gridwidth\": 2, \"showticklabels\": false, \"tick0\": 0.5, \"ticks\": \"\", \"zeroline\": false}},\n",
       "                        {\"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('9e50c40f-3340-40ad-ab5a-e69faff2d92a');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Convention</th>\n",
       "      <th>Probability count</th>\n",
       "      <th>Classifier count</th>\n",
       "      <th>provenance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>civic</td>\n",
       "      <td>7573</td>\n",
       "      <td>390</td>\n",
       "      <td>github_ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>domestic</td>\n",
       "      <td>9148</td>\n",
       "      <td>182</td>\n",
       "      <td>github_ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>green</td>\n",
       "      <td>8229</td>\n",
       "      <td>195</td>\n",
       "      <td>github_ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>industrial</td>\n",
       "      <td>59323</td>\n",
       "      <td>77041</td>\n",
       "      <td>github_ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>inspired</td>\n",
       "      <td>11651</td>\n",
       "      <td>399</td>\n",
       "      <td>github_ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>market</td>\n",
       "      <td>9902</td>\n",
       "      <td>3678</td>\n",
       "      <td>github_ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>project</td>\n",
       "      <td>11814</td>\n",
       "      <td>423</td>\n",
       "      <td>github_ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>renown</td>\n",
       "      <td>4778</td>\n",
       "      <td>236</td>\n",
       "      <td>github_ai</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Convention  Probability count  Classifier count provenance\n",
       "0       civic               7573               390  github_ai\n",
       "1    domestic               9148               182  github_ai\n",
       "2       green               8229               195  github_ai\n",
       "3  industrial              59323             77041  github_ai\n",
       "4    inspired              11651               399  github_ai\n",
       "5      market               9902              3678  github_ai\n",
       "6     project              11814               423  github_ai\n",
       "7      renown               4778               236  github_ai"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "GitHub_AI = model_helpers.get_count(ai_repo_analysis_df, _DLModels, _thresholds, num_prob_buckets = 8, actual=False )\n",
    "GitHub_AI = GitHub_AI.drop(\"Threshold\", axis = 1).drop(\"True count\", axis =1)\n",
    "GitHub_AI['provenance'] = \"github_ai\"\n",
    "display (GitHub_AI.head(10))\n",
    "GitHub_AI.to_csv(\"./counts/github_ai_count.tsv\",index=False, sep = \"\\t\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Append a tag summary to the end of each sentence. \n",
    "\n",
    "- Tensorflow is an end-to-end open source platform for machine learning.[0,0,0,1,0,0,0,0,]\n",
    "This will be used to show which tags match which sentence during analysis (after re-grouping sentences by RepoId or subredit id etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T21:17:23.997909Z",
     "start_time": "2020-01-13T21:17:18.350227Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tensorflow is an end-to-end open source platform for machine learning.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo_id</th>\n",
       "      <th>text</th>\n",
       "      <th>repo</th>\n",
       "      <th>civic</th>\n",
       "      <th>civic_prob</th>\n",
       "      <th>civic_y_pred</th>\n",
       "      <th>civic_prob_1</th>\n",
       "      <th>domestic</th>\n",
       "      <th>domestic_prob</th>\n",
       "      <th>domestic_y_pred</th>\n",
       "      <th>...</th>\n",
       "      <th>project_prob</th>\n",
       "      <th>project_y_pred</th>\n",
       "      <th>project_prob_1</th>\n",
       "      <th>renown</th>\n",
       "      <th>renown_prob</th>\n",
       "      <th>renown_y_pred</th>\n",
       "      <th>renown_prob_1</th>\n",
       "      <th>lbl_cnt</th>\n",
       "      <th>set_conf</th>\n",
       "      <th>pos_sample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45717250</td>\n",
       "      <td>Tensorflow is an end-to-end open source platfo...</td>\n",
       "      <td>tensorflow/tensorflow</td>\n",
       "      <td>0</td>\n",
       "      <td>0.948052</td>\n",
       "      <td>0</td>\n",
       "      <td>0.051948</td>\n",
       "      <td>0</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.802632</td>\n",
       "      <td>0</td>\n",
       "      <td>0.197368</td>\n",
       "      <td>0</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    repo_id                                               text  \\\n",
       "0  45717250  Tensorflow is an end-to-end open source platfo...   \n",
       "\n",
       "                    repo  civic  civic_prob  civic_y_pred  civic_prob_1  \\\n",
       "0  tensorflow/tensorflow      0    0.948052             0      0.051948   \n",
       "\n",
       "   domestic  domestic_prob  domestic_y_pred  ...  project_prob  \\\n",
       "0         0       0.967742                0  ...      0.802632   \n",
       "\n",
       "   project_y_pred  project_prob_1  renown  renown_prob  renown_y_pred  \\\n",
       "0               0        0.197368       0     0.973684              0   \n",
       "\n",
       "   renown_prob_1  lbl_cnt  set_conf  pos_sample  \n",
       "0       0.026316        0       0.0         0.0  \n",
       "\n",
       "[1 rows x 38 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'total repos'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "124959"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo_id</th>\n",
       "      <th>text</th>\n",
       "      <th>repo</th>\n",
       "      <th>civic</th>\n",
       "      <th>civic_prob</th>\n",
       "      <th>civic_y_pred</th>\n",
       "      <th>civic_prob_1</th>\n",
       "      <th>domestic</th>\n",
       "      <th>domestic_prob</th>\n",
       "      <th>domestic_y_pred</th>\n",
       "      <th>...</th>\n",
       "      <th>project_prob</th>\n",
       "      <th>project_y_pred</th>\n",
       "      <th>project_prob_1</th>\n",
       "      <th>renown</th>\n",
       "      <th>renown_prob</th>\n",
       "      <th>renown_y_pred</th>\n",
       "      <th>renown_prob_1</th>\n",
       "      <th>lbl_cnt</th>\n",
       "      <th>set_conf</th>\n",
       "      <th>pos_sample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45717250</td>\n",
       "      <td>Tensorflow is an end-to-end open source platfo...</td>\n",
       "      <td>tensorflow/tensorflow</td>\n",
       "      <td>0</td>\n",
       "      <td>0.948052</td>\n",
       "      <td>0</td>\n",
       "      <td>0.051948</td>\n",
       "      <td>0</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.802632</td>\n",
       "      <td>0</td>\n",
       "      <td>0.197368</td>\n",
       "      <td>0</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    repo_id                                               text  \\\n",
       "0  45717250  Tensorflow is an end-to-end open source platfo...   \n",
       "\n",
       "                    repo  civic  civic_prob  civic_y_pred  civic_prob_1  \\\n",
       "0  tensorflow/tensorflow      0    0.948052             0      0.051948   \n",
       "\n",
       "   domestic  domestic_prob  domestic_y_pred  ...  project_prob  \\\n",
       "0         0       0.967742                0  ...      0.802632   \n",
       "\n",
       "   project_y_pred  project_prob_1  renown  renown_prob  renown_y_pred  \\\n",
       "0               0        0.197368       0     0.973684              0   \n",
       "\n",
       "   renown_prob_1  lbl_cnt  set_conf  pos_sample  \n",
       "0       0.026316        0       0.0         0.0  \n",
       "\n",
       "[1 rows x 38 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Tensorflow is an end-to-end open source platform for machine learning.[0,0,0,0,0,0,0,0,][0.05,0.03,0.0,0.37,0.03,0.04,0.2,0.03,].'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Reading it from Shelf so we could start at this point if we do not want to classify all data again(if it \n",
    "#is already complete), here you will see the 1st line without the tags and then with the tags. \n",
    "ai_repo_analysis_df = aivm_helper.retrieve_shelved_object('ai_repo_analysis_df', 'ai_repo_analysis_df', False)\n",
    "\n",
    "display(ai_repo_analysis_df.iloc[0][1])\n",
    "display (ai_repo_analysis_df.head(1))\n",
    "ai_repo_analysis_df = tag_sentence_text(ai_repo_analysis_df, _thresholds )\n",
    "display(\"total repos\", ai_repo_analysis_df.shape[0])\n",
    "display(ai_repo_analysis_df.head(1))\n",
    "display(ai_repo_analysis_df.iloc[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-group the sentences based on the Repo_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T21:17:50.207164Z",
     "start_time": "2020-01-13T21:17:35.486191Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of repos is 8401\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo_id</th>\n",
       "      <th>repo</th>\n",
       "      <th>civic_y_pred</th>\n",
       "      <th>domestic_y_pred</th>\n",
       "      <th>green_y_pred</th>\n",
       "      <th>industrial_y_pred</th>\n",
       "      <th>inspired_y_pred</th>\n",
       "      <th>market_y_pred</th>\n",
       "      <th>project_y_pred</th>\n",
       "      <th>renown_y_pred</th>\n",
       "      <th>text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sentence_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>102637</td>\n",
       "      <td>cirg-up/cilib</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Computational intelligence library is a librar...</td>\n",
       "      <td>165</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>135191</td>\n",
       "      <td>igrigorik/decisiontree</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Tree a ruby library which implements id3 (info...</td>\n",
       "      <td>175</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   repo_id                    repo  civic_y_pred  domestic_y_pred  \\\n",
       "0   102637           cirg-up/cilib             0                0   \n",
       "1   135191  igrigorik/decisiontree             0                0   \n",
       "\n",
       "   green_y_pred  industrial_y_pred  inspired_y_pred  market_y_pred  \\\n",
       "0             0                  1                0              0   \n",
       "1             0                  7                0              1   \n",
       "\n",
       "   project_y_pred  renown_y_pred  \\\n",
       "0               0              0   \n",
       "1               0              0   \n",
       "\n",
       "                                                text  word_count  \\\n",
       "0  Computational intelligence library is a librar...         165   \n",
       "1  Tree a ruby library which implements id3 (info...         175   \n",
       "\n",
       "   sentence_count  \n",
       "0               4  \n",
       "1              11  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ai_repo_analysis_df']\n",
      "['grouped_ai_repo_analysis_df']\n"
     ]
    }
   ],
   "source": [
    "grouped_ai_repo_analysis_df = re_group(ai_repo_analysis_df, _thresholds)\n",
    "display(grouped_ai_repo_analysis_df.head(2))\n",
    "\n",
    "aivm_helper.save_to_shelf('grouped_ai_repo_analysis_df', 'grouped_ai_repo_analysis_df', grouped_ai_repo_analysis_df, False, None, None)\n",
    "aivm_helper.get_all_shelfed('ai_repo_analysis_df', False)\n",
    "aivm_helper.get_all_shelfed('grouped_ai_repo_analysis_df', False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save a random selection of repos to file for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T21:33:24.658534Z",
     "start_time": "2020-01-13T21:33:24.537708Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************EXAMPLE  1 ************************************\n",
      "Number of words: 1203\n",
      "Number of sentences: 63\n",
      "Total civic: 0\n",
      "Total domestic: 0\n",
      "Total green: 0\n",
      "Total industrial: 29\n",
      "Total inspired: 0\n",
      "Total market: 1\n",
      "Total project: 0\n",
      "Total renown: 0\n",
      "URL: https://github.com/gregversteeg/corex_topic/blob/master/README.md\n",
      "URL: https://github.com/gregversteeg/corex_topic/blob/master/README.rst\n",
      "Reference: 44352390\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " Corex: hierarchical topic modeling with minimal domain knowledge topic modeling by way of correlation explanation (corex) yields rich topics that are maximally informative about a set of data. <b>This project optimizes the corex framework for sparse binary data, allowing for topic modeling over large corpora</b>[<font color=red>industrial:1.0</font>]<b>. </b> <b>In addition, this code supports hierarchical topic modeling, and provides a mechanism for integrating domain knowledge via anchor words and the information bottleneck</b>[<font color=red>industrial:0.77</font>]<b>. </b> This semi-supervised anchoring is flexible and allows the user to anchor words through creative strategies that promote topic representation, separability, and aspects. Unlike lda, the corex topic model and its hierarchical and semi-supervised extensions make no assumptions on how documents are generated and, yet, they still find coherent, meaningful topics as measured across a variety of metrics. Our tacl paper makes detailed comparisons to unsupervised and semi-supervised variants of lda: gallagher, ryan j., kyle reing, david kale, and greg ver steeg. <b>\"anchored correlation explanation: topic modeling with minimal domain knowledge\" transactions of the association for computational linguistics (tacl), 2017</b>[<font color=red>industrial:0.76</font>]<b>. </b> <b>This code can be used for any sparse binary dataset</b>[<font color=red>industrial:0.86</font>]<b>. </b> In principle, continuous values in the range zero to one can also be used as inputs but the effect of this is not well tested.started. <b>Python code for the corex topic model can be installed via pip:.the corex topic model given a doc-word matrix, the corex topic model is easy to train</b>[<font color=red>industrial:0.67</font>]<b>. </b> The code follows the scikit-learn fit transform conventions. <b>Once the model is trained, the topics can be accessed through the function</b>[<font color=red>industrial:0.67</font>]<b>. </b> <b>Similarly, the most probable documents for each topic can be accessed through the ``get_top_docs`` function</b>[<font color=red>industrial:0.77</font>]<b>. </b> Summary files and visualizations can be outputted from. <b>The visualizations utilize , and is used for plotting hierarchical topic models</b>[<font color=red>industrial:0.67</font>]<b>. </b> <b>Graphviz should be compiled with the triangulation library for the best visual results</b>[<font color=red>industrial:0.86</font>]<b>. </b> Full details on how to retrieve and interpret output from the corex topic model are given in the example notebook.topic modeling.a hierarchical topic model for the corex topic model, topics are latent factors that can be expressed or not in each document. <b>We can use these binary topic expressions as input for another layer of the corex topic model, yielding a hierarchical representation</b>[<font color=red>industrial:0.77</font>]<b>. </b> Visualizations of the hierarchical topic model can be accessed through.the number of topics there is a principled way for choosing the number of topics within each layer of the topic model. <b>Each topic explains a certain portion of the total correlation (tc)</b>[<font color=red>industrial:0.54</font>]<b>. </b> <b>These topic tcs can be accessed through the attribute, and the overall tc (the sum of the topic tcs) can be accessed through</b>[<font color=red>industrial:0.5</font>]<b>. </b> <b>To assess how many topics to choose at each layer, you may look at the distribution of for each layer</b>[<font color=red>industrial:0.61</font>]<b>. </b> <b>As a rule of thumb, additional latent topics should be added until additional topics contribute little to the overall tc</b>[<font color=red>industrial:0.67</font>]<b>. </b> To get better topic results, you can restart the corex topic model several times from different initializations, and choose the topic model that has the highest tc (explains the most information about the documents).topic modeling.anchor words anchored corex allows a user to anchor words to topics in a semi-supervised fashion to uncover otherwise elusive topics. If is initialized, anchoring is straightforward: this anchors \"dog\" and \"cat\" to the first topic, and \"apple\" to the second topic. As a rule of thumb should always be set above 1, where setting between 1 and 3 gently nudges a topic towards the anchor words, and setting it above 5 more strongly encourages the topic towards the anchor words. <b>We encourage users to experiment with for their own purposes</b>[<font color=red>industrial:0.5</font>]<b>. </b> <b>If is not initialized, you may anchor by specifying the integer column feature indices that you wish to anchor on</b>[<font color=red>industrial:0.54</font>]<b>. </b> For example, anchors the features of columns 0 and 2 to the first topic, and feature 1 to the second topic.strategies in our tacl paper, we explore several anchoring strategies: 1. Anchoring a single set of words to a single topic. This can help promote a topic that did not naturally emerge when running an unsupervised instance of the corex topic model. For example, one might anchor words like \"snow,\" \"cold,\" and \"avalanche\" to a topic if one suspects there should be a snow avalanche topic within a set of disaster relief articles. Anchoring single sets of words to multiple topics. This can help find different aspects of a topic that may be discussed in several different contexts. For example, one might anchor \"protest\" to three topics and \"riot\" to three other topics to understand different framings that arise from tweets about political protests. Anchoring different sets of words to multiple topics. This can help enforce topic separability if there appear to be chimera topics. For example, one might anchor \"mountain,\" \"bernese,\" and \"dog\" to one topic and \"mountain,\" \"rocky,\" and \"colorado\" to another topic to help separate topics that merge discussion of bernese mountain dogs and the rocky mountains. The example notebook details other examples of using anchored corex. We encourage domain experts to experiment with other anchoring strategies that suit their needs. Note, when running unsupervised corex, the topics are returned and sorted according to how much total correlation they each explain. <b>When running anchored corex, the topics are not sorted by total correlation, and the first n topics will correspond to the n anchored topics in the order given by the model input.notes.of documents for speed reasons, this version of the corex topic model works only on binary data and produces binary latent factors</b>[<font color=red>industrial:0.77</font>]<b>. </b> Despite this limitation, our work demonstrates corex produces coherent topics that are as good as or better than those produced by lda for short to medium length documents. However, you may wish to consider additional preprocessing for working with longer documents. <b>We have several strategies for handling text data</b>[<font color=red>industrial:0.77</font>]<b>. </b> This will be good for documents of similar length and especially shortto medium-length documents. <b>We split documents into chunks, compute the binary bag of words for each documents and then average</b>[<font color=red>industrial:0.77</font>]<b>. </b> <b>Split documents into chunks and consider each chunk as its own binary bag of words documents</b>[<font color=red>industrial:0.67, </font> <font color=violet>market:0.67</font>]<b>. </b> This changes the number of documents so it may take some work to match the ids back, if desired. Implicitly, this will weight longer documents more heavily. <b>Generally this seems like the most theoretically justified method</b>[<font color=red>industrial:0.77</font>]<b>. </b> <b>Ideally, you could aggregate the latent factors over sub-documents to get 'counts' of latent factors at the higher layers</b>[<font color=red>industrial:0.77</font>]<b>. </b> <b>This converts counts into a fraction of the background rate, with 1 as the max</b>[<font color=red>industrial:0.67</font>]<b>. </b> <b>Short documents tend to stay binary and words in long documents are weighted according to their frequency with respect to background in the corpus</b>[<font color=red>industrial:0.67</font>]<b>. </b> <b>It requires no preprocessing of count data and it uses the full range of possible inputs</b>[<font color=red>industrial:0.77</font>]<b>. </b> <b>However, this approach is not very rigorous or well tested</b>[<font color=red>industrial:0.67</font>]<b>. </b> <b>For the python api, for 1 and 2, you can use the functions in to process data or do the same yourself</b>[<font color=red>industrial:0.77</font>]<b>. </b> <b>Naive binarization is specified through the python api with count'binarize' and fractional counts with count'fraction'</b>[<font color=red>industrial:0.77</font>]<b>. </b> While fractional counts may be work theoretically, their usage in the corex topic model has not be adequately tested.membership of words in topics also for speed reasons, the corex topic model enforces single membership of words in topics. If a user anchors a word to multiple topics, the single membership can be overriden. Going forward, we plan to develop a multi-membership extension of the corex topic model that retains the computational efficiency.theory and motivation of corex discovering structure in high-dimensional data through correlation explanation ver steeg and galstyan, nips 2014. <b>Maximally informative hierarchical representions of high-dimensional data ver steeg and galstyan, aistats 2015</b>[<font color=red>industrial:0.77</font>]<b>. </b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "****************************EXAMPLE  2 ************************************\n",
      "Number of words: 187\n",
      "Number of sentences: 2\n",
      "Total civic: 0\n",
      "Total domestic: 0\n",
      "Total green: 0\n",
      "Total industrial: 1\n",
      "Total inspired: 0\n",
      "Total market: 0\n",
      "Total project: 0\n",
      "Total renown: 0\n",
      "URL: https://github.com/wshuail/Learn-Data-Science-the-Hard-Way/blob/master/README.md\n",
      "URL: https://github.com/wshuail/Learn-Data-Science-the-Hard-Way/blob/master/README.rst\n",
      "Reference: 36500084\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " <b>About data science.python for data analysis.numpy tutorial.ten minutes to pandas.pandas cookbook.collective intelligence.five types of probility_models.python for data analysis chapter 1 preliminaries chapter 2: introductory examples chapter 3: ipthon: an interactive computing and development environment chapter 4: numpy basics: arrays and vectorized computation chapter 5: getting started with pandas chapter 6: data loading, storage, and file formats chapter 7: data wrangling: clean, transform, merge, reshape chapter 8: ploting and visualization chapter 9: data aggregation and group operations chapter 10: time series chapter 11: financial and economic data applications chapter 12: anvanced numpy appendix: python language essentials.numpy tutorial numpy tutorial.ten minutes to pandas ten minutes to pandas.pandas cookbook chapter 1: reading from a csv chapter 2: selecting data & finding the most common complaint type chapter 3: which borough has the most noise complaints? chapter 4: find out on which weekday people bike the most with groupby and aggregate chapter 5: combining dataframes and scraping canadian weather data chapter 6: string operations! which month was the snowiest? chapter 7: cleaning up messy data chapter 8: parsing unix timestamps chapter 9: loading data from sql databases.collective intelligence.five types of probility_models</b>[<font color=red>industrial:0.77</font>]<b>. </b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "File saved\n"
     ]
    }
   ],
   "source": [
    "print_analysis(grouped_ai_repo_analysis_df, './analysis_GitHub_final_model_no_calib_10_Jan.html', True, 2, 'github')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Scatter plot of re-grouped  AI repos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T14:46:51.584142Z",
     "start_time": "2019-12-13T14:46:20.156471Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scatter_plot(grouped_ai_repo_analysis_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-11T02:48:52.909287Z",
     "start_time": "2020-01-11T02:48:52.296854Z"
    }
   },
   "outputs": [],
   "source": [
    "#Release the memory to avoid bursting the notebook!\n",
    "del ai_repo_analysis_df\n",
    "del grouped_ai_repo_analysis_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify Reddit Repo with latest Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T21:37:58.217438Z",
     "start_time": "2020-01-13T21:33:38.400908Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2455\n",
      "2455\n",
      "Num repos:  2455\n",
      "Source:  reddit\n",
      "Number of sentences to be analyzed 38296\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-f38e03c981bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmin_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mreddit_analysis_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalyze_subreddit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mREDDIT_AI_GIT\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0m_thresholds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_tokenizer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tokenizer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_DLModels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_DLModelsIsotonicRegression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_helpers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# reddit_analysis_df = analyze_subreddit(REDDIT_AI_GIT,  _thresholds, _tokenizer['tokenizer'], _DLModels, None, model_helpers, min_score)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#Save reddit_analysis_df to the classified folder to be used by the Audit tool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-7cc9b0914664>\u001b[0m in \u001b[0;36manalyze_subreddit\u001b[0;34m(url, thresholds, tokenizer, DLModels, DLModelsIsotonicRegression, model_helpers, min_score)\u001b[0m\n\u001b[1;32m    652\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mreddit_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m     \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m     \u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_scores_and_classify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthresholds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_pd_from_repo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubreddit_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"reddit\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDLModels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDLModelsIsotonicRegression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_helpers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMAX_SEQUENCE_LENGTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    655\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0msubreddit_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-7cc9b0914664>\u001b[0m in \u001b[0;36mpredict_scores_and_classify\u001b[0;34m(thresholds_in, to_predict_df, _tokenizer, _DLModels, _DLModelsIsotonicRegression, seq_len)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mmy_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_DLModels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;31m#First through the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0my_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;31m#get the score for value = 1 as the response is [x,y] we need only the y values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/python3.6/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1460\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1461\u001b[0m                                             \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1462\u001b[0;31m                                             callbacks=callbacks)\n\u001b[0m\u001b[1;32m   1463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1464\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m~/.pyenv/versions/python3.6/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mbatch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predict'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/python3.6/lib/python3.6/site-packages/keras/backend/theano_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1428\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1430\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1431\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m             \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metrics_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/python3.6/lib/python3.6/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "min_score = 4\n",
    "reddit_analysis_df = analyze_subreddit(REDDIT_AI_GIT,  _thresholds, _tokenizer['tokenizer'], _DLModels, _DLModelsIsotonicRegression, model_helpers, min_score)\n",
    "# reddit_analysis_df = analyze_subreddit(REDDIT_AI_GIT,  _thresholds, _tokenizer['tokenizer'], _DLModels, None, model_helpers, min_score)\n",
    "\n",
    "#Save reddit_analysis_df to the classified folder to be used by the Audit tool\n",
    "USE_GIT_HUB = True\n",
    "ai_repo_for_audit_tool = pd.DataFrame()\n",
    "ai_repo_for_audit_tool['text'] = reddit_analysis_df['text'].str.replace('R_BODY','')\n",
    "ai_repo_for_audit_tool['ref'] = reddit_analysis_df['repo_id']\n",
    "ai_repo_for_audit_tool['repo'] = reddit_analysis_df['repo']\n",
    "ai_repo_for_audit_tool['data_provenance'] = 'reddit_ai'\n",
    "\n",
    "for conv in _thresholds:\n",
    "    ai_repo_for_audit_tool['convention_'+conv] = reddit_analysis_df[conv+'_prob_1']\n",
    "    \n",
    "ai_repo_for_audit_tool.to_csv(paths.CLASSIFIED_DATA_DIR_LOCAL  + 'reddit_ai_for_audit_tool.tsv', sep = '\\t')\n",
    "\n",
    "display (ai_repo_for_audit_tool.head())\n",
    "if USE_GIT_HUB == True:\n",
    "    my_file_list = [paths.CLASSIFIED_DATA_DIR_LOCAL + 'reddit_ai_for_audit_tool.tsv']\n",
    "    push_to_git_as = [paths.CLASSIFIED_DATA_DIR_GIT + 'reddit_ai_for_audit_tool.tsv']\n",
    "    \n",
    "    commit, message = aivm_helper.save_to_github(GIT_USR, GIT_PSWD, paths.GIT_OWNER_REPO, my_file_list, push_to_git_as, \"auto save keywords\")\n",
    "\n",
    "    if (commit != \"error\"):\n",
    "        print (\"File to commit:\", my_file_list)\n",
    "        print (\"Push to git as:\", push_to_git_as)\n",
    "        print (\"Commit: \", commit)\n",
    "        display(HTML(\"<font color='green'><b>reddit_ai_for_audit_tool.tsv saved to 'Classification results/Conventions/Audited/'</b></font>\"))\n",
    "        \n",
    "            \n",
    "    if (commit == \"error\"):\n",
    "        print (\"File to commit: \", my_file_list)\n",
    "        print (\"Push to git as: \", push_to_git_as)\n",
    "        display(HTML(\"<font color='red'><b>Warning!!</b></font>\"))\n",
    "        print(message)\n",
    "del ai_repo_for_audit_tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T16:25:16.882058Z",
     "start_time": "2019-12-04T16:25:16.872326Z"
    }
   },
   "source": [
    "# Append a tag summary to the end of each sentence. \n",
    "\n",
    "    - Columbia University Team Uses AI, Implants and Speech Synthesizer to Translate Brain Activity Into Words.[0,0,0,1,0,0,0,0,].'\n",
    "\n",
    "    This will be used to show which tags match which sentence during analysis (after re-grouping sentences by RepoId or subredit id etc.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-11T03:00:00.086473Z",
     "start_time": "2020-01-11T02:59:55.483831Z"
    }
   },
   "outputs": [],
   "source": [
    "reddit_analysis_df = tag_sentence_text(reddit_analysis_df, _thresholds )\n",
    "display(\"total repos\", reddit_analysis_df.shape[0])\n",
    "display(reddit_analysis_df.head(2))\n",
    "display(reddit_analysis_df.iloc[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-group the sentences based on the subredditID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-11T03:00:28.198291Z",
     "start_time": "2020-01-11T03:00:03.161944Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grouped_reddit_analysis_df = re_group(reddit_analysis_df, _thresholds)\n",
    "display(grouped_reddit_analysis_df.head(2))\n",
    "\n",
    "#Save the dataframes to local shelf in case want to use them again. \n",
    "aivm_helper.save_to_shelf('reddit_analysis_df', 'reddit_analysis_df', reddit_analysis_df, False, None, None)\n",
    "aivm_helper.save_to_shelf('grouped_reddit_analysis_df', 'grouped_reddit_analysis_df', grouped_reddit_analysis_df, False, None, None)\n",
    "aivm_helper.get_all_shelfed('reddit_analysis_df', False)\n",
    "aivm_helper.get_all_shelfed('grouped_reddit_analysis_df', False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save some classification results for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-11T03:10:38.170301Z",
     "start_time": "2020-01-11T03:10:36.762444Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print_analysis(grouped_reddit_analysis_df, './reddit_analysis_final_model_10_jan.html', False, 200, \"reddit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Scatter plot of Subreddit posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T15:25:31.247261Z",
     "start_time": "2019-12-13T15:25:21.550190Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scatter_plot(grouped_reddit_analysis_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T15:25:34.209019Z",
     "start_time": "2019-12-13T15:25:34.199699Z"
    }
   },
   "outputs": [],
   "source": [
    "#delete the dataframes to local shelf to free up some memory\n",
    "del reddit_analysis_df\n",
    "del grouped_reddit_analysis_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify Senmantic Scholar data with latest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-11T03:17:35.472752Z",
     "start_time": "2020-01-11T03:10:49.672680Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "ss_analysis_df = analyze_ss(SS_GIT,  _thresholds, _tokenizer['tokenizer'], _DLModels, _DLModelsIsotonicRegression, model_helpers)\n",
    "\n",
    "#Save reddit_analysis_df to the classified folder to be used by the Audit tool\n",
    "\n",
    "USE_GIT_HUB = True\n",
    "ai_repo_for_audit_tool = pd.DataFrame()\n",
    "ai_repo_for_audit_tool['text'] = ss_analysis_df['text']\n",
    "ai_repo_for_audit_tool['ref'] = ss_analysis_df['repo_id']\n",
    "ai_repo_for_audit_tool['repo'] = ss_analysis_df['repo']\n",
    "ai_repo_for_audit_tool['data_provenance'] = 's2_ai'\n",
    "\n",
    "for conv in _thresholds:\n",
    "    ai_repo_for_audit_tool['convention_'+conv] = ss_analysis_df[conv+'_prob_1']\n",
    "    \n",
    "ai_repo_for_audit_tool.to_csv(paths.CLASSIFIED_DATA_DIR_LOCAL  + 's2_ai_for_audit_tool.tsv', sep = '\\t')\n",
    "\n",
    "display (ai_repo_for_audit_tool.head())\n",
    "if USE_GIT_HUB == True:\n",
    "    my_file_list = [paths.CLASSIFIED_DATA_DIR_LOCAL + 's2_ai_for_audit_tool.tsv']\n",
    "    push_to_git_as = [paths.CLASSIFIED_DATA_DIR_GIT + 's2_ai_for_audit_tool.tsv']\n",
    "    \n",
    "    commit, message = aivm_helper.save_to_github(GIT_USR, GIT_PSWD, paths.GIT_OWNER_REPO, my_file_list, push_to_git_as, \"auto save keywords\")\n",
    "\n",
    "    if (commit != \"error\"):\n",
    "        print (\"File to commit:\", my_file_list)\n",
    "        print (\"Push to git as:\", push_to_git_as)\n",
    "        print (\"Commit: \", commit)\n",
    "        display(HTML(\"<font color='green'><b>Keywords Saved to GIT Resource folder!!</b></font>\"))\n",
    "        \n",
    "            \n",
    "    if (commit == \"error\"):\n",
    "        print (\"File to commit: \", my_file_list)\n",
    "        print (\"Push to git as: \", push_to_git_as)\n",
    "        display(HTML(\"<font color='red'><b>Warning!!</b></font>\"))\n",
    "        print(message)\n",
    "del ai_repo_for_audit_tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Append a tag summary to the end of each sentence. \n",
    "\n",
    "    - Columbia University Team Uses AI, Implants and Speech Synthesizer to Translate Brain Activity Into Words.[0,0,0,1,0,0,0,0,].'\n",
    "\n",
    "    This will be used to show which tags match which sentence during analysis (after re-grouping sentences by RepoId or subredit id etc.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-11T03:17:43.469565Z",
     "start_time": "2020-01-11T03:17:39.864449Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ss_analysis_df = tag_sentence_text(ss_analysis_df, _thresholds )\n",
    "display(\"total num sentences\", ss_analysis_df.shape[0])\n",
    "display(ss_analysis_df.head(2))\n",
    "display(ss_analysis_df.iloc[0][1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-group the sentences based on the abstract id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-11T03:18:23.940862Z",
     "start_time": "2020-01-11T03:17:50.190300Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grouped_ss_analysis_df = re_group(ss_analysis_df, _thresholds)\n",
    "display(grouped_ss_analysis_df.head(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# print out some samples for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-11T03:23:47.380530Z",
     "start_time": "2020-01-11T03:23:44.328056Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_analysis(grouped_ss_analysis_df, './s2_analysis_final_model_10_Jan.html', False, 200, \"ss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T15:34:28.062685Z",
     "start_time": "2019-12-13T15:34:14.305556Z"
    }
   },
   "outputs": [],
   "source": [
    "scatter_plot(grouped_ss_analysis_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T16:04:08.389343Z",
     "start_time": "2019-12-09T16:04:07.344301Z"
    }
   },
   "outputs": [],
   "source": [
    "#Save the dataframes to local shelf in case want to use them again. \n",
    "aivm_helper.save_to_shelf('ss_analysis_df', 'ss_analysis_df', ss_analysis_df, False, None, None)\n",
    "aivm_helper.save_to_shelf('grouped_ss_analysis_df', 'grouped_ss_analysis_df', grouped_ss_analysis_df, False, None, None)\n",
    "aivm_helper.get_all_shelfed('ss_analysis_df', False)\n",
    "aivm_helper.get_all_shelfed('grouped_ss_analysis_df', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T13:24:49.294392Z",
     "start_time": "2019-11-27T13:22:29.386785Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class Take(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Pass through a single column without modification\"\"\"\n",
    "    def __init__(self, col):\n",
    "        self.col = col\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return X[self.col].to_frame(self.col)\n",
    "name = ai_repo_analysis_df.index\n",
    "print (name [0])\n",
    "\n",
    "\n",
    "features = [\n",
    "    ('civic_y_pred', Take('civic_y_pred')),\n",
    "    ('domestic_y_pred', Take('domestic_y_pred')),\n",
    "    ('green_y_pred', Take('green_y_pred')),\n",
    "    ('industrial_y_pred', Take('industrial_y_pred')),\n",
    "    ('inspired_y_pred', Take('inspired_y_pred')),\n",
    "    ('market_y_pred', Take('market_y_pred')),\n",
    "    ('project_y_pred', Take('project_y_pred')),\n",
    "    ('renown_y_pred', Take('renown_y_pred')),\n",
    "    ('word_count', Take('word_count')),\n",
    "]\n",
    "pipe = Pipeline([\n",
    "    ('feat', FeatureUnion(features)),\n",
    "    ('scale', StandardScaler())\n",
    "])\n",
    "\n",
    "trans = pipe.fit_transform(grouped_ai_repo_analysis_df)\n",
    "\n",
    "\n",
    "# Try to cluster using KMeans for colouring out plot\n",
    "cluster = KMeans(n_clusters=8)\n",
    "group_pred = cluster.fit_predict(trans)\n",
    "\n",
    "# Perform t-SNE to reduce the dimensionality down to 2 dimenions, for easier plotting.\n",
    "tsne = TSNE(n_components=2)\n",
    "tsne_fit = tsne.fit_transform(trans)\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "trace = go.Scatter(\n",
    "    x=tsne_fit.T[0], \n",
    "    y=tsne_fit.T[1],\n",
    "    mode='markers',\n",
    "    name='Lines, Markers and Text',\n",
    "    text=name,\n",
    "    textposition='top left',\n",
    "    marker=dict(\n",
    "        color = group_pred, #set color equal to a variable\n",
    "        colorscale='Portland',\n",
    "        showscale=True\n",
    "    )\n",
    ")\n",
    "\n",
    "data = [trace]\n",
    "layout = go.Layout(\n",
    "    showlegend=False\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View a sample repo and it's convention for manual analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T13:30:41.865370Z",
     "start_time": "2019-11-27T13:30:41.735445Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num  = 180\n",
    "display(grouped_ai_repo_analysis_df[num:num+1])\n",
    "display(grouped_ai_repo_analysis_df.iloc[num][8] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search for repos with > or < x words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T13:33:33.283808Z",
     "start_time": "2019-11-27T13:33:33.276065Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sum_list_new = sum_list\n",
    "sum_list_new.pop()\n",
    "repos = grouped_ai_repo_analysis_df.loc[grouped_ai_repo_analysis_df['word_count'] > 10000 ]\n",
    "display(repos.head(3) )\n",
    "display(repos.shape[0] )\n",
    "#display(green_repos.iloc[2][8] )\n",
    "display (repos.iloc[0][8])"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python3.6 PyEnv",
   "language": "python",
   "name": "python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "501.215px",
    "left": "1052.22px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
