{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative AIVC models building (if using github - add credentials in cell 2)\n",
    "(This summary is out of sync - to be edited)\n",
    "### Implemented pipeline:\n",
    "\n",
    "#### 1.- Data gathering\n",
    "#### 2.- Classify data (probabilistic classification)\n",
    "#### 3.- Sample data from each strate of classifications (high confidence, medium, low)\n",
    "#### 4.- Manually validate data\n",
    "#### 5.- Append data to training files\n",
    "#### 6.- Retrain new models\n",
    "#### 7.- Gather new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T17:19:57.575320Z",
     "start_time": "2019-10-04T17:19:52.913035Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "import requests as req\n",
    "import json\n",
    "\n",
    "## Deep Learning imports for the classifiers\n",
    "os.environ['KERAS_BACKEND']='theano'\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dense, Input, Flatten\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding, Dropout, Concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from urllib.request import urlopen\n",
    "import cloudpickle as cp\n",
    "import urllib\n",
    "import urllib.request \n",
    "import cloudstorage\n",
    "from github import Github\n",
    "from github import InputGitTreeElement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T17:19:57.820349Z",
     "start_time": "2019-10-04T17:19:57.797906Z"
    }
   },
   "outputs": [],
   "source": [
    "###*******START-POPULATE GIT_HUB Credentials ********###\n",
    "#To read data files directly from  github - usr/pssword not necessary for read\n",
    "USE_GIT_HUB = True \n",
    "\n",
    "#To read pickle files from github - usr/pssword not necessary for read\n",
    "READ_PICKLE_FROM_GIT_HUB = False  \n",
    "#leave READ_PICKLE_FROM_GIT_HUB set to False as pickle files too big for github if not zipped(to discuss  with David)\n",
    "\n",
    "\n",
    "\n",
    "#To push data files directly to  github - usr/pssword required\n",
    "GIT_USER = '@@@@' \n",
    "GIT_PSWD = '@@@@'\n",
    "GIT_REPO = 'AIVC'\n",
    "###*******END-POPULATE GIT_HUB Credentials ********###\n",
    "\n",
    "\n",
    "#Classificaiton NETWORKs Configuration parameters\n",
    "MAX_SEQUENCE_LENGTH = 32\n",
    "MAX_NB_WORDS = 10000\n",
    "EMBEDDING_DIM = 100 ## 100, 200 or 300\n",
    "VALIDATION_SPLIT = 0.2\n",
    "NUM_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will read the data files directly from github: the following is the hirearchy.\n",
    "\n",
    "- BASE_DIR\n",
    "     - Gathered_data\n",
    "         - Conventions\n",
    "         - Software_characteristics\n",
    "     - Classification_results\n",
    "         - Conventions\n",
    "         - Software_characteristics\n",
    "     - Training_data\n",
    "         - Conventions\n",
    "         - Software_characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T17:19:58.072635Z",
     "start_time": "2019-10-04T17:19:58.066392Z"
    }
   },
   "outputs": [],
   "source": [
    "RESULTS_SAMPLING_PERCENTAJE = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data gathering\n",
    "\n",
    "To be done for different sources, to have high variability. It's important to keep tracking of where does each sentence come from (add a label of provenance).\n",
    "Identified data sources:\n",
    "    - Google\n",
    "    - Github\n",
    "    - Semantic Scholar\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T17:19:58.862247Z",
     "start_time": "2019-10-04T17:19:58.839974Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import  base64\n",
    "\n",
    "def remove_excluded_files(file_list):\n",
    "    cleaned_file_list = []\n",
    "    for f in file_list:\n",
    "        if not f.startswith( '.' ) and not \"random\" in f and \"gathered_\" in f and not f.startswith(\"_\"):\n",
    "            cleaned_file_list.append(f)\n",
    "    return cleaned_file_list\n",
    "        \n",
    "        \n",
    "def rreplace(s, old, new, occurrence):\n",
    "    li = s.rsplit(old, occurrence)\n",
    "    return new.join(li)\n",
    "\n",
    "\n",
    "def clean_file_name(name, replacements2=[]):\n",
    "    \n",
    "    replacements=[\".txt\", \".csv\", \".tsv\"]\n",
    "    \n",
    "    for r in replacements:\n",
    "        name = name.replace(r, \"\")\n",
    "        \n",
    "    for r in replacements2:\n",
    "        name = name.replace(r, \"\")\n",
    "    return name\n",
    "\n",
    "\n",
    "def save_to_github(git_user, git_password, git_repo, my_file_list, push_to_git_as):\n",
    "    '''\n",
    "    in order to push a file to github it must first be stored locally, then pushed\n",
    "    this local location can also be local to a virtual machine. \n",
    "    takes: \n",
    "            git username, password, repo, \n",
    "            a list of files to push to git ie the full local location of file,\n",
    "            a matching list of paths to push each file to in Git hub \n",
    "    '''\n",
    "    display(git_user, git_password, git_repo, my_file_list, push_to_git_as)\n",
    "    user = git_user\n",
    "    password = git_password\n",
    "    url = git_repo\n",
    "    file_list = []  #push these list of files to git\n",
    "    file_names = [] #push to this location in git\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        g = Github(user, password)\n",
    "        repo = g.get_user().get_repo(url)\n",
    "\n",
    "        file_list = my_file_list \n",
    "        file_names = push_to_git_as\n",
    "                 \n",
    "        commit_message = 'training data updated via the audit tool'\n",
    "    \n",
    "        master_ref = repo.get_git_ref('heads/master')\n",
    "        master_sha = master_ref.object.sha\n",
    "        base_tree = repo.get_git_tree(master_sha)\n",
    "        element_list = list()\n",
    "\n",
    "        for i, entry in enumerate(file_list):\n",
    "            print (\"file to commit:\", entry)\n",
    "            \n",
    "            with open(entry) as input_file:\n",
    "                #data = input_file.read()   #works with non zip file\n",
    "                data = base64.b64encode(open(entry, \"rb\").read())\n",
    "                \n",
    "            if entry.endswith('.png'):\n",
    "                data = base64.b64encode(data) \n",
    "                \n",
    "\n",
    "            blob = repo.create_git_blob(data.decode(\"utf-8\"), \"base64\")\n",
    "            element = InputGitTreeElement(path=file_names[i], mode='100644', type='blob', sha=blob.sha)\n",
    "\n",
    "            #push to git as file_names[i]\n",
    "            print (\"push to git as:\", file_names[i])\n",
    "            \n",
    "            #element = InputGitTreeElement(file_names[i], '100644', 'blob', data)\n",
    "            \n",
    "            #element_list is a list of InputGitTreeElement. \n",
    "            #Each one corresponds to a file. \n",
    "            # the 'content' of InputGitTreeElement can only be of type 'str' or 'unicode'. \n",
    "            #When I load a file to memory I have type 'bytes'. \n",
    "            #What is the right way to encode those bytes to str or unicode to upload a .zip\n",
    "            element_list.append(element)   \n",
    "        \n",
    "        tree = repo.create_git_tree(element_list, base_tree)\n",
    "        print(\"got here 2\")\n",
    "        parent = repo.get_git_commit(master_sha)\n",
    "        print(\"got here 3\")\n",
    "        commit = repo.create_git_commit(commit_message, tree, [parent])\n",
    "        master_ref.edit(commit.sha)\n",
    "        print (\"File commited to github :\", commit)\n",
    "    except e:\n",
    "        print(\"\")\n",
    "        print (\"GITHUB SUBMIT FAILED:\")\n",
    "        print (\"Are your github login credentials correct?\")\n",
    "        print (\"Are you a collaberator in the repo?\")\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read conventions data and  software characteristics data\n",
    "either from local file system for local testing or from github to allow full synchronization across collaborators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T17:20:02.480701Z",
     "start_time": "2019-10-04T17:20:02.475508Z"
    }
   },
   "outputs": [],
   "source": [
    "gathered_conventions_files = []\n",
    "gathered_characteristics_files = []\n",
    "gathered_conventions_data = {}\n",
    "gathered_software_characteristics_data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T17:20:03.436754Z",
     "start_time": "2019-10-04T17:20:03.422051Z"
    }
   },
   "outputs": [],
   "source": [
    "if(USE_GIT_HUB == False):\n",
    "    \n",
    "    MODELS_DIR = \"./Data/Iterative-models-building/Models/\"\n",
    "    BASE_DIR = \"./Data/Iterative-models-building\"\n",
    "    \n",
    "    \n",
    "    GATHERED_DATA_FOLDER = os.path.join(BASE_DIR, \"Gathered_data\")\n",
    "    CONVS_DIR_NAME = \"Conventions\"\n",
    "    SOFT_CHARS_DIR_NAME = \"Software_characteristics\"\n",
    "    GATHERED_SOFTWARE_CHARS_DIR = os.path.join(GATHERED_DATA_FOLDER, SOFT_CHARS_DIR_NAME)\n",
    "    GATHERED_CONVENTIONS_DIR = os.path.join(GATHERED_DATA_FOLDER, CONVS_DIR_NAME)\n",
    "    \n",
    "    \n",
    "    #For each file() in gathered software characteristics folder\n",
    "    gathered_conventions_files = [f for f in os.listdir(GATHERED_CONVENTIONS_DIR) ]\n",
    "    for f in gathered_conventions_files:\n",
    "        gathered_conventions_data[clean_file_name(f)] = pd.read_csv(os.path.join(GATHERED_CONVENTIONS_DIR, f), sep='\\t')\n",
    "    gathered_conventions_files = remove_excluded_files(gathered_conventions_files)   \n",
    "\n",
    "    #For each file in gathered software characteristics folder\n",
    "    gathered_characteristics_files = [f for f in os.listdir(GATHERED_SOFTWARE_CHARS_DIR) ]\n",
    "    for f in gathered_characteristics_files:\n",
    "        gathered_software_characteristics_data[clean_file_name(f)] = pd.read_csv(os.path.join(GATHERED_SOFTWARE_CHARS_DIR, f), sep='\\t')\n",
    "    gathered_characteristics_files = remove_excluded_files(gathered_characteristics_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T17:20:10.481912Z",
     "start_time": "2019-10-04T17:20:04.645531Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# the entire cell is only valid if using github as data source\n",
    "if(USE_GIT_HUB == True): \n",
    "    \n",
    "    # read data files for source data directly from github.\n",
    "    # to obtain the id for the folder, navigate the tree using\n",
    "    # https://api.github.com/repos/{owner}/{repo}/git/trees/master\n",
    "    # e.g https://api.github.com/repos/aideenf/AIVC/git/trees/master\n",
    "    # once navigated each directory will be of format\n",
    "    # https://api.github.com/repos/aideenf/AIVC/git/trees/{dir_ref}\n",
    "\n",
    "    ####need an alternative for these\n",
    "    MODELS_DIR = \"./Data/Iterative-models-building/Models/\"\n",
    "  \n",
    "    \n",
    "    BASE_DIR = \"./Data/Iterative-models-building\"\n",
    "    CONVS_DIR_NAME = \"Conventions\"\n",
    "    SOFT_CHARS_DIR_NAME = \"Software_characteristics\"\n",
    "    ####\n",
    "     \n",
    "    GATHERED_CONVENTIONS_DIR = \"https://api.github.com/repos/aideenf/AIVC/git/trees/048349b4dd81d95a17129e7fcd5418bdca8309b3\"\n",
    "    resp = req.get(GATHERED_CONVENTIONS_DIR)\n",
    "    response  = json.loads(resp.text)\n",
    "    for value in response['tree']:\n",
    "        gathered_conventions_files.append(value['path'])\n",
    "    gathered_conventions_files = remove_excluded_files(gathered_conventions_files)\n",
    "    \n",
    "    \n",
    "    GATHERED_SOFTWARE_CHARS_DIR = \"https://api.github.com/repos/aideenf/AIVC/git/trees/149a2b2f9696e575a4106e85002afda36a86e5fe\"\n",
    "    resp = req.get(GATHERED_SOFTWARE_CHARS_DIR)\n",
    "    response  = json.loads(resp.text)\n",
    "    for value in response['tree']:\n",
    "        gathered_characteristics_files.append(value['path'])\n",
    "    gathered_characteristics_files = remove_excluded_files(gathered_characteristics_files)\n",
    "    \n",
    "    #Read conventions data file from github. \n",
    "    for f in gathered_conventions_files:\n",
    "        urlBase  = 'https://raw.githubusercontent.com/aideenf/AIVC/master/cp_wssc/Data/Iterative-models-building/Gathered_data/Conventions/'\n",
    "        gathered_conventions_data[clean_file_name(f)] = pd.read_csv(urlBase+f, sep='\\t', error_bad_lines=False)\n",
    "        \n",
    "    #Read software characteristics data file from github. \n",
    "    for f in gathered_characteristics_files:\n",
    "        urlBase  = 'https://raw.githubusercontent.com/aideenf/AIVC/master/cp_wssc/Data/Iterative-models-building/Gathered_data/Software_characteristics/'\n",
    "        gathered_software_characteristics_data[clean_file_name(f)] = pd.read_csv(urlBase+f, sep='\\t', error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T17:20:12.284847Z",
     "start_time": "2019-10-04T17:20:12.233340Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Now we have a dictionary(gathered_conventions_data) of dataframes one entry for each gathered sentence source:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['gathered_green_test.tsv',\n",
       " 'gathered_news_sentences.tsv',\n",
       " 'gathered_s2_17-19_ki.tsv']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Now we have a dictionary(gathered_software_characteristics_data) of dataframes one entry for each SW character source:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['gathered_advantages.tsv',\n",
       " 'gathered_contributions.tsv',\n",
       " 'gathered_efficiency.tsv',\n",
       " 'gathered_functionalities.tsv',\n",
       " 'gathered_licensing.tsv',\n",
       " 'gathered_portability.tsv',\n",
       " 'gathered_s2_17-19_ki.tsv']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>provenance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Efficiency testing tests the amount of resourc...</td>\n",
       "      <td>efficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Efficiency can be defined as, using the resour...</td>\n",
       "      <td>efficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>we probably able to develop an optimal system ...</td>\n",
       "      <td>efficiency</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  provenance\n",
       "0  Efficiency testing tests the amount of resourc...  efficiency\n",
       "1  Efficiency can be defined as, using the resour...  efficiency\n",
       "2  we probably able to develop an optimal system ...  efficiency"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>provenance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Comparing their performance is difficult since...</td>\n",
       "      <td>advantages</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Both are open-source and easily available, as ...</td>\n",
       "      <td>advantages</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Another issue with the latter one is the owner...</td>\n",
       "      <td>advantages</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  provenance\n",
       "0  Comparing their performance is difficult since...  advantages\n",
       "1  Both are open-source and easily available, as ...  advantages\n",
       "2  Another issue with the latter one is the owner...  advantages"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display (\"Now we have a dictionary(gathered_conventions_data) of dataframes one entry for each gathered sentence source:\" , gathered_conventions_files)\n",
    "display (\"Now we have a dictionary(gathered_software_characteristics_data) of dataframes one entry for each SW character source:\" , gathered_characteristics_files)\n",
    "\n",
    "display (gathered_conventions_data[list(gathered_conventions_data.keys())[0]].head(3))\n",
    "display (gathered_software_characteristics_data[list(gathered_software_characteristics_data.keys())[0]].head(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasification - load the classifiers from pickle files\n",
    "\n",
    "Classify, using each of the classifiers, the gathered sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T17:21:38.271421Z",
     "start_time": "2019-10-04T17:20:13.949887Z"
    }
   },
   "outputs": [],
   "source": [
    "## Read pickled classifiers\n",
    "# Note: pickle is used for serializing and de-serializing a Python object structure. \n",
    "# Any object in python can be pickled so that it can be saved on disk. \n",
    "# What pickle does is that it “serialises” the object first before writing it to file. \n",
    "# Pickling is a way to convert a python object (list, dict, etc.) into a character stream\n",
    "\n",
    "\n",
    "\n",
    "## read convention models from pickle file from gitHub or local \n",
    "if(READ_PICKLE_FROM_GIT_HUB == True): \n",
    "    \n",
    "    CONV_MODEL_PCKL_URL = 'https://raw.githubusercontent.com/aideenf/AIVC/master/cp_wssc/Data/Iterative-models-building/Models/conv_models_items.pickle'\n",
    "    CHARACT_MODEL_PCKL_URL = 'https://github.com/aideenf/AIVC/blob/master/cp_wssc/Data/Iterative-models-building/Models/charact_models_items.pickle'\n",
    "    \n",
    "    #make sure updated pickle files are in github\n",
    "    convention_convnet_items = pickle.load(urllib.request.urlopen(CONV_MODEL_PCKL_URL))\n",
    "    characteristics_convnet_items = pickle.load(urllib.request.urlopen(CHARACT_MODEL_PCKL_URL))\n",
    "    \n",
    "    \n",
    "# or local\n",
    "elif(READ_PICKLE_FROM_GIT_HUB == False):\n",
    "    \n",
    "    f = open( os.path.join(MODELS_DIR, 'conv_models_items.pickle'), 'rb') \n",
    "    convention_convnet_items = pickle.load(f)\n",
    "    f.close()\n",
    "    f = open( os.path.join(MODELS_DIR, 'charact_models_items.pickle'), 'rb')\n",
    "    characteristics_convnet_items = pickle.load(f)\n",
    "    f.close()\n",
    "    \n",
    "\n",
    "\n",
    "## Load the  convention models from the downloaded pickle file             \n",
    "_conventions_models = convention_convnet_items['model'] \n",
    "_conventions_tokenizers = convention_convnet_items['tokenizer'] \n",
    "_conventions_data_val_x = convention_convnet_items['_x_val'] \n",
    "_conventions_data_val_y = convention_convnet_items['_y_val'] \n",
    "_conventions_train_histories = convention_convnet_items['train_history'] \n",
    " \n",
    "\n",
    "## Load the convention models from the downloaded pickle file\n",
    "_characteristics_models = characteristics_convnet_items['model'] \n",
    "_characteristics_tokenizers = characteristics_convnet_items['tokenizer'] \n",
    "_characteristics_data_val_x = characteristics_convnet_items['_x_val'] \n",
    "_characteristics_data_val_y = characteristics_convnet_items['_y_val'] \n",
    "_characteristics_train_histories = characteristics_convnet_items['train_history'] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T17:21:42.818814Z",
     "start_time": "2019-10-04T17:21:42.803671Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_model_matches_proba(sequences, model):\n",
    "    data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "    preds = model.predict(data)\n",
    "\n",
    "    return preds[:,1]\n",
    "\n",
    "\n",
    "def calculate_matches(sentences, _models, _tokenizers):\n",
    "    _repos_matches = {}\n",
    "\n",
    "    ## Getting classification confidence per model for each repo\n",
    "    for model_key in _models.keys():\n",
    "            \n",
    "        tokenized_sentences = _tokenizers[model_key].texts_to_sequences(sentences)\n",
    "        preds = get_model_matches_proba(tokenized_sentences, _models[model_key])\n",
    "\n",
    "        _repos_matches[clean_file_name(model_key)] = preds\n",
    "    return _repos_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T17:21:47.421952Z",
     "start_time": "2019-10-04T17:21:47.372373Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example sentence/source from combination of all data sources:\n",
      "*Sentence: Efficiency testing tests the amount of resources required by a program to perform a specific function. \n",
      "*Source: efficiency\n"
     ]
    }
   ],
   "source": [
    "## TODO: Put here all sentences from gathered data \n",
    "#data_sentences = np.array([\"This would be talking about efficiency in industrial terms\", \"just one random example\", \"please, classify this a green world\"])\n",
    "#data_sentences_provenance = np.array([\"Google\", \"Github\", \"Semantic Scholar\"])\n",
    "\n",
    "#AF: Check with david what the above comments refer to\n",
    "\n",
    "data_sentences = []\n",
    "data_sentences_provenance = []\n",
    "\n",
    "#for each data source in the dataframe dictionary\n",
    "for k in gathered_conventions_data.keys():\n",
    "    #retrieve the dataFrame for the convention\n",
    "    conv_data_df = gathered_conventions_data[k]\n",
    "    #aggregate the source\n",
    "    provenances = conv_data_df['provenance'].values\n",
    "    #aggregate the sentence\n",
    "    texts = conv_data_df['sentence'].values\n",
    "    for i in range(len(conv_data_df)):\n",
    "        data_sentences.append( texts[i])\n",
    "        data_sentences_provenance.append(provenances[i])\n",
    "\n",
    "#Now we have a list of sentences and sentence sources which we will \n",
    "#input to the trained model and later we will evaluate and audit \n",
    "print (\"Example sentence/source from combination of all data sources:\")\n",
    "print (\"*Sentence:\", data_sentences[0])\n",
    "print (\"*Source:\", data_sentences_provenance[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pass all the combined convention sentences through each convention classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T17:27:25.617789Z",
     "start_time": "2019-10-04T17:21:53.887080Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training_Domestic': array([0.00534185, 0.12774004, 0.01665984, ..., 0.00375354, 0.1560743 ,\n",
       "        0.04842694], dtype=float32),\n",
       " 'training_Civic': array([0.04638804, 0.3896583 , 0.01244823, ..., 0.04746608, 0.00286384,\n",
       "        0.00752154], dtype=float32),\n",
       " 'training_Project': array([0.25859016, 0.29603943, 0.13812582, ..., 0.01918435, 0.721226  ,\n",
       "        0.00617128], dtype=float32),\n",
       " 'training_Inspired': array([0.00012241, 0.00055518, 0.040906  , ..., 0.00685755, 0.01248142,\n",
       "        0.00384337], dtype=float32),\n",
       " 'training_Green': array([0.01495152, 0.00140612, 0.02147203, ..., 0.00295671, 0.01914687,\n",
       "        0.00662242], dtype=float32),\n",
       " 'training_Market': array([4.4414458e-07, 2.2101747e-03, 3.5192791e-01, ..., 2.5251795e-02,\n",
       "        1.2655546e-03, 1.7326655e-02], dtype=float32),\n",
       " 'training_Industrial': array([0.99999905, 0.99902415, 0.99531776, ..., 0.99642736, 0.98281306,\n",
       "        0.650132  ], dtype=float32),\n",
       " 'training_Renown': array([0.00825112, 0.01819912, 0.02585935, ..., 0.03906786, 0.3349709 ,\n",
       "        0.26484984], dtype=float32)}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conventions_classifications = calculate_matches( data_sentences, _conventions_models, _conventions_tokenizers)\n",
    "display (conventions_classifications)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We will pass the combined software characteristic sentences through each characteristic classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T17:34:30.670581Z",
     "start_time": "2019-10-04T17:27:31.876778Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training_advantages': array([0.08301048, 0.02721285, 0.09450483, ..., 0.56885636, 0.01144238,\n",
       "        0.46630916], dtype=float32),\n",
       " 'training_usability': array([0.71851295, 0.35090455, 0.01321431, ..., 0.34620893, 0.07782289,\n",
       "        0.2947704 ], dtype=float32),\n",
       " 'training_contributions': array([2.8789060e-05, 1.2267357e-06, 5.2368261e-08, ..., 3.6041586e-06,\n",
       "        8.9865207e-06, 1.5677137e-05], dtype=float32),\n",
       " 'training_efficiency': array([9.9995708e-01, 1.0000000e+00, 9.9996716e-01, ..., 9.9977249e-01,\n",
       "        9.9961907e-01, 1.6965065e-04], dtype=float32),\n",
       " 'training_licensing': array([1.2643369e-09, 1.5572624e-09, 1.0375873e-05, ..., 4.0166731e-10,\n",
       "        6.9252914e-04, 2.9069158e-06], dtype=float32),\n",
       " 'training_reliability:maintanability': array([9.9616271e-01, 7.7404926e-04, 1.0657408e-01, ..., 5.5658985e-03,\n",
       "        3.3819985e-02, 2.2447189e-02], dtype=float32),\n",
       " 'training_functionalities': array([1.9418344e-06, 1.2071126e-05, 1.3660118e-03, ..., 1.8029995e-04,\n",
       "        5.9585669e-04, 1.2513903e-04], dtype=float32),\n",
       " 'training_portability': array([0.00775013, 0.97574705, 0.22887349, ..., 0.39903668, 0.03692268,\n",
       "        0.22649093], dtype=float32)}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "characteristics_classifications = calculate_matches( data_sentences, _characteristics_models, _characteristics_tokenizers)\n",
    "display (characteristics_classifications)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotate data for each type of classifications (high confidence, medium, low + the confidence score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T17:34:47.193991Z",
     "start_time": "2019-10-04T17:34:47.160619Z"
    }
   },
   "outputs": [],
   "source": [
    "class ClassificationResult:\n",
    "        \n",
    "    def __init__(self, text, value, level, provenance='Unknown'):\n",
    "        self.text = text\n",
    "        self.confidence_value = value\n",
    "        self.confidence_level = level\n",
    "        self.data_provenance = provenance\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"{} -- {} -- {}\".format(self.text, self.confidence_value, self.confidence_level)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"{} -- {} -- {}\".format(self.text, self.confidence_value, self.confidence_level)\n",
    "        \n",
    "        \n",
    "def split_sentences_by_confidence (calculated_classifications, _sentences, _sentences_provenance):\n",
    "\n",
    "    stratified_classifications = {}\n",
    "\n",
    "    for k in calculated_classifications.keys():\n",
    "        classifications = calculated_classifications[k]\n",
    "\n",
    "        ## Low level percentile\n",
    "        low_percentile = np.percentile(classifications, 33)#0.2\n",
    "        classifications_low = np.where(classifications<=low_percentile)[0]\n",
    "        #print(classifications_low)\n",
    "\n",
    "        ## Medium level percentile\n",
    "        medium_percentile = np.percentile(classifications, 66)#0.8\n",
    "        classifications_medium = np.where((classifications<=medium_percentile) & (classifications>low_percentile))[0]\n",
    "        #print(classifications_medium)\n",
    "\n",
    "        ## High level percentile\n",
    "        top_percentile = np.percentile(classifications, 100) #1.0\n",
    "        classifications_top = np.where((classifications<=top_percentile) & (classifications>medium_percentile))[0]\n",
    "        #print(classifications_top)\n",
    "       \n",
    "        classified_sentences = []\n",
    "        #print(classifications_low)\n",
    "        for i1 in classifications_low:\n",
    "            c1 = ClassificationResult(_sentences[i1], classifications[i1], \"Low\", _sentences_provenance[i1])\n",
    "            classified_sentences.append(c1)\n",
    "\n",
    "        for i2 in classifications_medium:\n",
    "            c2 = ClassificationResult(_sentences[i2], classifications[i2], \"Medium\", _sentences_provenance[i2])\n",
    "            classified_sentences.append(c2)\n",
    "\n",
    "        for i3 in classifications_top:\n",
    "            c3 = ClassificationResult(_sentences[i3], classifications[i3], \"High\", _sentences_provenance[i3])\n",
    "            classified_sentences.append(c3)\n",
    "            \n",
    "        stratified_classifications[clean_file_name(k)] = classified_sentences\n",
    "    return stratified_classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conventions results sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T17:39:10.168413Z",
     "start_time": "2019-10-04T17:38:22.568838Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_Domestic\n",
      "training_Civic\n",
      "training_Project\n",
      "training_Inspired\n",
      "training_Green\n",
      "training_Market\n",
      "training_Industrial\n",
      "training_Renown\n",
      "Concatenate all files to one\n",
      "Applying one hot encoding to convention to have format suitable for audit tool (binary and for all)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'aideenf'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'aid99rk4'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'AIVC'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['./Data/Iterative-models-building/Classification results/Conventions/audit_training_data.gz']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['cp_wssc/Data/Iterative-models-building/Classification results/Conventions/audit_training_data.gz']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file to commit: ./Data/Iterative-models-building/Classification results/Conventions/audit_training_data.gz\n",
      "push to git as: cp_wssc/Data/Iterative-models-building/Classification results/Conventions/audit_training_data.gz\n",
      "got here 2\n",
      "got here 3\n",
      "File commited to github : GitCommit(sha=\"95788fa203ee8f23f16c8a45facc2f5677291883\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>confidence_value</th>\n",
       "      <th>confidence_level</th>\n",
       "      <th>data_provenance</th>\n",
       "      <th>convention_civic</th>\n",
       "      <th>convention_domestic</th>\n",
       "      <th>convention_green</th>\n",
       "      <th>convention_industrial</th>\n",
       "      <th>convention_inspired</th>\n",
       "      <th>convention_market</th>\n",
       "      <th>convention_project</th>\n",
       "      <th>convention_renown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Provides easily configurable data import progr...</td>\n",
       "      <td>0.00039</td>\n",
       "      <td>Low</td>\n",
       "      <td>efficiency</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Runs on industry standard hardware.</td>\n",
       "      <td>0.00038</td>\n",
       "      <td>Low</td>\n",
       "      <td>efficiency</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  confidence_value  \\\n",
       "0  Provides easily configurable data import progr...           0.00039   \n",
       "1               Runs on industry standard hardware.            0.00038   \n",
       "\n",
       "  confidence_level data_provenance  convention_civic  convention_domestic  \\\n",
       "0              Low      efficiency                 0                    1   \n",
       "1              Low      efficiency                 0                    1   \n",
       "\n",
       "   convention_green  convention_industrial  convention_inspired  \\\n",
       "0                 0                      0                    0   \n",
       "1                 0                      0                    0   \n",
       "\n",
       "   convention_market  convention_project  convention_renown  \n",
       "0                  0                   0                  0  \n",
       "1                  0                   0                  0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>confidence_value</th>\n",
       "      <th>confidence_level</th>\n",
       "      <th>data_provenance</th>\n",
       "      <th>convention_civic</th>\n",
       "      <th>convention_domestic</th>\n",
       "      <th>convention_green</th>\n",
       "      <th>convention_industrial</th>\n",
       "      <th>convention_inspired</th>\n",
       "      <th>convention_market</th>\n",
       "      <th>convention_project</th>\n",
       "      <th>convention_renown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26338</th>\n",
       "      <td>We show empirically that our techniques can ou...</td>\n",
       "      <td>0.334971</td>\n",
       "      <td>High</td>\n",
       "      <td>Semantic Scholar</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26339</th>\n",
       "      <td>In particular, bounding the memory use in indi...</td>\n",
       "      <td>0.264850</td>\n",
       "      <td>High</td>\n",
       "      <td>Semantic Scholar</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  confidence_value  \\\n",
       "26338  We show empirically that our techniques can ou...          0.334971   \n",
       "26339  In particular, bounding the memory use in indi...          0.264850   \n",
       "\n",
       "      confidence_level   data_provenance  convention_civic  \\\n",
       "26338             High  Semantic Scholar                 0   \n",
       "26339             High  Semantic Scholar                 0   \n",
       "\n",
       "       convention_domestic  convention_green  convention_industrial  \\\n",
       "26338                    0                 0                      0   \n",
       "26339                    0                 0                      0   \n",
       "\n",
       "       convention_inspired  convention_market  convention_project  \\\n",
       "26338                    0                  0                   0   \n",
       "26339                    0                  0                   0   \n",
       "\n",
       "       convention_renown  \n",
       "26338                  1  \n",
       "26339                  1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#AF - Modified below code (line 13 and 17) to add the \"convention\" in question to the generated file.\n",
    "\n",
    "conv_stratified_classifications = split_sentences_by_confidence(conventions_classifications, data_sentences, data_sentences_provenance)\n",
    "\n",
    "file_list = []\n",
    "  \n",
    "for k in conv_stratified_classifications.keys():\n",
    "    print (k)\n",
    "    with open(os.path.join(BASE_DIR, \"Classification results\", CONVS_DIR_NAME, \"{}_stratified_classifications.tsv\".format(k)), \"w\")as f3:\n",
    "        \n",
    "        file_list.append(BASE_DIR +\"/Classification results/\"+CONVS_DIR_NAME + \"/{}_stratified_classifications.tsv\".format(k))\n",
    "        \n",
    "        f3.write(\"{}\\t{}\\t{}\\t{}\\t{}\\n\".format(\"text\", \"convention\", \"confidence_value\", \"confidence_level\", \"data_provenance\"))\n",
    "    \n",
    "        for c in conv_stratified_classifications[k]:\n",
    "            convention = k.replace(\"training_\", \"\").lower()     \n",
    "            f3.write(\"{}\\t{}\\t{}\\t{}\\t{}\\n\".format(c.text, convention, c.confidence_value, c.confidence_level, c.data_provenance))\n",
    "        f3.close()\n",
    "        \n",
    "\n",
    "        \n",
    "##############CODE ADDED BY AIDEEN#######################################################\n",
    "#Create an aggregated DataFrame and then a tsv/csv file of the full data for auditing\n",
    "#This code is to create a file and push it to git hub to be read by the audit tool only\n",
    "# This is independant piece of code, removing it will only remove this functionality\n",
    "# leaving it here means that when we retrain the model this file will be auto updated with\n",
    "# new labels. (to discuss with David - to revert this to the format that can be used by the \n",
    "# model training process)\n",
    "df_list = [pd.read_csv(file, sep='\\t') for file in file_list]\n",
    "#concatenate them \n",
    "print(\"Concatenate all files to one\")\n",
    "convention_sentences_df = pd.concat(df_list)\n",
    "## We will perform one hot encoding\n",
    "print(\"Applying one hot encoding to convention to have format suitable for audit tool (binary and for all)\")\n",
    "convention_sentences_df[\"convention\"] = pd.Categorical(convention_sentences_df[\"convention\"])\n",
    "dfDummies = pd.get_dummies(convention_sentences_df[\"convention\"], prefix=\"convention\")\n",
    "convention_sentences_df = pd.concat([convention_sentences_df, dfDummies], axis=1)\n",
    "convention_sentences_df = convention_sentences_df.drop([\"convention\"], axis=1)\n",
    "\n",
    "## Now we will save a file 'audit_training_data.tsv'  and zipped version locally which contains all of the results\n",
    "file_name = 'audit_training_data.tsv'\n",
    "file_name_zip = 'audit_training_data.gz'\n",
    "\n",
    "file_path = BASE_DIR +\"/Classification results/\"+CONVS_DIR_NAME +\"/\"\n",
    "convention_sentences_df.to_csv(file_path + file_name)\n",
    "convention_sentences_df.to_csv(file_path + file_name_zip, compression='gzip')\n",
    "\n",
    "## We will also push this to git hub for use by audit tool\n",
    "if(USE_GIT_HUB == True):\n",
    "    #Call helper file to zip the file for push to github\n",
    "    my_file_list = [file_path + file_name_zip]\n",
    "    push_to_git_as = ['cp_wssc/Data/Iterative-models-building/Classification results/Conventions/'+file_name_zip]\n",
    "    save_to_github(GIT_USER, GIT_PSWD, GIT_REPO, my_file_list, push_to_git_as)\n",
    "    \n",
    "display (convention_sentences_df.head(2))\n",
    "display (convention_sentences_df.tail(2))\n",
    "\n",
    "############################END CODE ADDED BY AIDEEN####################################################\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T17:37:14.193560Z",
     "start_time": "2019-10-04T17:37:14.187104Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provides easily configurable data import programs. \n",
      "Runs on industry standard hardware. \n"
     ]
    }
   ],
   "source": [
    "print(conv_stratified_classifications['training_Domestic'][0].text)\n",
    "print(conv_stratified_classifications['training_Domestic'][1].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T17:34:59.848056Z",
     "start_time": "2019-10-04T17:34:59.838084Z"
    }
   },
   "source": [
    "# software Characteristics results sampling -  \n",
    "\n",
    "    - Nothing modified from below here.\n",
    "\n",
    "    - AF: As per Meeting the focus should be on the conventions and labeling convention data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chars_stratified_classifications = split_sentences_by_confidence(characteristics_classifications, data_sentences, data_sentences_provenance)\n",
    "for k in conv_stratified_classifications.keys():\n",
    "    with open(os.path.join(BASE_DIR, \"Classification results\", SOFT_CHARS_DIR_NAME, \"{}_stratified_classifications.tsv\".format(k)), \"w\")as f3:\n",
    "\n",
    "        f3.write(\"{}\\t{}\\t{}\\n\".format(\"text\", \"confidence_value\", \"confidence_level\", \"data_provenance\"))\n",
    "    \n",
    "        for c in conv_stratified_classifications[k]:\n",
    "            \n",
    "            f3.write(\"{}\\t{}\\t{}\\t{}\\n\".format(c.text, c.confidence_value, c.confidence_level, c.data_provenance))\n",
    "\n",
    "        f3.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps to be done manually:\n",
    "\n",
    "### ~~4.- Manually validate data~~\n",
    "### ~~5.- Append data to training files ~~\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.- Retrain new models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_new_text_pipelineNB(texts, labels1):\n",
    "    text_clf = Pipeline([\n",
    "        ('vect', CountVectorizer(max_df=0.85, stop_words=stopwords, max_features=FEATURES_LENGTH)),\n",
    "        ('tfidf', TfidfTransformer(smooth_idf=True,use_idf=True)),\n",
    "        ('clf', MultinomialNB()),\n",
    "    ])\n",
    "    \n",
    "    text_clf.fit(texts, labels1)  \n",
    "    \n",
    "    return text_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mypath = \"Data/VALIDATED_DATA/Conventions/\"\n",
    "training_files = [f for f in os.listdir(mypath) if (os.path.isfile(os.path.join(mypath, f)) and \"training\" in f and not f.startswith( '.' )) and not \"random\" in f]#[:2]\n",
    "training_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_LENGTH = 3000\n",
    "VALIDATION_SPLIT = 0.25\n",
    "GENERATE_NEW_TRAINING_FILES = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_stop_words(stop_file_path):\n",
    "    \"\"\"load stop words \"\"\"\n",
    "    \n",
    "    with open(stop_file_path, 'r', encoding=\"utf-8\") as f:\n",
    "        stopwords = f.readlines()\n",
    "        stop_set = set(m.strip() for m in stopwords)\n",
    "        return frozenset(stop_set)\n",
    "#load a set of stop words\n",
    "stopwords=get_stop_words(\"resources/stopwords.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_line(X):\n",
    "    \n",
    "    stemmer = WordNetLemmatizer()\n",
    "\n",
    "    # Remove all the special characters\n",
    "    document = re.sub(r'\\W', ' ', str(X))\n",
    "\n",
    "    # remove all single characters\n",
    "    document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
    "\n",
    "    # Remove single characters from the start\n",
    "    document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document) \n",
    "\n",
    "    # Substituting multiple spaces with single space\n",
    "    document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
    "\n",
    "    # Removing prefixed 'b'\n",
    "    document = re.sub(r'^b\\s+', '', document)\n",
    "\n",
    "    # Converting to Lowercase\n",
    "    document = document.lower()\n",
    "\n",
    "    # Lemmatization\n",
    "    document = document.split()\n",
    "\n",
    "    document2 = [stemmer.lemmatize(word) for word in document]\n",
    "    document = ' '.join(document2)\n",
    "\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_str(text):\n",
    "    documents = []\n",
    "    ret = documents\n",
    "    if type(text == \"list\"):\n",
    "        #print(\"list: \", text)\n",
    "        for X in text:\n",
    "            documents.append(clean_line(X))\n",
    "    \n",
    "        ret =\"\"\n",
    "        if(len(documents)>1):\n",
    "\n",
    "            for d in documents:\n",
    "                ret+=d+\"\\n\"\n",
    "        else:\n",
    "            ret = documents[0]\n",
    "        \n",
    "    elif type(text)==\"str\":\n",
    "        p#rint(\"str\")\n",
    "        ret = clear_line(text)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_conv_ML_models = {}\n",
    "_test_data_x = {}\n",
    "_test_data_y = {}\n",
    "\n",
    "\n",
    "for f in training_files:\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "    print(\"            {}                  \".format(f))\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "\n",
    "    \n",
    "    \n",
    "    ## USING licensing text from github\n",
    "    data_train = pd.read_csv(mypath+f, sep='\\t')\n",
    "\n",
    "    #data_train = pd.read_csv('Data/TRAINING_0/training_contributions.txt', sep='\\t')\n",
    "\n",
    "    print(data_train.shape)\n",
    "\n",
    "    _texts = []\n",
    "    _labels = []\n",
    "\n",
    "    for idx in range(data_train.text.shape[0]):\n",
    "        \n",
    "        text = [data_train.text[idx]] #BeautifulSoup(data_train.text[idx])\n",
    "        \n",
    "        _texts.append(clean_str(text))#.encode('ascii','ignore')))\n",
    "        _labels.append(int(data_train.category[idx]))\n",
    "        \n",
    "    #SHUFFLE and DATA SPLITTING \n",
    "    x_train, x_val, y_train, y_val = train_test_split(_texts, _labels, test_size=VALIDATION_SPLIT, random_state=42)\n",
    "    \n",
    "    _test_data_x[f] = np.array(x_val)[np.where(np.array(y_val)==1)]\n",
    "    _test_data_y[f] = np.array(y_val)[np.where(np.array(y_val)==1)]\n",
    "    \n",
    "    model1 = train_new_text_pipelineNB(x_train, y_train)\n",
    "    tmp_pred = model1.predict(x_val)\n",
    "    print(\"Accuracy: {}\".format(np.mean(tmp_pred == y_val)))\n",
    "\n",
    "    _conv_ML_models[f] = model1\n",
    "    \n",
    "    #print(\"  Naive-Bayes: \",mean1)\n",
    "    #print(\"  Random-Forest: \",mean2)\n",
    "    #print(metrics.classification_report(_labels, pred))\n",
    "        \n",
    "    print(\"\\n\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_matches_proba_ML(_data, model):\n",
    "    preds = model.predict_proba(_data)\n",
    "\n",
    "    return preds[:,1]\n",
    "\n",
    "def calculate_matches_ML(_sentences, _models):\n",
    "    _repos_matches = {}\n",
    "\n",
    "    ## Getting classification confidence per model for each repo\n",
    "    for model_key in _models.keys():\n",
    "            \n",
    "\n",
    "        preds = get_model_matches_proba_ML(_sentences, _models[model_key])\n",
    "\n",
    "        _repos_matches[clean_file_name(model_key)] = preds\n",
    "    return _repos_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_matches_mixture(_sentences, _modelsML, _modelsDL, _tokenizersDL):\n",
    "    _repos_matches = {}\n",
    "\n",
    "    ## Getting classification confidence per model for each repo\n",
    "    for model_key in _modelsML.keys():\n",
    "            \n",
    "        tokenized_sentences = _tokenizersDL[model_key].texts_to_sequences(_sentences)\n",
    "        preds1 = get_model_matches_proba(tokenized_sentences, _modelsDL[model_key])\n",
    "        preds2 = get_model_matches_proba_ML(_sentences, _modelsML[model_key])\n",
    "\n",
    "        _repos_matches[clean_file_name(model_key)] = preds1+preds2\n",
    "    return _repos_matches\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conv_ML_matches = calculate_matches_ML( data_sentences, _conv_ML_models)\n",
    "conv_ML_matches = calculate_matches_mixture( data_sentences, _conv_ML_models, _conventions_models, _conventions_tokenizers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_conv_ML_models['training_Domestic.txt'].predict_proba([data_sentences[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confidence_value(C):\n",
    "    return C.confidence_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Conventions results sampling\n",
    "conv_stratified_classifications = split_sentences_by_confidence(conv_ML_matches, data_sentences, data_sentences_provenance)\n",
    "\n",
    "for k in conv_stratified_classifications.keys():\n",
    "    with open(os.path.join(BASE_DIR, \"Classification results\", CONVS_DIR_NAME, \"ML_{}_stratified_classifications.tsv\".format(k)), \"w\")as f3:\n",
    "\n",
    "        f3.write(\"{}\\t{}\\t{}\\t{}\\n\".format(\"text\", \"confidence_value\", \"confidence_level\", \"data_provenance\"))\n",
    "    \n",
    "        for c in sorted(conv_stratified_classifications[k],key=get_confidence_value, reverse=True):\n",
    "            \n",
    "            f3.write(\"{}\\t{}\\t{}\\t{}\\n\".format(c.text, c.confidence_value, c.confidence_level, c.data_provenance))\n",
    "\n",
    "        f3.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_stratified_classifications.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_stratified_classifications['training_Civic'],"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
