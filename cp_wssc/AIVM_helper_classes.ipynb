{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- markdown_to_text()\n",
    "- remove_nums_from_str(s)\n",
    "- pre_process_sentence(sent)\n",
    "- pre_process(textBlob) returns tokenized to sentences\n",
    "- remove_excluded_files(file_list)\n",
    "- remove_excluded_files_except(file_list, except_with_text)\n",
    "- rreplace(s, old, new, occurrence)\n",
    "- clean_file_name(name, replacements2=[]):\n",
    "- def save_to_github(git_user, git_password, git_repo, my_file_list, push_to_git_as):\n",
    "- keep_pdf_urls_only(file_list):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-06T12:30:42.963135Z",
     "start_time": "2019-10-06T12:30:42.859460Z"
    }
   },
   "outputs": [],
   "source": [
    "# Required Python utilities\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter\n",
    "import re\n",
    "from langdetect import detect\n",
    "from bs4 import BeautifulSoup\n",
    "from markdown import markdown\n",
    "from lxml import etree\n",
    "import os\n",
    "import random\n",
    "import tqdm\n",
    "import itertools \n",
    "import pickle\n",
    "\n",
    "## Deep Learning imports for the classifiers\n",
    "os.environ['KERAS_BACKEND']='theano'\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dense, Input, Flatten\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding, Dropout, Concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "##Â ML required imports (for clustering)\n",
    "from sklearn import metrics\n",
    "from sklearn.decomposition import PCA, LatentDirichletAllocation\n",
    "from sklearn.preprocessing import scale, StandardScaler\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "\n",
    "\n",
    "# Topic modeling imports\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "##Â NLP related imports\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "\n",
    "# visualization imports\n",
    "from IPython.display import display\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import base64\n",
    "import io\n",
    "%matplotlib inline\n",
    "sns.set() \n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "import base64\n",
    "from github import Github\n",
    "from github import InputGitTreeElement\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-06T12:30:43.538935Z",
     "start_time": "2019-10-06T12:30:43.530647Z"
    }
   },
   "outputs": [],
   "source": [
    "def markdown_to_text(markdown_string):\n",
    "    \"\"\" Converts a markdown string to plaintext \"\"\"\n",
    "\n",
    "    # md -> html -> text since BeautifulSoup can extract text cleanly\n",
    "    html = markdown(markdown_string)\n",
    "\n",
    "    # remove code snippets\n",
    "    html = re.sub(r'<pre>(.*?)</pre>', ' ', html)\n",
    "    html = re.sub(r'<code>(.*?)</code >', ' ', html)\n",
    "\n",
    "    # extract text\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    text = ''.join(soup.findAll(text=True))\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-06T21:31:21.384957Z",
     "start_time": "2019-10-06T21:31:21.379666Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_nums_from_str(s):\n",
    "    result = ''.join([i for i in s if not i.isdigit()])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-06T23:32:13.111547Z",
     "start_time": "2019-10-06T23:32:13.090734Z"
    }
   },
   "outputs": [],
   "source": [
    "def pre_process_sentence(sent):\n",
    "    sent = re.sub('-', ' ', sent, flags=re.MULTILINE) # Added by Aideen\n",
    "    sent = re.sub(' +', ' ', sent, flags=re.MULTILINE) # Added by Aideen\n",
    "    sent = sent.replace(\";\", \", \")\n",
    "    sent = re.sub(' +', ' ', sent, flags=re.MULTILINE) # Added by Aideen\n",
    "    sent = sent.strip()\n",
    "    sent = sent.lstrip()\n",
    "    sent = sent.rstrip()\n",
    "    sent = remove_nums_from_str(sent.replace(\",\", \" \"))\n",
    "    sent = sent.replace(\"  \", \" \")\n",
    "    sent = sent.replace(\" .\", \".\")\n",
    "\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-06T21:08:47.175245Z",
     "start_time": "2019-10-06T21:08:47.163398Z"
    }
   },
   "outputs": [],
   "source": [
    "def pre_process(text):\n",
    "    \n",
    "    \n",
    "    # Removing prefixed 'b'\n",
    "    document = re.sub(r'^b\\s+', '', str(text))\n",
    "    \n",
    "    #Removing splicit line change\n",
    "    document = re.sub(r'\\\\n', '', document, flags=re.MULTILINE)\n",
    "    \n",
    "    \n",
    "    soup = BeautifulSoup(document)\n",
    "    \n",
    "    #Remove HTML code from text\n",
    "    document = soup.get_text() \n",
    "    \n",
    "    # Parse text from markdown code\n",
    "    document = markdown_to_text(document)\n",
    "        \n",
    "    ## Removing URLS\n",
    "    document = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', document, flags=re.MULTILINE)\n",
    "    \n",
    "    ## Removing strings such as \\\\xe5 \\\\xe6 \\\\xe7 that appear a lot in the descriptions\n",
    "    document = re.sub(r':?\\\\+x\\w{2}', ' ', document, flags=re.MULTILINE)\n",
    "\n",
    "    # Remove all the special characters except spaces, dashes, commas and dots\n",
    "    document = re.sub(r\"[^\\s.,\\-a-zA-Z0-9]\", ' ', str(document))\n",
    "    \n",
    "    # Substituting multiple spaces with single space\n",
    "    document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
    "    \n",
    "    # Substituting multiple '-' with single '-'\n",
    "    document = re.sub(r'\\-{2,50}', '', document, flags=re.I)\n",
    "    \n",
    "    document = re.sub('-', ' ', document, flags=re.MULTILINE) # Added by Aideen\n",
    "    document = re.sub(' +', ' ', document, flags=re.MULTILINE) # Added by Aideen\n",
    "    document.replace(\";\", \", \")\n",
    "    document = re.sub(' +', ' ', document, flags=re.MULTILINE) # Added by Aideen\n",
    "    # Converting to Lowercase\n",
    "    document = document.lower()\n",
    "    \n",
    "    # Sentences Tokenization\n",
    "    return sent_tokenize(document)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-06T23:50:19.228694Z",
     "start_time": "2019-10-06T23:50:19.192262Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_excluded_files(file_list):\n",
    "    cleaned_file_list = []\n",
    "    for f in file_list:\n",
    "        if not f.startswith( '.' ) and not \"random\" in f and \"gathered_\" in f and not f.startswith(\"_\"):\n",
    "            cleaned_file_list.append(f)\n",
    "    return cleaned_file_list\n",
    "\n",
    "def keep_pdf_urls_only(file_list):\n",
    "    cleaned_file_list = []\n",
    "    for f in file_list:\n",
    "        if f.endswith( '.pdf' ) and not \" \" in f:\n",
    "            cleaned_file_list.append(f)\n",
    "    return cleaned_file_list\n",
    "\n",
    "def remove_excluded_files_except(file_list, except_with_text):\n",
    "    cleaned_file_list = []\n",
    "    for f in file_list:\n",
    "        if not f.startswith( '.' ) and not \"random\" in f and except_with_text in f and not f.startswith(\"_\"):\n",
    "            cleaned_file_list.append(f)\n",
    "    return cleaned_file_list\n",
    "        \n",
    "def rreplace(s, old, new, occurrence):\n",
    "    li = s.rsplit(old, occurrence)\n",
    "    return new.join(li)\n",
    "\n",
    "\n",
    "def clean_file_name(name, replacements2=[]):\n",
    "    \n",
    "    replacements=[\".txt\", \".csv\", \".tsv\"]\n",
    "    \n",
    "    for r in replacements:\n",
    "        name = name.replace(r, \"\")\n",
    "        \n",
    "    for r in replacements2:\n",
    "        name = name.replace(r, \"\")\n",
    "    return name\n",
    "\n",
    "\n",
    "def save_to_github(git_user, git_password, git_repo, my_file_list, push_to_git_as):\n",
    "    '''\n",
    "    in order to push a file to github it must first be stored locally, then pushed\n",
    "    this local location can also be local to a virtual machine. \n",
    "    takes: \n",
    "            git username, password, repo, \n",
    "            a list of files to push to git ie the full local location of file,\n",
    "            a matching list of paths to push each file to in Git hub \n",
    "    '''\n",
    "    user = git_user\n",
    "    password = git_password\n",
    "    url = git_repo\n",
    "    file_list = []  #push these list of files to git\n",
    "    file_names = [] #push to this location in git\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        g = Github(user, password)\n",
    "        repo = g.get_user().get_repo(url)\n",
    "\n",
    "        file_list = my_file_list \n",
    "        file_names = push_to_git_as\n",
    "                 \n",
    "        commit_message = 'training data updated via the audit tool'\n",
    "    \n",
    "        master_ref = repo.get_git_ref('heads/master')\n",
    "        master_sha = master_ref.object.sha\n",
    "        base_tree = repo.get_git_tree(master_sha)\n",
    "        element_list = list()\n",
    "\n",
    "        for i, entry in enumerate(file_list):\n",
    "            print (\"file to commit:\", entry)\n",
    "            \n",
    "            with open(entry) as input_file:\n",
    "                #data = input_file.read()   #works with non zip file\n",
    "                data = base64.b64encode(open(entry, \"rb\").read())\n",
    "                \n",
    "            if entry.endswith('.png'):\n",
    "                data = base64.b64encode(data) \n",
    "                \n",
    "\n",
    "            blob = repo.create_git_blob(data.decode(\"utf-8\"), \"base64\")\n",
    "            element = InputGitTreeElement(path=file_names[i], mode='100644', type='blob', sha=blob.sha)\n",
    "\n",
    "            #push to git as file_names[i]\n",
    "            print (\"push to git as:\", file_names[i])\n",
    "            \n",
    "            #element = InputGitTreeElement(file_names[i], '100644', 'blob', data)\n",
    "            \n",
    "            #element_list is a list of InputGitTreeElement. \n",
    "            #Each one corresponds to a file. \n",
    "            # the 'content' of InputGitTreeElement can only be of type 'str' or 'unicode'. \n",
    "            #When I load a file to memory I have type 'bytes'. \n",
    "            #What is the right way to encode those bytes to str or unicode to upload a .zip\n",
    "            element_list.append(element)   \n",
    "        \n",
    "        tree = repo.create_git_tree(element_list, base_tree)\n",
    "        parent = repo.get_git_commit(master_sha)\n",
    "        commit = repo.create_git_commit(commit_message, tree, [parent])\n",
    "        master_ref.edit(commit.sha)\n",
    "        print (\"File commited to github :\", commit)\n",
    "    except e:\n",
    "        print(\"\")\n",
    "        print (\"GITHUB SUBMIT FAILED:\")\n",
    "        print (\"Are your github login credentials correct?\")\n",
    "        print (\"Are you a collaberator in the repo?\")\n",
    "        print(e)\n",
    "\n",
    "\n",
    "\n",
    "def save_to_github_not_zip(git_user, git_password, git_repo, my_file_list, push_to_git_as):\n",
    "    user = git_user\n",
    "    password = git_password\n",
    "    url = git_repo\n",
    "    file_list = []  #push these list of files to git\n",
    "    file_names = [] #push to this location in git\n",
    "    \n",
    "    try:\n",
    "        g = Github(user,password)\n",
    "        repo = g.get_user().get_repo(url)\n",
    "\n",
    "        file_list = my_file_list \n",
    "        file_names = push_to_git_as\n",
    "                 \n",
    "        commit_message = 'training data audited via the audit tool'\n",
    "    \n",
    "        master_ref = repo.get_git_ref('heads/master')\n",
    "        master_sha = master_ref.object.sha\n",
    "        base_tree = repo.get_git_tree(master_sha)\n",
    "        element_list = list()\n",
    "\n",
    "        for i, entry in enumerate(file_list):\n",
    "            print (\"open\", entry)\n",
    "            with open(entry) as input_file:\n",
    "                data = input_file.read()\n",
    "            if entry.endswith('.png'):\n",
    "                data = base64.b64encode(data)\n",
    "                \n",
    "            print (\"file to commit:\", entry)\n",
    "            print (\"push to git as:\", file_names[i])\n",
    "            element = InputGitTreeElement(file_names[i], '100644', 'blob', data)\n",
    "            element_list.append(element)\n",
    "            \n",
    "        tree = repo.create_git_tree(element_list, base_tree)\n",
    "        parent = repo.get_git_commit(master_sha)\n",
    "        commit = repo.create_git_commit(commit_message, tree, [parent])\n",
    "        master_ref.edit(commit.sha)\n",
    "\n",
    "        return commit\n",
    "\n",
    "    except IOError as e:\n",
    "        print (\"GITHUB SUBMIT FAILED:\")\n",
    "        print (\"Are your github login credentials correct?\")\n",
    "        print (\"Are you a collaberator in the repo?\")\n",
    "        print (e)\n",
    "        return \"error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.6 PyEnv",
   "language": "python",
   "name": "python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
