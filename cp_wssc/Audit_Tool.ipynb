{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UI to conduct a manual audit of the labels from conventions classifiers. \n",
    "\n",
    "\n",
    "# ***IF NOT USING BINDER - UNCHECK THE BOX***\n",
    "\n",
    "\n",
    "The output of the classifier via Iterative_Models_building.ipyng are stored to\n",
    "\n",
    "    -file 'audit_training_data.gz (which is a zipped pandas database) \n",
    "    -location: cp_wssc/Data/Iterative-models-building/Classification results/Conventions/\n",
    "\n",
    "The UI randomly displays an already classified sentence for the purpose of audit and correction\n",
    "\n",
    "Completed audits will be stored locally until the \"Save to GIT\" button is selected, in which case the tsv of audit will be stored to \n",
    "\n",
    "    - file 'audit_training_data-{gituser}{date}.tsv \n",
    "    -location: cp_wssc/Data/Iterative-models-building/Classification results/Conventions/Audited/\n",
    "\n",
    "Content of the Audited files may be coccat and added to the Train_Validate data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T00:57:03.495827Z",
     "start_time": "2019-12-17T00:56:56.859298Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from IPython.display import display, clear_output, HTML, Image, IFrame\n",
    "import base64\n",
    "import io\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "import base64\n",
    "from github import Github, GithubException\n",
    "from github import InputGitTreeElement\n",
    "import requests\n",
    "import time\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import urllib.request\n",
    "import requests as req\n",
    "import spacy\n",
    "\n",
    "_ = !python3 -m spacy download en_core_web_sm\n",
    "import en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T21:09:10.635385Z",
     "start_time": "2019-12-16T21:09:09.718Z"
    }
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "//To remove scroll from any output area and automatically extend the jupyter cell\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T21:09:11.010169Z",
     "start_time": "2019-12-16T21:09:10.997547Z"
    }
   },
   "outputs": [],
   "source": [
    "FLAG__ON_BINDER = True\n",
    "FLAG__FROM_GIT = True\n",
    "DOWNLOAD_TSV_PATH = './Data/Iterative-models-building/Classification results/Conventions/Audited/'\n",
    "\n",
    "########These are all defined in the shared helper files should modify to point there####\n",
    "GIT_OWNER = 'aideenf'\n",
    "GIT_REPO = 'AIVC'\n",
    "RESOURCES_DIR_LOCAL = 'Data/Iterative-models-building/Resources/'\n",
    "RESOURCES_DIR_GIT = 'cp_wssc/Data/Iterative-models-building/Resources/'\n",
    "RESOURCES_URL_GIT = 'https://github.com/aideenf/AIVC/blob/master/cp_wssc/Data/Iterative-models-building/Resources/'\n",
    "CLASSIFIED_DATA_DIR_LOCAL  = './Data/Iterative-models-building/Classification results/Conventions/'\n",
    "CLASSIFIED_DATA_DIR_GIT =  'cp_wssc/Data/Iterative-models-building/Classification results/Conventions/'\n",
    "GITHUB_CLASSIFIED_DATA_URL_PATH = 'https://raw.githubusercontent.com/aideenf/AIVC/master/cp_wssc/Data/Iterative-models-building/Classification%20results/Conventions/'\n",
    "\n",
    "AUDITED_DATA_DIR_LOCAL  = './Data/Iterative-models-building/Classification results/Conventions/Audited'\n",
    "AUDITED_DATA_DIR_GIT =  'cp_wssc/Data/Iterative-models-building/Classification results/Conventions/Audited'\n",
    "###########                 \n",
    "\n",
    "my_style = {'description_width': 'initial'}\n",
    "my_layout = {'width': '600px'}\n",
    "my_layout_short = {'width': '300px'}\n",
    "my_layout_shortest = {'width': '200px'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T21:09:15.674386Z",
     "start_time": "2019-12-16T21:09:15.644849Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "167002684f434de39eb28c87e2213cab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=True, description='*MUST un-check thid box IF NOT running on binder', layout=Layout(width='600pâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....loading test tool\n",
      "./Data/Iterative-models-building/Classification results/Conventions/Audited/\n"
     ]
    }
   ],
   "source": [
    "\n",
    "box_binder = widgets.Checkbox(True, description='*MUST un-check thid box IF NOT running on binder', style = my_style, layout = my_layout)\n",
    "\n",
    "def update_box_binder(change):\n",
    "    global FLAG__ON_BINDER\n",
    "    global FILE_PATH\n",
    "    global DOWNLOAD_PATH\n",
    "    FILE_NAME = 'audit_training_data.gz'\n",
    "    FLAG__ON_BINDER = change['new']\n",
    "    if (FLAG__ON_BINDER == True):\n",
    "        DOWNLOAD_PATH = '/home/jovyan/cp_wssc/Data/Iterative-models-building/Classification results/Conventions/'\n",
    "        DOWNLOAD_PATH = DOWNLOAD_PATH + FILE_NAME\n",
    "        FILE_PATH = '/home/jovyan/cp_wssc/Data/Iterative-models-building/Classification results/Conventions/Audited/'\n",
    "\n",
    "    else:\n",
    "        DOWNLOAD_PATH = './Data/Iterative-models-building/Classification results/Conventions/'\n",
    "        DOWNLOAD_PATH = DOWNLOAD_PATH + FILE_NAME\n",
    "        FILE_PATH = './Data/Iterative-models-building/Classification results/Conventions/Audited/'\n",
    "        if not os.path.exists(DOWNLOAD_PATH):\n",
    "            os.makedirs(DOWNLOAD_PATH)\n",
    "\n",
    "        if not os.path.exists(FILE_PATH):\n",
    "            os.makedirs(FILE_PATH)\n",
    "    print (FILE_PATH)\n",
    "   \n",
    "    \n",
    "box_binder.observe(update_box_binder, 'value')\n",
    "\n",
    "display(box_binder)\n",
    "print(\"....loading test tool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T21:09:16.773247Z",
     "start_time": "2019-12-16T21:09:16.764738Z"
    }
   },
   "outputs": [],
   "source": [
    "FILE_NAME = 'audit_training_data.gz'\n",
    "TOTAL_RECORDS_AUDITED = 0\n",
    "TOTAL_UNSAVED_AUDITS = 0\n",
    "LAST_SAVED = \"\"\n",
    "LAST_FILE_SAVED = \"\"\n",
    "\n",
    "if FLAG__ON_BINDER == True:\n",
    "    DOWNLOAD_PATH = '/home/jovyan/cp_wssc/Data/Iterative-models-building/Classification results/Conventions/'\n",
    "    DOWNLOAD_PATH = DOWNLOAD_PATH + FILE_NAME\n",
    "    FILE_PATH = '/home/jovyan/cp_wssc/Data/Iterative-models-building/Classification results/Conventions/Audited/'\n",
    "    \n",
    "else:\n",
    "    DOWNLOAD_PATH = './Data/Iterative-models-building/Classification results/Conventions/'\n",
    "    DOWNLOAD_PATH = DOWNLOAD_PATH + FILE_NAME\n",
    "    FILE_PATH = './Data/Iterative-models-building/Classification results/Conventions/Audited/'\n",
    "    \n",
    "if FLAG__FROM_GIT == True:\n",
    "    DOWNLOAD_PATH = 'https://github.com/aideenf/AIVC/blob/master/cp_wssc/Data/Iterative-models-building/Classification%20results/Conventions/audit_training_data.gz?raw=true'\n",
    "    GIT_PUSH_PATH = 'cp_wssc/Data/Iterative-models-building/Classification results/Conventions/Audited/' \n",
    "    IMAGE_PATH = 'https://github.com/aideenf/AIVC/raw/master/cp_wssc/Data/Iterative-models-building/Resources/labelled_data_proportions.png'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T21:09:27.679995Z",
     "start_time": "2019-12-16T21:09:27.669194Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set CSS properties for th elements in dataframe\n",
    "th_props = [\n",
    "  ('font-size', '15px'),\n",
    "  ('text-align', 'center'),\n",
    "  #('font-weight', 'bold'),\n",
    "  ('color', 'grey'),\n",
    "  ('background-color', 'lightgrey'),\n",
    "  ('border-color', 'black'),\n",
    "  ('border-style' ,'solid') ,\n",
    "  ('border-width', '1px'),\n",
    "  ('border-collapse','collapse'),\n",
    "  ('max-width', '700px'),\n",
    "  ('min-width', '700px')\n",
    "  ]\n",
    "  \n",
    "\n",
    "# Set CSS properties for td elements in dataframe\n",
    "td_props = [\n",
    "  ('font-size', '15px'),\n",
    "  ('text-align', 'left'),\n",
    "  #('font-weight', 'bold'),\n",
    "  ('color', 'lightgrey'),\n",
    "  ('background-color', 'grey'),\n",
    "  ('border-color', 'black'),\n",
    "  ('border-style' ,'solid') ,\n",
    "  ('border-width', '1px'),\n",
    "  ('border-collapse','collapse'),\n",
    "  ('height', '100px'),\n",
    "  ('max-width', '700px'),\n",
    "  ('min-width', '700px')\n",
    "  ]\n",
    "\n",
    "# Set table styles\n",
    "styles = [\n",
    "  dict(selector=\"th\", props=th_props),\n",
    "  dict(selector=\"td\", props=td_props)\n",
    "  ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T21:09:28.521614Z",
     "start_time": "2019-12-16T21:09:28.485873Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def image_to_byte_array(image:Image):\n",
    "  imgByteArr = io.BytesIO()\n",
    "  image.save(imgByteArr, format=image.format)\n",
    "  imgByteArr = imgByteArr.getvalue()\n",
    "  return imgByteArr\n",
    "\n",
    "\n",
    "def retrieve_classified_data (path):\n",
    "   \n",
    "    if FLAG__FROM_GIT == True:\n",
    "        # sep='\\t'  to specify tab seperated?\n",
    "        df = pd.read_csv(path, error_bad_lines=False, compression='gzip', header=0, quotechar='\"')\n",
    "\n",
    "    if FLAG__FROM_GIT == False:\n",
    "        df = pd.read_csv(path, sep='\\t')\n",
    "\n",
    "    df = df.drop(df.columns[0], axis=1)\n",
    "    \n",
    "    #print(\"num of records with NaN\", df.isna().sum() )\n",
    "    \n",
    "    #Drop any rows where there is 0 confidence value. \n",
    "    df = df.dropna(subset=['confidence_value'])\n",
    "    #if source is not specified, fill as other. \n",
    "    df['data_provenance'] = df.data_provenance.fillna('other')\n",
    "    row_to_edit = df.sample(n = 1)\n",
    "    index_number = 0     \n",
    "    #print(\"num of records with NaN\", df.isna().sum() )   \n",
    "    #remove rows where text = \"unknown\"\n",
    "    df = df[df['text']!=\"unknown\"]\n",
    "    \n",
    "    print(\"data file loaded:\", len(df.index), \" rows\")\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "    # Method to get the latest aggregate audited data and to return a pandas DB containing the aggregated content.\n",
    "\n",
    "def get_aggregated_classified_data(use_git,\n",
    "                                    data_dir_git,\n",
    "                                    data_dir_local,\n",
    "                                    github_url,\n",
    "                                    git_owner,\n",
    "                                    git_repo):\n",
    "    use_git = use_git\n",
    "    data_dir_git = data_dir_git\n",
    "    data_dir_local = data_dir_local\n",
    "    github_url_path = github_url\n",
    "    git_owner = git_owner\n",
    "    git_repo = git_repo\n",
    "\n",
    "\n",
    "    files = []\n",
    "    data_frames_dict = {}\n",
    "\n",
    "    if (use_git == True):\n",
    "        files = list_files_from_github_dir(git_owner, git_repo, data_dir_git)\n",
    "        files = remove_excluded_files(files)\n",
    "        url = 'https://github.com/aideenf/AIVC/blob/master/cp_wssc/Data/Iterative-models-building/Classification%20results/Conventions/'   \n",
    "        for f in files:\n",
    "            get_file = \"\"\n",
    "            get_file = url + f + '?raw=true'\n",
    "            data_frames_dict[f] = pd.read_csv(get_file, sep='\\t', error_bad_lines=False, index_col = False)\n",
    "\n",
    "    elif (use_git == False):\n",
    "        # For each file() in gathered conventions folder\n",
    "        files = [f for f in os.listdir(data_dir_local)]\n",
    "        files = remove_excluded_files(files)\n",
    "        for f in files:\n",
    "            data_frames_dict[f] = pd.read_csv(os.path.join(data_dir_local, f), sep='\\t', error_bad_lines=False, index_col = False)\n",
    "\n",
    "    data_frame = pd.concat(data_frames_dict.values(), ignore_index=True)\n",
    "    return files, data_frame\n",
    "\n",
    "\n",
    "def remove_excluded_files(file_list):\n",
    "        cleaned_file_list = []\n",
    "        for f in file_list:\n",
    "            if not f.startswith('.') and not \"random\" in f and \"_for_audit_tool\" in f and not f.startswith(\"_\"):\n",
    "                cleaned_file_list.append(f)\n",
    "        return cleaned_file_list\n",
    "\n",
    "def list_files_from_github_dir(owner, repo, path):\n",
    "    \n",
    "        # read data files for source data directly from github.\n",
    "        # to obtain the id for the folder, navigate the tree using\n",
    "        # https://api.github.com/repos/{owner}/{repo}/git/trees/master\n",
    "        # e.g https://api.github.com/repos/aideenf/AIVC/git/trees/master\n",
    "        # once navigated each directory will be of format\n",
    "        # https://api.github.com/repos/aideenf/AIVC/git/trees/{dir_ref}\n",
    "        # exampe dir_ref = 048349b4dd81d95a17129e7fcd5418bdca8309b3\"\n",
    "        \n",
    "        \n",
    "        #Note A commit, or \"revision\", is an individual change to a file (or set of files). \n",
    "        #It's like when you save a file, except with Git, \n",
    "        #every time you save it creates a unique ID (a.k.a. the \"SHA\" or \"hash\") \n",
    "        #that allows you to keep record of what changes were made when and by who.\n",
    "        # in order to list the docs in the latest version of any folder the most up to date\n",
    "        #Sha should be used. \n",
    "        \n",
    "        #in order to get latest must always start at the master\n",
    "        #https://api.github.com/repos/aideenf/AIVC/git/trees/master\n",
    "        \n",
    "        # import requests as req  #we need to ensure we do not get cached response from browser.\n",
    "        \n",
    "        #get the dir for each step in the path\n",
    "        dir_list = path.split('/')\n",
    "        # ['cp_wssc', 'Data', 'Iterative-models-building', 'Classification results', 'Conventions', '']\n",
    "        files = []\n",
    "        headers = {\n",
    "            'Cache-Control': 'no-cache',\n",
    "            'Pragma': 'no-cache',\n",
    "            'If-None-Match': ''\n",
    "            }\n",
    "        \n",
    "        MASTER = 'https://api.github.com/repos/' + owner + '/' + repo + '/git/trees/master'\n",
    "        NEXT = 'https://api.github.com/repos/' + owner + '/' + repo + '/git/trees/'\n",
    "        resp = req.get(MASTER,  headers=headers)\n",
    "        response = json.loads(resp.text)\n",
    "        try:\n",
    "            for value in response['tree']:\n",
    "                if value['path'] == dir_list[0]:\n",
    "                    NEXT_DIR = NEXT + value['sha']\n",
    "            \n",
    "            for d, i in zip(dir_list, range(len(dir_list)-1)):                          \n",
    "                resp = req.get(NEXT_DIR,  headers=headers)\n",
    "                response = json.loads(resp.text)\n",
    "                for value in response['tree']:\n",
    "                    if value['path'] == dir_list[i+1]:\n",
    "                        NEXT_DIR = NEXT + value['sha']\n",
    "                   \n",
    "        \n",
    "            resp = req.get(NEXT_DIR,  headers=headers)\n",
    "            response = json.loads(resp.text)\n",
    "            for value in response['tree']:\n",
    "                files.append(value['path'])\n",
    "            \n",
    "            \n",
    "            \n",
    "            return files\n",
    "        except: \n",
    "            print (response['message'])\n",
    "            return []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the key words from GIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T21:09:30.365391Z",
     "start_time": "2019-12-16T21:09:29.758291Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "urlBase  = 'https://raw.githubusercontent.com/aideenf/AIVC/master/cp_wssc/Data/Iterative-models-building/Resources/keywords_df.csv'\n",
    "dfKeyWords = pd.read_csv(urlBase, index_col = False)\n",
    "list_conv = list (pd.unique(dfKeyWords['convention']))\n",
    "conventions = list (pd.unique(dfKeyWords['convention']))\n",
    "list_conv.sort()\n",
    "conventions.sort()\n",
    "keyword_de_dict = {}\n",
    "keyword_td_dict = {}\n",
    "for conv in list_conv:\n",
    "    keyword_de_dict[conv] = dfKeyWords.loc[(dfKeyWords['convention'] == conv) & (dfKeyWords['source'] == \"domain_expert\"), 'word'].tolist()\n",
    "    keyword_td_dict[conv] = dfKeyWords.loc[ (dfKeyWords['convention'] == conv) & (dfKeyWords['source'] != \"domain_expert\"), 'word'].tolist()\n",
    "    \n",
    "list_conv = np.insert(list_conv, 0, \"text\")\n",
    "list_conv = np.insert(list_conv, 1, \"provenance\")\n",
    "\n",
    "audited_df = pd.DataFrame(columns=list_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T21:09:52.335314Z",
     "start_time": "2019-12-16T21:09:30.571913Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Total number of sentences'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "192834"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "classified_data_files, convention_sentences_df = get_aggregated_classified_data (\n",
    "                            True,\n",
    "                            CLASSIFIED_DATA_DIR_GIT,\n",
    "                            CLASSIFIED_DATA_DIR_LOCAL,\n",
    "                            GITHUB_CLASSIFIED_DATA_URL_PATH, \n",
    "                            GIT_OWNER,\n",
    "                            GIT_REPO)\n",
    "\n",
    "# display (convention_sentences_df.head(1)) \n",
    "display (\"Total number of sentences\", convention_sentences_df.shape[0])\n",
    "convention_sentences_df['ref'] = convention_sentences_df['ref'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T00:58:08.691013Z",
     "start_time": "2019-12-17T00:58:08.686957Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# nlp = en_core_web_sm.load()\n",
    "# def contains_name(text):\n",
    "#     doc = nlp(text)\n",
    "#     if len(doc.ents) == 0:\n",
    "#         return False\n",
    "#     for ent in doc.ents:\n",
    "#         if ent.label_ == 'PERSON':\n",
    "#             return True\n",
    "#     return False\n",
    "\n",
    "\n",
    "# convention_sentences_df['contains_name'] = convention_sentences_df[\"text\"].swifter.apply(contains_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T22:22:02.405240Z",
     "start_time": "2019-12-16T22:22:02.363952Z"
    }
   },
   "outputs": [],
   "source": [
    "def time_stamp():\n",
    "    now = datetime.now()\n",
    "    timestamp = datetime.timestamp(now)\n",
    "    dt_object = datetime.fromtimestamp(timestamp)\n",
    "    words = str(dt_object).split(' ');\n",
    "    return words[0], words[1]\n",
    "\n",
    "def save_to_github(git_user, git_password, git_owner_repo, my_file_list, push_to_git_as):\n",
    "    '''\n",
    "    in order to push a file to github it must first be stored locally, then pushed\n",
    "    this local location can also be local to a virtual machine. \n",
    "    takes: \n",
    "            git username, password, repo, \n",
    "            a list of files to push to git ie the full local location of file,\n",
    "            a matching list of paths to push each file to in Git hub \n",
    "    '''\n",
    "    user = git_user\n",
    "    password = git_password\n",
    "    url = git_owner_repo #owner/repo eg aideenf/AIVC\n",
    "    file_list = []  #push these list of files to git\n",
    "    file_names = [] #push to this location in git\n",
    "    message = 'ok'\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        g = Github(user, password)\n",
    "        try:\n",
    "            repo = g.get_repo(url)\n",
    "        except (IOError, OSError, GithubException) as e: \n",
    "            return \"error\", e.message\n",
    "\n",
    "        file_list = my_file_list \n",
    "        file_names = push_to_git_as\n",
    "                 \n",
    "        commit_message = 'training data updated via the audit tool'\n",
    "    \n",
    "        master_ref = repo.get_git_ref('heads/master')\n",
    "        master_sha = master_ref.object.sha\n",
    "        base_tree = repo.get_git_tree(master_sha)\n",
    "        element_list = list()\n",
    "\n",
    "        for i, entry in enumerate(file_list):   \n",
    "            with open(entry) as input_file:\n",
    "                #data = input_file.read()   #works with non zip file\n",
    "                data = base64.b64encode(open(entry, \"rb\").read())\n",
    "                \n",
    "            if entry.endswith('.png'):\n",
    "                data = base64.b64encode(data) \n",
    "                \n",
    "\n",
    "            blob = repo.create_git_blob(data.decode(\"utf-8\"), \"base64\")\n",
    "            element = InputGitTreeElement(path=file_names[i], mode='100644', type='blob', sha=blob.sha)\n",
    "\n",
    "            #push to git as file_names[i]\n",
    "            #print (\"push to git as:\", file_names[i])           \n",
    "            #element = InputGitTreeElement(file_names[i], '100644', 'blob', data)\n",
    "        \n",
    "        \n",
    "            #element_list is a list of InputGitTreeElement. \n",
    "            #Each one corresponds to a file. \n",
    "            # the 'content' of InputGitTreeElement can only be of type 'str' or 'unicode'. \n",
    "            #When I load a file to memory I have type 'bytes'. \n",
    "            #What is the right way to encode those bytes to str or unicode to upload a .zip\n",
    "            element_list.append(element)   \n",
    "        \n",
    "        tree = repo.create_git_tree(element_list, base_tree)\n",
    "        parent = repo.get_git_commit(master_sha)\n",
    "        commit = repo.create_git_commit(commit_message, tree, [parent])\n",
    "        master_ref.edit(commit.sha)\n",
    "        return commit, message \n",
    "    except:\n",
    "        message = \"GitHub save FAILED:\" + '\\n' +\"Are your github login credentials correct?\" + '\\n' + \"Are you a collaberator in the repo?\"\n",
    "        return \"error\", message\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T22:23:20.628494Z",
     "start_time": "2019-12-16T22:23:20.245229Z"
    }
   },
   "outputs": [],
   "source": [
    "del filtered_result \n",
    "# = convention_sentences_df.loc[(convention_sentences_df['contains_name'] == True)]\n",
    "# display (filtered_result.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T22:25:26.442466Z",
     "start_time": "2019-12-16T22:25:25.152416Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "#check by partial text in the text column df[df['text'].str.contains(\"tree\")]\n",
    "checkbox_dict = {}\n",
    "cb_list = []\n",
    "for conv in conventions:\n",
    "    checkbox_dict[conv] = widgets.Checkbox(value=False,description=conv,disabled=False, style = my_style,\n",
    "    layout = my_layout_shortest)\n",
    "    cb_list.append(checkbox_dict[conv])\n",
    "    \n",
    "check_boxes  = widgets.HBox(cb_list)\n",
    "\n",
    "\n",
    "###### Confidence values\n",
    "min_confidence = 0 #below this threshold the classification will be negative, above it will be pos\n",
    "max_confidence = 1\n",
    "\n",
    "\n",
    "selectHTMLHead = widgets.HTML(\n",
    "            \"<font color = '#8c8c8c'><h3><center>*** Model Classification, Audit Tool ***</center></h3></font>\")\n",
    "\n",
    "selectHTML = widgets.HTML(\n",
    "            \"<font color = '#8c8c8c'><h4><left>--- Filter ---</left></h4></font>\")\n",
    "\n",
    "saveHTML = widgets.HTML(\n",
    "            \"<h4><left><font color = '#8c8c8c'>--- Push unsaved audits to Github repo ---</font></left></h4>\")\n",
    "\n",
    "actionHTML = widgets.HTML(\n",
    "            \"<font color = '#8c8c8c'><h4><left>--- Action ---</h4></left></font>\")\n",
    "\n",
    "\n",
    "space = widgets.Label('  ', layout=widgets.Layout(width='100%'))\n",
    "small_space = widgets.Label(' ', layout=widgets.Layout(width='5%'))\n",
    "\n",
    "\n",
    "\n",
    "convention_drop_down = widgets.Dropdown(\n",
    "    options={ \n",
    "             'Civic':'convention_civic', \n",
    "             'Domestic':'convention_domestic', \n",
    "             'Green':'convention_green', \n",
    "             'Industrial':'convention_industrial', \n",
    "             'Inspired':'convention_inspired',\n",
    "             'Market':'convention_market', \n",
    "             'Project':'convention_project',\n",
    "             'Renown':'convention_renown',\n",
    "             'None':'None'},\n",
    "    value='convention_civic',\n",
    "    description='Convention  :',\n",
    "    disabled=False,\n",
    "    style = my_style,\n",
    "    layout = my_layout\n",
    ")\n",
    "\n",
    "source_drop_down = widgets.Dropdown(\n",
    "    options =  convention_sentences_df.data_provenance.unique(),\n",
    "    description=\"Data source :\",\n",
    "     #value=None,\n",
    "    disabled=False,\n",
    "    style = my_style,\n",
    "    layout = my_layout\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "convention_pos_neg = widgets.Dropdown(\n",
    "    options=['Positive', 'Negative'],\n",
    "    value='Positive',\n",
    "    description='Classified as:',\n",
    "    disabled=False,\n",
    "    style = my_style,\n",
    "    layout = my_layout\n",
    ")\n",
    "\n",
    "confidence_score_slider_min = widgets.FloatSlider(\n",
    "    min=min_confidence, \n",
    "    max=max_confidence,\n",
    "    value = min_confidence,\n",
    "    step = 0.1,\n",
    "    description='Min Confidence level:',\n",
    "    style = my_style,\n",
    "    layout = my_layout\n",
    "    )\n",
    "confidence_score_slider_min.style.handle_color = '#5c85d6'\n",
    "\n",
    "\n",
    "confidence_score_slider_max = widgets.FloatSlider(\n",
    "    min=min_confidence, \n",
    "    max=max_confidence, \n",
    "    value = max_confidence,\n",
    "    step = 0.1,\n",
    "    description='Max Confidence level:',\n",
    "    style = my_style,\n",
    "    layout = my_layout\n",
    "    )\n",
    "confidence_score_slider_max.style.handle_color = '#5c85d6'\n",
    "\n",
    "\n",
    "ref_search_box = widgets.Text(value='', \n",
    "                              description='Reference: ',\n",
    "                              style = my_style,\n",
    "                              layout = my_layout\n",
    "                             )\n",
    "\n",
    "string_search_box = widgets.Text(value='', \n",
    "                              description='String: \\x09\\x09\\x09',\n",
    "                              style = my_style,\n",
    "                              layout = my_layout\n",
    "                             )\n",
    "\n",
    "change_value_button = widgets.Button(\n",
    "            description= \"Add\",\n",
    "            disabled=False,\n",
    "            button_style='',\n",
    "            tooltip='Audit complete, change classification',\n",
    "        )\n",
    "change_value_button.style.button_color = '#e68a00'\n",
    "\n",
    "\n",
    "\n",
    "audit_next_button = widgets.Button(\n",
    "            description='Skip',\n",
    "            disabled=False,\n",
    "            button_style='',\n",
    "            tooltip='Move to next, without audit'\n",
    "        )\n",
    "audit_next_button.style.button_color = '#d9d9d9'\n",
    "\n",
    "\n",
    "undo_last_audit = widgets.Button(\n",
    "            description='Undo last',\n",
    "            disabled=False,\n",
    "            button_style='',\n",
    "            tooltip='undoes the last line added to audit'\n",
    "        )\n",
    "audit_next_button.style.button_color = '#d9d9d9'\n",
    "\n",
    "\n",
    "save_to_git_button = widgets.Button(\n",
    "            description='Save to GitHub',\n",
    "            disabled=False,\n",
    "            button_style='',\n",
    "            tooltip='Click me',\n",
    "        )\n",
    "save_to_git_button.style.button_color = '#00b386'\n",
    "\n",
    "\n",
    "\n",
    "download_button = widgets.Button(\n",
    "            description='Download',\n",
    "            disabled=False,\n",
    "            button_style='',\n",
    "            tooltip='Click me',\n",
    "        )\n",
    "download_button.style.button_color = '#d9d9d9'\n",
    "\n",
    "\n",
    "\n",
    "user = widgets.Text(\n",
    "            description='Username',\n",
    "            disabled=False,\n",
    "            layout=my_layout_shortest,\n",
    "            tooltip='Enter your GitHub username',\n",
    "            style = my_style\n",
    "        )\n",
    "\n",
    "\n",
    "pswd = widgets.Password(\n",
    "            description='Password',\n",
    "            disabled=False,\n",
    "            layout=my_layout_shortest,\n",
    "            tooltip='Enter your GitHub password',\n",
    "            style = my_style\n",
    "        )\n",
    "\n",
    "\n",
    "def change_value_button_clicked(b):\n",
    "    \n",
    "    global TOTAL_UNSAVED_AUDITS \n",
    "    global TOTAL_RECORDS_AUDITED \n",
    "    global index_number\n",
    "    global row_to_edit\n",
    "    global audited_df\n",
    "    global convention_sentences_df\n",
    "    \n",
    "        \n",
    "    text = row_to_edit.text.values.astype(str)[0]\n",
    "    prov = row_to_edit.data_provenance.values.astype(str)[0]\n",
    "    is_name = row_to_edit.contains_name.values.astype(str)[0]\n",
    "    current_conv = convention_drop_down.value.replace('convention_', '')\n",
    "    \n",
    "    \n",
    "    current = pd.DataFrame({\n",
    "                            'text': [text],\n",
    "                            'provenance': [prov],\n",
    "                            'civic': [ checkbox_dict['civic'].value ],\n",
    "                            'domestic': [checkbox_dict['domestic'].value],\n",
    "                            'green': [checkbox_dict['green'].value],\n",
    "                            'industrial': [checkbox_dict['industrial'].value],\n",
    "                            'inspired': [checkbox_dict['inspired'].value],\n",
    "                            'market': [checkbox_dict['market'].value],\n",
    "                            'project': [checkbox_dict['project'].value],\n",
    "                            'renown': [checkbox_dict['renown'].value]\n",
    "                            })\n",
    "   \n",
    "    for con in conventions:\n",
    "        current[con] = current[con].astype(int)\n",
    "        \n",
    "\n",
    "    \n",
    "    audited_df = audited_df.append(current, ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    TOTAL_UNSAVED_AUDITS = TOTAL_UNSAVED_AUDITS + 1\n",
    "    TOTAL_RECORDS_AUDITED = TOTAL_RECORDS_AUDITED + 1\n",
    "    with output:\n",
    "        clear_output(wait=True)\n",
    "        output_function(convention_drop_down.value, confidence_score_slider_min.value, confidence_score_slider_max.value, source_drop_down.value, convention_pos_neg.value , ref_search_box.value, string_search_box.value)\n",
    "    \n",
    "    with outputToSave:\n",
    "        clear_output(wait=True)\n",
    "        display (audited_df)\n",
    "        \n",
    "    with outputGitHub:\n",
    "        clear_output(wait=True)\n",
    "        print (\"\")\n",
    "        \n",
    "\n",
    "def audit_next_button_clicked(b):\n",
    "    with output:\n",
    "        clear_output(wait=True)\n",
    "        output_function(convention_drop_down.value, confidence_score_slider_min.value, confidence_score_slider_max.value, source_drop_down.value, convention_pos_neg.value, ref_search_box.value, string_search_box.value )\n",
    "    with outputToSave:\n",
    "        clear_output(wait=True)\n",
    "        display (audited_df)\n",
    "    with outputGitHub:\n",
    "        clear_output(wait=True)\n",
    "        print(\"\")\n",
    "        \n",
    "def undo_last_audit_button_clicked(b):\n",
    "    global audited_df\n",
    "    global TOTAL_UNSAVED_AUDITS \n",
    "    global TOTAL_RECORDS_AUDITED\n",
    "\n",
    "    if (audited_df.shape[0] > 0):\n",
    "        audited_df.drop(audited_df.tail(1).index,inplace=True) \n",
    "        with outputToSave:\n",
    "            clear_output(wait=True)\n",
    "            display (audited_df)   \n",
    "        TOTAL_UNSAVED_AUDITS = TOTAL_UNSAVED_AUDITS - 1\n",
    "        with outputCount:\n",
    "            clear_output(wait=True)\n",
    "            print(\"Total audited:\", TOTAL_RECORDS_AUDITED, \" Total unsaved:\", TOTAL_UNSAVED_AUDITS,\" Last Saved:\", LAST_SAVED )\n",
    "       \n",
    "    else:\n",
    "        with outputToSave:\n",
    "            clear_output(wait=True)\n",
    "            print (\"No more rows to delete\")\n",
    "            \n",
    "            \n",
    "def download_button_clicked(b):\n",
    "    global FILE_PATH\n",
    "    global LAST_FILE_SAVED\n",
    "    file_name = DOWNLOAD_TSV_PATH + LAST_FILE_SAVED\n",
    "    display(IFrame(file_name, width=700, height=400))\n",
    "\n",
    "def save_changes_to_github_button_clicked(b):\n",
    "    global TOTAL_UNSAVED_AUDITS \n",
    "    global convention_sentences_df\n",
    "    global LAST_SAVED\n",
    "    global LAST_FILE_SAVED\n",
    "    global FILE_PATH\n",
    "    global GIT_PUSH_PATH\n",
    "    global audited_df\n",
    "    GIT_USER = user.value\n",
    "    GIT_PSWD = pswd.value\n",
    "    GIT_REPO = 'aideenf/AIVC'\n",
    "    D, T = time_stamp()\n",
    "    file_name = 'audited_labelled_data_'+ GIT_USER   + '_' + D + '-' + T +  '.tsv'\n",
    "    file_name_zip = 'audit_labelled_data_'+ GIT_USER + '_' + D + '-' + T +   '.gz'\n",
    "    LAST_FILE_SAVED = file_name\n",
    "    with outputGitHub:\n",
    "            clear_output(wait=True)\n",
    "            display(\"saving, please wait....\")\n",
    "    try:\n",
    "        audited_df.to_csv(FILE_PATH + file_name, sep = '\\t', index = False)\n",
    "    except (IOError, OSError) as e:\n",
    "        with outputGitHub:\n",
    "            clear_output(wait=True)\n",
    "            display(HTML(\"<font color='red'><b>Warning!!</b></font>\"))\n",
    "            print (\"Are your settings correct for local machine v's binder?\")\n",
    "            print (e)\n",
    "        return \"error\"\n",
    "        \n",
    "    my_file_list = [FILE_PATH + file_name]\n",
    "    push_to_git_as = [GIT_PUSH_PATH + file_name]\n",
    "    commit, message = save_to_github(GIT_USER, GIT_PSWD, GIT_REPO, my_file_list, push_to_git_as)\n",
    "    if (commit != \"error\"):\n",
    "        with outputGitHub:\n",
    "            clear_output(wait=True)\n",
    "            print (\"File to commit:\", my_file_list[0])\n",
    "            print (\"Push to git as:\", push_to_git_as[0])\n",
    "            print (\"Commit: \", commit)\n",
    "            TOTAL_UNSAVED_AUDITS = 0\n",
    "            D, T = time_stamp()\n",
    "            LAST_SAVED = D+T\n",
    "            print (\"Number of audits saved: \", audited_df.shape[0] )\n",
    "            display(HTML(\"<font color='green'><b>Saved!!</b></font>\"))\n",
    "            audited_df = pd.DataFrame(columns=['text', 'provenance', 'convention', 'old', 'new'])\n",
    "    if (commit == \"error\"):\n",
    "        with outputGitHub:\n",
    "            clear_output(wait=True)\n",
    "            print (\"File to commit: \", my_file_list[0])\n",
    "            print (\"Push to git as: \", push_to_git_as[0])\n",
    "            display(HTML(\"<font color='red'><b>Warning!!</b></font>\"))\n",
    "            print(message)\n",
    "            print (\"\")\n",
    "            print(\"If you continue to have a problem download here and save locally\")\n",
    "            display(download_button)\n",
    "            \n",
    "            \n",
    "\n",
    "def output_function(convention_drop_down_value, confidence_score_slider_min_value, confidence_score_slider_max_value, source_drop_down_value, convention_pos_neg_value, ref_search_box_value, string_search_box_value ):\n",
    "    global convention_sentences_df\n",
    "    global row_to_edit\n",
    "    global index_number\n",
    "    global LAST_SAVED\n",
    "    global TOTAL_RECORDS_AUDITED\n",
    "    global TOTAL_UNSAVED_AUDIT\n",
    "    \n",
    "    convention_drop_down.disabled = False\n",
    "    confidence_score_slider_min.disabled = False\n",
    "    confidence_score_slider_max.disabled = False\n",
    "    source_drop_down.disabled = False\n",
    "    convention_pos_neg.disabled = False\n",
    "    \n",
    "    #Confidence values in the case that .05 is the threshold between Negative and Positive\n",
    "    confidenceOfPosMin = confidence_score_slider_min.value #0.5\n",
    "    confidenceOfPosMax = confidence_score_slider_max.value  #somewhere around 1\n",
    "    confidenceOfNegMin = 0\n",
    "    confidenceOfNegMax = .5\n",
    "    \n",
    "    filter_lower = 0\n",
    "    filter_upper = 1\n",
    "    \n",
    "    if (convention_pos_neg.value ==  'Positive'):\n",
    "\n",
    "        filter_lower = confidenceOfPosMin\n",
    "        filter_upper = confidenceOfPosMax\n",
    "\n",
    "    if (convention_pos_neg.value ==  'Negative'):\n",
    "\n",
    "        filter_lower = confidenceOfNegMin\n",
    "        filter_upper = confidenceOfNegMax\n",
    "    \n",
    "   \n",
    "    convention = convention_drop_down_value.replace('convention_', '')\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    try:\n",
    "\n",
    "        if ref_search_box_value != '':\n",
    "                convention_drop_down.disabled = True\n",
    "                confidence_score_slider_min.disabled = True\n",
    "                confidence_score_slider_max.disabled = True\n",
    "                source_drop_down.disabled = True\n",
    "                convention_pos_neg.disabled = True\n",
    "\n",
    "                filtered_result =  convention_sentences_df.loc[(convention_sentences_df['ref'] == ref_search_box.value) &\n",
    "                                                                (convention_sentences_df['text'].str.contains(string_search_box.value))]\n",
    "                display (filtered_result.shape[0])\n",
    "\n",
    "                row_to_edit = filtered_result.sample(n = 1)\n",
    "                num_of_examples = filtered_result.shape[0]\n",
    "                del filtered_result\n",
    "        \n",
    "        elif convention_drop_down_value == \"None\":\n",
    "            confidence_score_slider_min.disabled = True\n",
    "            confidence_score_slider_max.disabled = True\n",
    "            filtered_result = convention_sentences_df.loc[\n",
    "                                            (convention_sentences_df['data_provenance'] == source_drop_down_value) &\n",
    "                                            (convention_sentences_df['convention_civic'] < 0.5) &\n",
    "                                            (convention_sentences_df['convention_domestic'] < 0.5) &\n",
    "                                            (convention_sentences_df['convention_green'] < 0.5) &\n",
    "                                            (convention_sentences_df['convention_industrial'] < 0.5)&\n",
    "                                            (convention_sentences_df['convention_inspired'] < 0.5) &\n",
    "                                            (convention_sentences_df['convention_market'] < 0.5) &\n",
    "                                            (convention_sentences_df['convention_project'] < 0.5) &\n",
    "                                            (convention_sentences_df['convention_renown'] < 0.5) &\n",
    "                                            (convention_sentences_df['text'].str.contains(string_search_box.value))&\n",
    "                                            (convention_sentences_df['contains_name'] == True)]\n",
    "            \n",
    "            \n",
    "            row_to_edit = filtered_result.sample(n = 1)\n",
    "            num_of_examples = filtered_result.shape[0]\n",
    "            del filtered_result\n",
    "            \n",
    "            \n",
    "        else:    \n",
    "            filtered_result = convention_sentences_df.loc[\n",
    "                                                (convention_sentences_df['data_provenance'] == source_drop_down_value) &\n",
    "                                                (convention_sentences_df[convention_drop_down_value] >= filter_lower) &\n",
    "                                                (convention_sentences_df[convention_drop_down_value] <= filter_upper) &\n",
    "                                                (convention_sentences_df['text'].str.contains(string_search_box.value))]\n",
    "                                                 \n",
    "            \n",
    "            row_to_edit = filtered_result.sample(n = 1)\n",
    "            num_of_examples = filtered_result.shape[0]\n",
    "            del filtered_result\n",
    "        \n",
    "        \n",
    "        txt = \"The number of filtered samples is \" + str(num_of_examples)\n",
    "        display(HTML(\"<font color='green'>\" + txt + \"</font>\"))\n",
    "        if (num_of_examples < 20):\n",
    "            display(HTML(\"<font color='green'><b>Warning!</b> \" + \"The sample number is low and you may see repeats\" + \"</font>\"))\n",
    "    except ValueError:\n",
    "        print (ValueError)\n",
    "        display(HTML(\"<font color='red'><b>Warning</b> \" + \"No data, please adjust filter:</font>\"))\n",
    "    \n",
    "    if not row_to_edit.empty:\n",
    "        display (row_to_edit[['text']].style.background_gradient().set_caption('Row randomly selected based on filter').set_table_styles(styles).hide_index())\n",
    "        sentence = row_to_edit['text'].values.astype(str)[0]\n",
    "        try:\n",
    "            conf = row_to_edit[convention_drop_down_value].values.astype(float)[0]\n",
    "        except:\n",
    "            conf = 0\n",
    "        res = \"\"\n",
    "        ref = row_to_edit['ref'].values.astype(str)[0]\n",
    "        repo = row_to_edit['repo'].values.astype(str)[0]\n",
    "        source = row_to_edit['data_provenance'].values.astype(str)[0]\n",
    "\n",
    "        if source == \"github_ai\":\n",
    "                \n",
    "                repo1 = 'https://github.com/' + repo + '/blob/master/README.md'\n",
    "                temp = \"<a href=\" + repo1 +\">\" + repo1 + \"</a>\"\n",
    "                repo1 = temp\n",
    "                \n",
    "                repo2 = 'https://github.com/' + repo + '/blob/master/README.rst'\n",
    "                temp = \"<a href=\" + repo2 +\">\" + repo2 + \"</a>\"\n",
    "                repo2 = temp\n",
    "        else:\n",
    "                repo1 = \"<a href=\" + repo +\">\" + repo + \"</a>\" \n",
    "        true_for = \"\"\n",
    "        for conv in conventions:\n",
    "            to_dis = str(round(row_to_edit['convention_'+conv].values[0].item(),2))\n",
    "            checkbox_dict[conv].description = conv + \" (\" + to_dis + \" )\"\n",
    "            val = round ( row_to_edit['convention_'+conv].values[0]).item()\n",
    "            checkbox_dict[conv].value = bool(val)\n",
    "            if bool(val) == True:\n",
    "                true_for = true_for + conv + \", \"\n",
    "        if (true_for != \"\"):\n",
    "            res = 'POSITIVE'\n",
    "\n",
    "        if (true_for == \"\"):\n",
    "            res = 'NEGATIVE'\n",
    "\n",
    "        #display(HTML(\"Sentence: <b><font color='green'>\" + sentence + \"</b></font>\" ))\n",
    "        display(HTML(\"Text field labelled <b><font color='black'>\" + res + \"</b> \" + \"</font> for the <font color='black'><b>\" +  true_for.upper() + \" </b></font>economy of conventions </> \"))\n",
    "        \n",
    "        if convention_drop_down_value != \"None\":\n",
    "            display(HTML(\"Text field scored <b><font color='black'> \" + str(round(conf,2)) + \" </b> </font> for  \" + convention_drop_down.value.replace(\"convention_\", \"\") +\" as per filter\" ))\n",
    "        \n",
    "        display(HTML(\"Reference : \" + ref))\n",
    "        display(HTML(\"Link: \" + repo1))\n",
    "        if source == \"github_ai\":\n",
    "            display(HTML(\"Link :\" + repo2))\n",
    "            \n",
    "        \n",
    "        index_number = row_to_edit.index.values.astype(int)[0]\n",
    "        try:\n",
    "            with outputCount:\n",
    "                clear_output(wait=True)\n",
    "                print(\"Total audited:\", TOTAL_RECORDS_AUDITED, \" Total unsaved:\", TOTAL_UNSAVED_AUDITS,\" Last Saved:\", LAST_SAVED )\n",
    "        except:\n",
    "            print (\"\")\n",
    "    else:\n",
    "        print (\"No results, change search setting\")\n",
    "    \n",
    "    \n",
    "  \n",
    "output = widgets.interactive_output(output_function, {\n",
    "            'convention_drop_down_value': convention_drop_down,\n",
    "            'confidence_score_slider_min_value': confidence_score_slider_min,\n",
    "            'confidence_score_slider_max_value': confidence_score_slider_max,\n",
    "            'source_drop_down_value': source_drop_down,\n",
    "            'convention_pos_neg_value' : convention_pos_neg,\n",
    "            'ref_search_box_value': ref_search_box, \n",
    "            'string_search_box_value':string_search_box\n",
    "            })\n",
    "\n",
    "outputGitHub = widgets.Output()\n",
    "outputToSave = widgets.Output()\n",
    "outputCount = widgets.Output()\n",
    "change_value_button.on_click(change_value_button_clicked)\n",
    "# keep_value_button.on_click(change_value_button_clicked)\n",
    "audit_next_button.on_click(audit_next_button_clicked)\n",
    "save_to_git_button.on_click(save_changes_to_github_button_clicked)\n",
    "undo_last_audit.on_click(undo_last_audit_button_clicked)\n",
    "download_button.on_click(download_button_clicked)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T22:25:29.362307Z",
     "start_time": "2019-12-16T22:25:27.583206Z"
    }
   },
   "outputs": [],
   "source": [
    "#HTML Help Content   \n",
    "using = '<h4>Using the audit tool</h4><p>This tool will randomly select and display a sentence which has already been classified by the model thus facilitating human evaluation and correction of model predictions. These validated and corrected predictions will be fed back to the model as part of a re-training process, with the objective of increasing model accuracy. The tool will automatically select and display a random sentence from the pool each time an action is involked, either by modifying the filter or by one of the three action buttons [Change], [Ok] and [Skip]. Once the sentence is audited via either the [Ok] or [Change] button it will be used to train the model on the next training iteration.<br/>[Skip]: Use the Skip button if you are unable to confirm the classification (no action will be taken)</p><p>[Ok]: </span> Use the OK button to confirm that the sentence has been classified correctly as [Positive] or [Negative] for the convention in question i.e if the classification is True </p><p>[Chang]e]: Use the change button, if you believe the sentence has been classified incorrectly by the model  i.e if the classification is a \"False Positive\" or \"False Negative\".<br/> If the original classification has been \"False Positive\" and you can correctly classify the sentence as belonging to another convention, please select the appropriate convention via the [Change to] dropdown.</p><p><em>Note: A&nbsp;<strong>GitHub</strong>&nbsp;username and password is required to save the results of the audits, it is important to remember to save the audit on a regular basis</em></p><hr/><p></p>'                              \n",
    "filtering = '<h4>Filtering</h4>To help obtain a more balanced training data set across all convention models, please review the histogram to determine focus of audit'\n",
    "\n",
    "#Histogram image\n",
    "image = Image.open(urllib.request.urlopen(IMAGE_PATH))\n",
    "image = image_to_byte_array(image)\n",
    "\n",
    "\n",
    "#keywords tab, populate using keyword_de_dict and keyword_td_dict\n",
    "td_tab_contents = keyword_td_dict.values() \n",
    "de_tab_contents = keyword_de_dict.values() \n",
    "tab_name = list(keyword_td_dict.keys())\n",
    "\n",
    "children = [widgets.HTML(  value=\"TRAINING DATA: \" + str(td_content) + \" DOMAIN EXPERT: \" +str(de_content)   ) for td_content, de_content in zip (td_tab_contents, de_tab_contents)]\n",
    "\n",
    "tab_keywords = widgets.Tab()\n",
    "tab_keywords.children = children\n",
    "for i in range(len(children)):\n",
    "    tab_keywords.set_title(i, str(tab_name[i]))\n",
    "\n",
    "#SET UP A HEADER ACCORDIAN TO SHOW HELP, HISTOGRAM and KEYWORDS\n",
    "accordion = widgets.Accordion(children=\n",
    "                              [widgets.HTML(filtering+using),\n",
    "                               widgets.Image(value=image,format='png',width=1200,height=1200),\n",
    "                               tab_keywords\n",
    "                              ]\n",
    "                         \n",
    "                             )\n",
    "\n",
    "\n",
    "accordion.set_title(0, 'About The Tool')\n",
    "accordion.set_title(1, 'Training Data Histogram')\n",
    "accordion.set_title(2, 'Convention Keyword hints')\n",
    "accordion.selected_index = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T22:25:30.570845Z",
     "start_time": "2019-12-16T22:25:30.341226Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "320adff674a54782b2b48a278ee1e431",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"<font color = '#8c8c8c'><h3><center>*** Model Classification, Audit Tool ***</center></h3></font>\"â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0716e90fa53044ada3b110e883f96885",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(HTML(value='<h4>Filtering</h4>To help obtain a more balanced training data set across all â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1295342bb924462c89f89443d227c833",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='  ', layout=Layout(width='100%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92401c82c2af49d48636bfbcf9cd2d25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"<font color = '#8c8c8c'><h4><left>--- Filter ---</left></h4></font>\")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbdbb2a9f3614bd49a0713a6c354b7c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='Convention  :', layout=Layout(width='600px'), options={'Civic': 'conventiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dadba4fc3a7b4638bcec1419ad0a57e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(outputs=({'output_type': 'display_data', 'data': {'text/plain': '<IPython.core.display.HTML object>', 'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78829873485e44b3a8a05fa86f78a9e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Checkbox(value=False, description='civic (0.05 )', layout=Layout(width='200px'), style=Descriptâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1295342bb924462c89f89443d227c833",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='  ', layout=Layout(width='100%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "059a072e18c54810815cdbeb5646c9ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"<font color = '#8c8c8c'><h4><left>--- Action ---</h4></left></font>\")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd9728d1fc254f96b6b2776365d2c8e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='Save', style=ButtonStyle(button_color='#e68a00'), tooltip='Audit complete, â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44fcf15535754c0183445b47bdd8b119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1295342bb924462c89f89443d227c833",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='  ', layout=Layout(width='100%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a667f378a4d47328d45c88b333b2a24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"<h4><left><font color = '#8c8c8c'>--- Push unsaved audits to Github repo ---</font></left></h4>\")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1295342bb924462c89f89443d227c833",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='  ', layout=Layout(width='100%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4788d59bc389418595ed1a662d6aefe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Text(value='', description='Username', layout=Layout(width='200px'), style=DescriptionStyle(desâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1eba84523554ec4a5f4ccef19fed1bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Save to GitHub', style=ButtonStyle(button_color='#00b386'), tooltip='Click me')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1295342bb924462c89f89443d227c833",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='  ', layout=Layout(width='100%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10e0d8f9132c4c0c8e20ee1218a31944",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e12f5240e44b4005aa06b19fa6a7fbf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1295342bb924462c89f89443d227c833",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='  ', layout=Layout(width='100%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "display (\n",
    "        selectHTMLHead,\n",
    "        accordion,\n",
    "        space,\n",
    "        selectHTML,\n",
    "        widgets.VBox([\n",
    "        convention_drop_down, \n",
    "        source_drop_down, \n",
    "        confidence_score_slider_min, \n",
    "        confidence_score_slider_max,ref_search_box, string_search_box]),\n",
    "        output,\n",
    "        check_boxes,\n",
    "        space,\n",
    "        actionHTML,\n",
    "        widgets.HBox([change_value_button, audit_next_button, small_space, undo_last_audit]),\n",
    "        outputCount,\n",
    "        space,\n",
    "        saveHTML,\n",
    "        space,\n",
    "        widgets.HBox([user, pswd]),\n",
    "        save_to_git_button,\n",
    "        space,\n",
    "        outputGitHub,\n",
    "        outputToSave,\n",
    "        space\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
