{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file is used by: \n",
    "- extract_sentences_from_pdf.ipynb\n",
    "\n",
    "\n",
    "It contains the following Methods\n",
    "- markdown_to_text()\n",
    "- remove_nums_from_str(s)\n",
    "- pre_process_sentence(sent)\n",
    "- pre_process(textBlob) returns tokenized to sentences\n",
    "- remove_excluded_files(file_list)\n",
    "- remove_excluded_files_except(file_list, except_with_text)\n",
    "- rreplace(s, old, new, occurrence)\n",
    "- clean_file_name(name, replacements2=[]):\n",
    "- def save_to_github(git_user, git_password, git_repo, my_file_list, push_to_git_as):\n",
    "- def list_files_from_github_dir (owner, repo, dir_ref):\n",
    "- keep_pdf_urls_only(file_list):\n",
    "- def concat_files_from_github_dir (directory_base_url, file_list):  \n",
    "- def read_single_file_from_github_dir (directory_base_url, file_name): \n",
    "\n",
    "\n",
    "It can be encorporated into any other notebook by using \n",
    "    -%run ./AIVM_helper_classes.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T07:53:00.143963Z",
     "start_time": "2019-10-09T07:52:54.561277Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "# Required Python utilities\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter\n",
    "import re\n",
    "from langdetect import detect\n",
    "from bs4 import BeautifulSoup\n",
    "from markdown import markdown\n",
    "from lxml import etree\n",
    "import os\n",
    "import random\n",
    "import tqdm\n",
    "import itertools \n",
    "import pickle\n",
    "import time\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "\n",
    "## Deep Learning imports for the classifiers\n",
    "os.environ['KERAS_BACKEND']='theano'\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dense, Input, Flatten\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding, Dropout, Concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "##Â ML required imports (for clustering)\n",
    "from sklearn import metrics\n",
    "from sklearn.decomposition import PCA, LatentDirichletAllocation\n",
    "from sklearn.preprocessing import scale, StandardScaler\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "\n",
    "# Topic modeling imports\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "##Â NLP related imports\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "\n",
    "# visualization imports\n",
    "from IPython.display import display\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import base64\n",
    "import io\n",
    "%matplotlib inline\n",
    "sns.set() \n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "import base64\n",
    "\n",
    "from github import Github, GithubException, InputGitTreeElement\n",
    "from IPython.display import display, clear_output, HTML, Image\n",
    "\n",
    "import requests as req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T12:37:21.763839Z",
     "start_time": "2019-10-09T12:37:21.700886Z"
    }
   },
   "outputs": [],
   "source": [
    "class AIVM_Generic_helper:\n",
    "    def __init__(self):\n",
    "        print(\"initialised\")\n",
    "\n",
    "    def image_to_byte_array(self, image: Image):\n",
    "        imgByteArr = io.BytesIO()\n",
    "        image.save(imgByteArr, format=image.format)\n",
    "        imgByteArr = imgByteArr.getvalue()\n",
    "        return imgByteArr\n",
    "\n",
    "    def time_stamp(self):\n",
    "        now = datetime.now()\n",
    "        timestamp = datetime.timestamp(now)\n",
    "        dt_object = datetime.fromtimestamp(timestamp)\n",
    "        words = str(dt_object).split(' ')\n",
    "        return words[0], words[1]\n",
    "\n",
    "    def markdown_to_text(self, markdown_string):\n",
    "        \"\"\" Converts a markdown string to plaintext \"\"\"\n",
    "\n",
    "        # md -> html -> text since BeautifulSoup can extract text cleanly\n",
    "        html = markdown(markdown_string)\n",
    "\n",
    "        # remove code snippets\n",
    "        html = re.sub(r'<pre>(.*?)</pre>', ' ', html)\n",
    "        html = re.sub(r'<code>(.*?)</code >', ' ', html)\n",
    "\n",
    "        # extract text\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "        text = ''.join(soup.findAll(text=True))\n",
    "        return text\n",
    "\n",
    "    def remove_nums_from_str(self, s):\n",
    "        result = ''.join([i for i in s if not i.isdigit()])\n",
    "        return result\n",
    "\n",
    "    def pre_process_sentence(self, sent):\n",
    "        sent = re.sub('-', ' ', sent, flags=re.MULTILINE)  # Added by Aideen\n",
    "        sent = re.sub(' +', ' ', sent, flags=re.MULTILINE)  # Added by Aideen\n",
    "        sent = sent.replace(\";\", \", \")\n",
    "        sent = re.sub(' +', ' ', sent, flags=re.MULTILINE)  # Added by Aideen\n",
    "        sent = sent.strip()\n",
    "        sent = sent.lstrip()\n",
    "        sent = sent.rstrip()\n",
    "        sent = remove_nums_from_str(sent.replace(\",\", \" \"))\n",
    "        sent = sent.replace(\"  \", \" \")\n",
    "        sent = sent.replace(\" .\", \".\")\n",
    "        return sent\n",
    "\n",
    "    def pre_process(self, text):\n",
    "\n",
    "        # Removing prefixed 'b'\n",
    "        document = re.sub(r'^b\\s+', '', str(text))\n",
    "\n",
    "        # Removing splicit line change\n",
    "        document = re.sub(r'\\\\n', '', document, flags=re.MULTILINE)\n",
    "\n",
    "        soup = BeautifulSoup(document)\n",
    "\n",
    "        # Remove HTML code from text\n",
    "        document = soup.get_text()\n",
    "\n",
    "        # Parse text from markdown code\n",
    "        document = markdown_to_text(document)\n",
    "\n",
    "        # Removing URLS\n",
    "        document = re.sub(\n",
    "            r'^https?:\\/\\/.*[\\r\\n]*', '', document, flags=re.MULTILINE)\n",
    "\n",
    "        # Removing strings such as \\\\xe5 \\\\xe6 \\\\xe7 that appear a lot in the descriptions\n",
    "        document = re.sub(r':?\\\\+x\\w{2}', ' ', document, flags=re.MULTILINE)\n",
    "\n",
    "        # Remove all the special characters except spaces, dashes, commas and dots\n",
    "        document = re.sub(r\"[^\\s.,\\-a-zA-Z0-9]\", ' ', str(document))\n",
    "\n",
    "        # Substituting multiple spaces with single space\n",
    "        document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
    "\n",
    "        # Substituting multiple '-' with single '-'\n",
    "        document = re.sub(r'\\-{2,50}', '', document, flags=re.I)\n",
    "\n",
    "        document = re.sub('-', ' ', document,\n",
    "                          flags=re.MULTILINE)  # Added by Aideen\n",
    "        document = re.sub(' +', ' ', document,\n",
    "                          flags=re.MULTILINE)  # Added by Aideen\n",
    "        document.replace(\";\", \", \")\n",
    "        document = re.sub(' +', ' ', document,\n",
    "                          flags=re.MULTILINE)  # Added by Aideen\n",
    "        # Converting to Lowercase\n",
    "        document = document.lower()\n",
    "\n",
    "        # Sentences Tokenization\n",
    "        return sent_tokenize(document)\n",
    "\n",
    "    def remove_excluded_files(file_list):\n",
    "        cleaned_file_list = []\n",
    "        for f in file_list:\n",
    "            if not f.startswith('.') and not \"random\" in f and \"gathered_\" in f and not f.startswith(\"_\"):\n",
    "                cleaned_file_list.append(f)\n",
    "        return cleaned_file_list\n",
    "\n",
    "    def keep_pdf_urls_only(file_list):\n",
    "        cleaned_file_list = []\n",
    "        for f in file_list:\n",
    "            if f.endswith('.pdf') and not \" \" in f:\n",
    "                cleaned_file_list.append(f)\n",
    "        return cleaned_file_list\n",
    "\n",
    "    def remove_excluded_files_except(file_list, except_with_text):\n",
    "        cleaned_file_list = []\n",
    "        for f in file_list:\n",
    "            if not f.startswith('.') and not \"random\" in f and except_with_text in f and not f.startswith(\"_\"):\n",
    "                cleaned_file_list.append(f)\n",
    "        return cleaned_file_list\n",
    "\n",
    "    def rreplace(s, old, new, occurrence):\n",
    "        li = s.rsplit(old, occurrence)\n",
    "        return new.join(li)\n",
    "\n",
    "    def clean_file_name(name, replacements2=[]):\n",
    "\n",
    "        replacements = [\".txt\", \".csv\", \".tsv\"]\n",
    "\n",
    "        for r in replacements:\n",
    "            name = name.replace(r, \"\")\n",
    "\n",
    "        for r in replacements2:\n",
    "            name = name.replace(r, \"\")\n",
    "        return name\n",
    "\n",
    "    def save_to_github(git_user, git_password, git_repo, my_file_list, push_to_git_as):\n",
    "        '''\n",
    "        in order to push a file to github it must first be stored locally, then pushed\n",
    "        this local location can also be local to a virtual machine. \n",
    "        takes: \n",
    "                git username, password, repo, \n",
    "                a list of files to push to git ie the full local location of file,\n",
    "                a matching list of paths to push each file to in Git hub \n",
    "        '''\n",
    "        user = git_user\n",
    "        password = git_password\n",
    "        url = git_repo\n",
    "        file_list = []  # push these list of files to git\n",
    "        file_names = []  # push to this location in git\n",
    "        message = 'ok'\n",
    "\n",
    "        try:\n",
    "            g = Github(user, password)\n",
    "            try:\n",
    "                repo = g.get_user().get_repo(url)\n",
    "            except (IOError, OSError, GithubException) as e:\n",
    "                return \"error\", e.message\n",
    "\n",
    "            file_list = my_file_list\n",
    "            file_names = push_to_git_as\n",
    "\n",
    "            commit_message = 'training data updated via the audit tool'\n",
    "\n",
    "            master_ref = repo.get_git_ref('heads/master')\n",
    "            master_sha = master_ref.object.sha\n",
    "            base_tree = repo.get_git_tree(master_sha)\n",
    "            element_list = list()\n",
    "\n",
    "            for i, entry in enumerate(file_list):\n",
    "                with open(entry) as input_file:\n",
    "                    # data = input_file.read()   #works with non zip file\n",
    "                    data = base64.b64encode(open(entry, \"rb\").read())\n",
    "\n",
    "                if entry.endswith('.png'):\n",
    "                    data = base64.b64encode(data)\n",
    "\n",
    "                blob = repo.create_git_blob(data.decode(\"utf-8\"), \"base64\")\n",
    "                element = InputGitTreeElement(\n",
    "                    path=file_names[i], mode='100644', type='blob', sha=blob.sha)\n",
    "\n",
    "                # element_list is a list of InputGitTreeElement.\n",
    "                # Each one corresponds to a file.\n",
    "                element_list.append(element)\n",
    "\n",
    "            tree = repo.create_git_tree(element_list, base_tree)\n",
    "            parent = repo.get_git_commit(master_sha)\n",
    "            commit = repo.create_git_commit(commit_message, tree, [parent])\n",
    "            master_ref.edit(commit.sha)\n",
    "            return commit, message\n",
    "        except:\n",
    "            message = \"GitHub save FAILED:\" + '\\n' + \"Are your github login credentials correct?\" + \\\n",
    "                '\\n' + \"Are you a collaberator in the repo?\"\n",
    "            return \"error\", message\n",
    "\n",
    "        def list_files_from_github_dir(owner, repo, dir_ref):\n",
    "\n",
    "            # read data files for source data directly from github.\n",
    "            # to obtain the id for the folder, navigate the tree using\n",
    "            # https://api.github.com/repos/{owner}/{repo}/git/trees/master\n",
    "            # e.g https://api.github.com/repos/aideenf/AIVC/git/trees/master\n",
    "            # once navigated each directory will be of format\n",
    "            # https://api.github.com/repos/aideenf/AIVC/git/trees/{dir_ref}\n",
    "            # exampe dir_ref = 048349b4dd81d95a17129e7fcd5418bdca8309b3\"\n",
    "\n",
    "            # import requests as req  #we need to ensure we do not get cached response from browser.\n",
    "            headers = {\n",
    "                'Cache-Control': 'no-cache',\n",
    "                'Pragma': 'no-cache',\n",
    "                'If-None-Match': '',\n",
    "                'If-Modified-Since': 'Thu, 14 Sep 2019 22:31:14 GMT',\n",
    "                'If-None-Match': '048349b4dd81d95a17129e7fcd5418bdca8309b3'\n",
    "            }\n",
    "            # https://github.com/octokit/rest.js/issues/890 #need to add this for caching\n",
    "\n",
    "            # Audited dir_ref  = 602c472723d27ff6a14e73c3e5e5da42087b73d8\n",
    "            gathered_files = []\n",
    "            DIR_TO_SEARCH = \"https://api.github.com/repos/\" + \\\n",
    "                owner + \"/\" + repo + \"/git/trees/\" + dir_ref\n",
    "            print(DIR_TO_SEARCH)\n",
    "            resp = req.get(DIR_TO_SEARCH,  headers=headers)\n",
    "            response = json.loads(resp.text)\n",
    "            for value in response['tree']:\n",
    "                gathered_files.append(value['path'])\n",
    "\n",
    "            return gathered_files\n",
    "\n",
    "    def concat_files_from_github_dir(directory_base_url, file_list):\n",
    "        df_list = []\n",
    "        for file_name, i in zip(file_list, range(len(file_list))):\n",
    "            urlBase = directory_base_url\n",
    "            df_list.append(pd.read_csv(urlBase+file_name,\n",
    "                                       sep='\\t', error_bad_lines=False))\n",
    "        # NOTE: \"truncated\": false  we should check for truncated = true to do follow on call to get all files\n",
    "        df = pd.concat(df_list)\n",
    "        return df\n",
    "\n",
    "    def read_single_file_from_github_dir(directory_base_url, file_name):\n",
    "        df_list = []\n",
    "        for file_name, i in zip(file_list, range(len(file_list))):\n",
    "            urlBase = directory_base_url\n",
    "            df_list.append(pd.read_csv(urlBase+file_name,\n",
    "                                       sep='\\t', error_bad_lines=False))\n",
    "        # NOTE: \"truncated\": false  we should check for truncated = true to do follow on call to get all files\n",
    "        df = pd.concat(df_list)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T12:37:24.071644Z",
     "start_time": "2019-10-09T12:37:24.065644Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialised\n",
      "('2019-10-09', '14:37:24.067756')\n"
     ]
    }
   ],
   "source": [
    "aivm =  AIVM_Generic_helper()\n",
    "print (aivm. time_stamp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T16:59:34.028033Z",
     "start_time": "2019-10-08T16:59:34.010245Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T18:45:15.416594Z",
     "start_time": "2019-10-08T18:45:15.373035Z"
    }
   },
   "outputs": [],
   "source": [
    "####I think we can delete . this ver, i need to check if we are using it anywhere.\n",
    "def save_to_github_not_zip(git_user, git_password, git_repo, my_file_list, push_to_git_as):\n",
    "    user = git_user\n",
    "    password = git_password\n",
    "    url = git_repo\n",
    "    file_list = []  #push these list of files to git\n",
    "    file_names = [] #push to this location in git\n",
    "    message = \"ok\"\n",
    "    \n",
    "    try:\n",
    "        g = Github(user,password)\n",
    "\n",
    "        try:\n",
    "            repo = g.get_user().get_repo(url)\n",
    "        except (IOError, OSError, GithubException) as e:\n",
    "            return \"error\", e.message\n",
    "\n",
    "        file_list = my_file_list \n",
    "        file_names = push_to_git_as\n",
    "                 \n",
    "        commit_message = 'training data audited via the audit tool'\n",
    "    \n",
    "        master_ref = repo.get_git_ref('heads/master')\n",
    "        master_sha = master_ref.object.sha\n",
    "        base_tree = repo.get_git_tree(master_sha)\n",
    "        element_list = list()\n",
    "\n",
    "        for i, entry in enumerate(file_list):\n",
    "            with open(entry) as input_file:\n",
    "                data = input_file.read()\n",
    "            if entry.endswith('.png'):\n",
    "                data = base64.b64encode(data)\n",
    "                \n",
    "            #print (\"file to commit:\", entry)\n",
    "            #print (\"push to git as:\", file_names[i])\n",
    "            element = InputGitTreeElement(file_names[i], '100644', 'blob', data)\n",
    "            element_list.append(element)\n",
    "            \n",
    "        tree = repo.create_git_tree(element_list, base_tree)\n",
    "        parent = repo.get_git_commit(master_sha)\n",
    "        commit = repo.create_git_commit(commit_message, tree, [parent])\n",
    "        master_ref.edit(commit.sha)\n",
    "        return commit, message\n",
    "    except:\n",
    "        \n",
    "        message = \"GitHub save FAILED:\" + '\\n' +\"Are your github login credentials correct?\" + '\\n' + \"Are you a collaberator in the repo?\"\n",
    "        return \"error\", message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T12:34:55.501231Z",
     "start_time": "2019-10-09T12:34:55.153794Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.github.com/repos/aideenf/AIVC/git/trees/602c472723d27ff6a14e73c3e5e5da42087b73d8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['audited_training_data_aideenf_2019-10-0520:03:25.312689.tsv',\n",
       " 'audited_training_data_aideenf_2019-10-0520:33:33.129616.tsv',\n",
       " 'audited_training_data_aideenf_2019-10-0520:49:55.413888.tsv',\n",
       " 'audited_training_data_aideenf_2019-10-0617:32:53.171416.tsv',\n",
       " 'audited_training_data_aideenf_2019-10-0811:12:44.116775.tsv',\n",
       " 'audited_training_data_aideenf_2019-10-0814:17:38.344798.tsv',\n",
       " 'audited_training_data_aideenf_2019-10-0814:37:21.889650.tsv',\n",
       " 'audited_training_data_aideenf_2019-10-0814:51:31.725512.tsv',\n",
       " 'audited_training_data_aideenf_2019-10-0814:58:41.347833.tsv',\n",
       " 'audited_training_data_aideenf_2019-10-0815:03:23.867661.tsv',\n",
       " 'audited_training_data_aideenf_2019-10-0815:11:59.552159.tsv',\n",
       " 'audited_training_data_aideenf_2019-10-0815:21:20.992877.tsv',\n",
       " 'audited_training_data_aideenf_2019-10-0815:32:43.192700.tsv',\n",
       " 'audited_training_data_aideenf_2019-10-0815:38:10.178973.tsv',\n",
       " 'audited_training_data_dsolanno_2019-10-0709:58:50.185973.tsv']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_file_list = list_files_from_github_dir (\"aideenf\", \"AIVC\", \"602c472723d27ff6a14e73c3e5e5da42087b73d8\")\n",
    "display (my_file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T18:58:24.310033Z",
     "start_time": "2019-10-08T18:58:24.296084Z"
    }
   },
   "outputs": [],
   "source": [
    "def delete_files_from_github(git_user, git_password, git_repo, GIT_PATH, del_files_list):\n",
    "    '''\n",
    "    in order to push a file to github it must first be stored locally, then pushed\n",
    "    this local location can also be local to a virtual machine. \n",
    "    takes: \n",
    "            git username, password, repo, \n",
    "            a list of files to push to git ie the full local location of file,\n",
    "            a matching list of paths to push each file to in Git hub \n",
    "    '''\n",
    "    user = git_user\n",
    "    password = git_password\n",
    "    url = git_repo\n",
    "    file_list = []  #push these list of files to git\n",
    "    file_names = [] #push to this location in git\n",
    "    message = 'ok'\n",
    "    \n",
    "\n",
    "    try:\n",
    "        g = Github(user, password)\n",
    "        try:\n",
    "            repo = g.get_user().get_repo(url)\n",
    "        except (IOError, OSError, GithubException) as e:\n",
    "            return \"error\", e.message\n",
    "\n",
    "        file_list = del_file_list \n",
    "                 \n",
    "        commit_message = 'Deleting processed audit files'\n",
    "        \n",
    "        repo = g.get_repo(git_repo)\n",
    "        print (repo)\n",
    "        contents = repo.get_contents(GIT_PATH + \"test.txt\", ref=\"test\")\n",
    "        #result = repo.delete_file(contents.path, \"Audit file removed automatically after processed\", contents.sha, branch=\"test\")\n",
    "\n",
    "        print (contents)\n",
    "    \n",
    "       #''' \n",
    "        \n",
    "        \n",
    "        #'''\n",
    "    except:\n",
    "        message = \"GitHub save FAILED:\" + '\\n' +\"Are your github login credentials correct?\" + '\\n' + \"Are you a collaberator in the repo?\"\n",
    "        return \"error\", message"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.6 PyEnv",
   "language": "python",
   "name": "python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
